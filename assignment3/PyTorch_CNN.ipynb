{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3.2 - сверточные нейронные сети (CNNs) в PyTorch\n",
    "\n",
    "Это упражнение мы буде выполнять в Google Colab - https://colab.research.google.com/  \n",
    "Google Colab позволяет запускать код в notebook в облаке Google, где можно воспользоваться бесплатным GPU!  \n",
    "\n",
    "Авторы курса благодарят компанию Google и надеятся, что праздник не закончится.\n",
    "\n",
    "Туториал по настройке Google Colab:  \n",
    "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d  \n",
    "(Keras инсталлировать не нужно, наш notebook сам установит PyTorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T07:49:10.177475Z",
     "start_time": "2019-05-20T07:49:10.174480Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FcXBeP1O7cnY"
   },
   "outputs": [],
   "source": [
    "# Intstall PyTorch and download data\n",
    "# !pip3 install torch torchvision\n",
    "\n",
    "# !wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T09:02:13.604709Z",
     "start_time": "2019-05-20T09:02:12.380200Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-afwWw-Q85vD"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T09:02:14.916236Z",
     "start_time": "2019-05-20T09:02:14.912237Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NNU-OD9O9ltP"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")  # Let's make sure GPU is available!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:02:19.873933Z",
     "start_time": "2019-05-20T10:02:17.296932Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YAvkoRx-9FsP"
   },
   "outputs": [],
   "source": [
    "# First, lets load the dataset\n",
    "data_train = dset.SVHN('./data',\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43, 0.44, 0.47],\n",
    "                                                std=[0.20, 0.20, 0.20])\n",
    "                       ])\n",
    "                       )\n",
    "data_test = dset.SVHN('./data', split='test', transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43, 0.44, 0.47],\n",
    "                         std=[0.20, 0.20, 0.20])\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на training и validation.\n",
    "\n",
    "На всякий случай для подробностей - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:02:30.840578Z",
     "start_time": "2019-05-20T10:02:30.824578Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YRnr8CPg7Hli"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "data_size = data_train.data.shape[0]\n",
    "validation_split = .2\n",
    "split = int(np.floor(validation_split * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                           sampler=train_sampler, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler, num_workers=0)\n",
    "del indices, train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T21:30:59.139002Z",
     "start_time": "2019-05-18T21:30:10.021116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 time 13.142887115478516\n",
      "epoch 1 time 8.960036516189575\n",
      "epoch 2 time 8.94799518585205\n",
      "epoch 3 time 8.958033084869385\n",
      "epoch 4 time 9.095001935958862\n",
      "summary time 49.105886936187744\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "def dataloader_test(loader, num_epochs):\n",
    "    start = time()\n",
    "    for epoch in range(num_epochs):\n",
    "        start_epoch = time()\n",
    "        for x, y in loader:\n",
    "            x_gpu = x.to(device, non_blocking=True)\n",
    "            y_gpu = y.to(device, non_blocking=True)\n",
    "#             pass\n",
    "        print(f'epoch {epoch} time {time()-start_epoch}')\n",
    "    print(f'summary time {time()-start}')\n",
    "\n",
    "\n",
    "dataloader_test(train_loader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T09:02:22.498190Z",
     "start_time": "2019-05-20T09:02:22.493191Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LyYvt-T67PBG"
   },
   "outputs": [],
   "source": [
    "# We'll use a special helper module to shape it into a flat tensor\n",
    "class Flattener(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size, *_ = x.shape\n",
    "        return x.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейшую сеть с новыми слоями:  \n",
    "Convolutional - `nn.Conv2d`  \n",
    "MaxPool - `nn.MaxPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T05:32:08.060604Z",
     "start_time": "2019-05-20T05:32:03.815038Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "w9SFVGZP7SQd"
   },
   "outputs": [],
   "source": [
    "nn_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(4),\n",
    "    nn.Conv2d(64, 64, 3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(4),\n",
    "    Flattener(),\n",
    "    nn.Linear(64*2*2, 10),\n",
    ")\n",
    "\n",
    "nn_model.type(torch.cuda.FloatTensor)\n",
    "nn_model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=1e-1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановите функцию `compute_accuracy` из прошлого задания.  \n",
    "Единственное отличие в новом - она должна передать данные на GPU прежде чем прогонять через модель. Сделайте это так же, как это делает функция `train_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T09:03:30.757326Z",
     "start_time": "2019-05-20T09:03:30.743358Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2ek3KVQK7hJ6"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Enter train mode\n",
    "\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            x_gpu = x.to(device, non_blocking=True)\n",
    "            y_gpu = y.to(device, non_blocking=True)\n",
    "            prediction = model(x_gpu)\n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "\n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "\n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "\n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" %\n",
    "              (ave_loss, train_accuracy, val_accuracy))\n",
    "\n",
    "    return loss_history, train_history, val_history\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "\n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    # model.eval()  # Evaluation mode\n",
    "    # TODO: Copy implementation from previous assignment\n",
    "    # Don't forget to move the data to device before running it through the model!\n",
    "\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            model.eval()\n",
    "            x_gpu = x.to(device, non_blocking=True)\n",
    "            y_gpu = y.to(device, non_blocking=True)\n",
    "            total_samples += y.shape[0]\n",
    "            prediction = torch.argmax(model(x_gpu), dim=1)\n",
    "            correct += torch.sum(prediction == y_gpu)\n",
    "\n",
    "    return float(correct)/total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, train_history, val_history = train_model(\n",
    "    nn_model, train_loader, val_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6a-3a1ZFGEw_"
   },
   "source": [
    "# Аугментация данных (Data augmentation)\n",
    "\n",
    "В работе с изображениями одним из особенно важных методов является аугментация данных - то есть, генерация дополнительных данных для тренировки на основе изначальных.   \n",
    "Таким образом, мы получаем возможность \"увеличить\" набор данных для тренировки, что ведет к лучшей работе сети.\n",
    "Важно, чтобы аугментированные данные были похожи на те, которые могут встретиться в реальной жизни, иначе польза от аугментаций уменьшается и может ухудшить работу сети.\n",
    "\n",
    "С PyTorch идут несколько таких алгоритмов, называемых `transforms`. Более подробно про них можно прочитать тут -\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms\n",
    "\n",
    "Ниже мы используем следующие алгоритмы генерации:\n",
    "- ColorJitter - случайное изменение цвета\n",
    "- RandomHorizontalFlip - горизонтальное отражение с вероятностью 50%\n",
    "- RandomVerticalFlip - вертикальное отражение с вероятностью 50%\n",
    "- RandomRotation - случайный поворот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T21:32:14.486017Z",
     "start_time": "2019-05-18T21:32:12.807970Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jCWMUWmr7t5g"
   },
   "outputs": [],
   "source": [
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.50, saturation=.50),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(50, resample=PIL.Image.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43, 0.44, 0.47],\n",
    "                         std=[0.20, 0.20, 0.20])\n",
    "])\n",
    "\n",
    "# Create augmented train dataset\n",
    "data_aug_train = dset.SVHN('./data/',\n",
    "                           transform=tfs\n",
    "                           )\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size,\n",
    "                                               sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результаты агментации (вообще, смотреть на сгенерированные данные всегда очень полезно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T21:32:16.492969Z",
     "start_time": "2019-05-18T21:32:14.486968Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YlJJEro1KZ45"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABqwAAACvCAYAAACIEP81AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvVnIbm2a33WteT3TO+3hG+r7qr6ik06nkxAPcpB0ozEHDbZC6FakPREEBTXSEEnSJBhMW0ZCa7c0msmIAxEEDxxAaEQDQY/EI9EgqeqkurvqG/a3x3d4pjV7sCvQ1//6136fKv2eZ1fV/3e21r7XdK97uO71vPv6JdM0mRBCCCGEEEIIIYQQQgghhBCnIj31DQghhBBCCCGEEEIIIYQQQogfbfSDlRBCCCGEEEIIIYQQQgghhDgp+sFKCCGEEEIIIYQQQgghhBBCnBT9YCWEEEIIIYQQQgghhBBCCCFOin6wEkIIIYQQQgghhBBCCCGEECdFP1gJIYQQQgghhBBCCCGEEEKIk6IfrIQQQgghhBBCCCGEEEIIIcRJ0Q9WQgghhBBCCCGEEEIIIYQQ4qTkx7xYkiTT797++X/6j4UyN69at/38dgplmqZ323kWf3e7XPhHe3BRuu2iHsIx4+SPGawLZW7vtm770ydtKNNa4bbfP1+EMo8fjm47T/1z9ok/h5nZCL8vFlN87s7wfmKZYvLnzuDa23AOs//xN/6PsO9YTNOUHPN62E4Zf/IX/gQcM8ZCeJoxvovE/HEpvIuBnLeF956MsXrqJPOXnuIjddC++74PZdq17yfNtd9eX8dj8JnOzuIws3pn7u+vivf3P/23/3vY9zbzNrbTHzT+q1/+H8K+7X7ntps+jsvbdu+2N1t/DGnaZr1/Xc1dE4rsb/x4v7/bhzLN1h839r7992O8+L73x7TkBgecokjzSs338//58/80lEGO3U7NYlt9+LN/LZaplm57KstQJp3Vbnu+Ogtlzi4vfZn5ym2XpT+HmVmW+SpJ0vg+qsy/1yIj3W/yZZI0lklSf60RtgcyZ3fQVvsYvtiE80sa54608PeTZb79pOTaI3S30C7NDIZ8G8f43FNyf9383X/jq/6YH6Ex9d/72t902wl59MSgnZK7xaPwGLP43vMsztFp6ttCin0kXtrGyTeOYYyNpeu6e8uEZgh9hL2mcYT2Re5vgjiIxTwD7Bv62I++9iu/hOf9kWmn/3/xtV+BOYA9EVQrCWNtgrEGmqCNODiRa6VJbP9J2BdfMd7ONMDY3pMbxtsht5fCM/Vk0MXn/iu//q/HE+ExR26n/8zP/xF3kxNptmF8YrcYKjrOU/ho4wAHkVcxm/u1+Tvvvh/KvPPue267qmehTNP4MQ3jTzOztvExXwKNucqreH8Q71RFLJPB9w8ylJvh9wUcc8lcjGMjW0Pmub9YkceYLUt9mSwhcSzMNb/4p/7CyWPUHwb+2n/074R9Y+Lf/UjWJ/2A3wb8NospUvicOMRlmnWNr+JmE6+9Xvt+stt18O/rcMzN7a0/bxe/YVVz35cevPMglJnNfN/+G3/jb4YyyI/y3P+HfvyfCPvw5shSwCBUs8nYosKTkvVMDtNAXvi4FsdGM7O2w7Evvr4B5u2WLLhw/s1SWEuRVpHBZD+1sZN0rW+7wxD7SApr0Sx+Lra//62v+2u9he30z/zFf9ttT6TSEniHVR4fNr9nHcvuBOt16GI9jxB3JWTuwmlxnNi3YDgG74UEgVgG50gzs1/9Whzff9B5UzvV/7ASQgghhBBCCCGEEEIIIYQQJ0U/WAkhhBBCCCGEEEIIIYQQQoiToh+shBBCCCGEEEIIIYQQQgghxEk5qsMKud3GPLPfvvH7NhtyIOTcLdr4GPudzwnZQYrIx49iLmhMjTmxvOGQjLKZYg7Szcaf+7MmPicm1Xx0hclY43mTyefXTYm7KMuzsA/BPOKYgzMleTp/9md+ym3vNtH3koBDYyS38umzO7f95PnTUCYr367fUX/+n/+nwr5hgvzeJL8u5uoeM5KvFtoy5l4t05ivNcHc7CTjJ+ZaHTCxv5k1g7/n/W0sc/sE8kc/A/cacQPVkE923ca6SQrffuYPY3/82X/uj7rtFnLO3lzHweH5x76vjTfxvI/OfT9afkhcL1fg4iA58/+3/+7/DPt+GPgrfzL66s7e92Psoy/73P/vfjm6hB686+u5mhMfW+cdUc+efB7KbHfeG7Vv49hzc+vzmr94eeOvsyeuEpgj0iF2pHnqc/Lvsm0os079tds95GBvYr8a9tBOMa+2mWVwbUvigDoeX0f1ffHBz/0nbjut5qFMtvDuqaSO7sfqzPuoZstYJi98vWXgwsqLOKYW6FfCMdbMSsgzPSPTVArnmcbYVsfBv/sOnJws6XsC774wkrQcvJcjiQ/QR5XCMUkSHRQDTDAs23wC+dsxTjIzGyErd0KkIn/8P/4mOfvx+Nov/7rbpvnIAfTImcX3xXKf48SNfiWaCh3K4HY8K9+D+feHgczRcM/4COz9ocOKuXcwd/whOd9RJ0Srk1qr3syAMgUzG4b738MPC//ur/2HfkdG2jL+XSOMK6x+DqozqPtDFAsHvXfYTEnsFg6hJ37zOun1PuhH0K865rDCLkHmmgm8acxjwdxqbxtJdo+84bvtw/Pg+zngPOgSZV7FoM9jcya8wx35brG+27xx28zsFjw76Myosjj3rpbe67mYxbipKP3gWM3i95Cihn3QzTOUwVicI1gfSXGeI38Djb4jMuTSd/PDzK/91X/LbWOMhW3XzAyVqRUR12AswkaIxDA2iWVQl4Je6p6sV/DNo6/KzOz2pV8/3b6KPqrN1gepqKNq2jgWNjt0fzPHne8DbVzKWfF2fXqi/ORH/rsIe4FdmKwO8C+S1pJDQ8hCvcZ3nKGjl3V4+AZJ9DxhHzpUX9+f3y4KX6Yg30OrCtZJZMzCeDgn7X2AfWEsZL6jEf2o5BszzmMkPkCfIOqLf1B4ce2/0ySkIeSF77ezOn7Tqyq/D8fG2G7N7lt/vd6JRxywxiBxLK6D+t4Paj35PovuroJ8t/hzf+kv+WPIPNqDX3O79bHJ02cvwjEvXr5y2//r//Ibocwp+AFt5kIIIYQQQgghhBBCCCGEEOKHBf1gJYQQQgghhBBCCCGEEEIIIU6KfrASQgghhBBCCCGEEEIIIYQQJ0U/WAkhhBBCCCGEEEIIIYQQQoiTEu2cR+STuygvbcFRfjWLx2Ug39vuu1Bm23gB3tMbL7uryyjju3oI4vBYxDIQ6dUWb3A/eTnahghzv/XEP/v1tReuXpxHAeuVd9LbQLzrGYglx4wo0hN/P8mAgjrSLEAm37PzhssQmSEK5tlPptlJm2UgzaI0Ev18ExGvd2D0bYgQr4S2nEKXbEk1Mzcg0prvE7sxtsHbjS9z8zyWsbW/WLUEEXUaj+n2IJ7exYY6PfV1WsyI8HPl66YHkzdKLs3M5iiiTWNb2m1AfEmeewXnzmbxWj/7cz8V9h2TX/nZ/8ttj12UUeapH0cSInfsUm+fnZ/HTvnOR37w+eAfu3DbV1+N116d+/dXlVFGmUxnbvvyy2ehzPp677abJs4bL17eue3ZJ8/c9vVzL7w2M2s3/jxlFp8ha3x9LZZRel2C9Prm1bXbZkLNGt5VRoS3WeLfXT8QmecPiKz6/Q8euO0hjXU9lF4wbvUqlKkvfDvMiYA1COph3MiT+D5mua/HIo/1OgPr9SJO0VZCmTInAnQwBacpyOHJKx1ABt+PcTzad77MmsRFdzvf5vfbnb9OHutzTPy+0UjgAVJb4q5nk2Y8DTOAHxG8fkIEuvcdw6BCXywDcuqBhW7QOBJ2WhQyE+k1ipwPec4RxjF23mG8vwzGksyHnGBcBDb0LIsHpRn2q1gGpckTuT18V4e8u2Pzp//NP+226+UilCmr2m3nORmwguE7PmuQsU9Yh0Qujl2d1SGeljUVPC8dWOAY7MOkgYV9pP1j06Vtxd7c10ZyEHQRGzuyvgAZe9/GsZwJ2982sA+y8eCQ/oX9lo256KbHMgWZi+f1HLaXoUxZ+jKsHdgI82h8Xba98R83dmsfd6ekae/m/phZvQllMognZvPYz5fn/rlWF368mEhs3g2w3iJjbgYTUE++dUxwGLZ/s8PWtF80v/7rf95tF2R9meEHC/LSxhTWv2wMgH6RpP5ag8VKGlt/3qaNlZZA/2L1CpeyoYvvDOf6fevLNCS2LDN/4nGM7aVp/P3tdvE5d1sY+2DMH3rS9weov4yslQbf/+82cR1ZlWSOfMvA9eaEHczM8PFxnjIz66Gt9ANpp9AOMmjbKannHMaJjHyDwbth8VwJ32jzgsR8Ka7b4LtNFvtwGub+WKbtfV3sm9je8TsExusTTkgW1/AjiTuwR9CxEV/VAXHR28gz+FbC2mkK83hVxjXqcuHn6LOln+/mVfxOj+3USEyRwByQkDUFrqVGEkP30J520J568n02K++/dljj9LEPt61vp5uNjzt2e/997fVp/DP8kT/+M6HMvvHH7bYxNukwbiVzIfmZ5bui/2ElhBBCCCGEEEIIIYQQQgghTop+sBJCCCGEEEIIIYQQQgghhBAnRT9YCSGEEEIIIYQQQgghhBBCiJNyUlnQ+Cpe/qz2uRzffxBzyk6Qe/LlfhfKNC8g5y54dF68jLkUFwvwT8xJDmPImZrnJCEz7MtIDvUc8qbuR59Xct+xxKU+T+dI8ieH/O0kQyR6D/CYdGIOqwbKxGfC9JT7oQlltp1/zmyM77di1z8hCXFYBRcQ+ekXU8znpLvlkJs9ptyN7aCDPKUJuXhnb85BbWY2vvTbxXUoYhk4qx6969/XYDGf7NOXkNv0Gcm1vfHPvXsecwRXNbRv1FOR/MkFFBrJ/fXoFnsZr91Bju6zq9iPigcsmf3xaMa12x5Z/vgEc5qTHLKFfz+zi9gnH3x47rZXH/h6nS3Iu4D3lWWxHaCPML2MjqgUXBwjyTU8W1357Zm/30/LJ+GYHt7x+DiO5QPk921u7kIZrL8BHIED6cNjDw6ZjuSsh1ztCcmJzfa9jfyBP/SB277dxft+uffjWJvGdpgv/BiaFmSOhoE3g/5eZTF3/Sz3/WJVxPdxOff393AVx5bLlb/ny7M6lrnw++bgx2N9dL/zbXW7i2Ve3fr59ul1zCn96Qs/ZnwC26/2ftvMbMh9e57y6MsZ0A0U7DPRR8OSszOPxzHBWCg/yKfJHD7o+SFjALxn9Lv0JAbE86DTysxsBBfBSGRY6L8ZSe7zAY4bIM8685UMBzh8cnCu5KwPw760Q58BmY8L/66ynPgLUODBnE3BvxSKnJzQnqjL7N4d4Txs7AmODLz0IXXIyuClmNMO1knoMzAzS2HQQLcpc5lhGeYNTOCGJuaVQc/VAY3nEEcaOgSwX5mZDcQ58raB74b3pe9j0CftAP0X4VrEzZxBjMH8GFXu5+uOxGo2+DY2EYdVDn7dFO+HuMx68AHviesCF/Q9cRKl4JEpSvDbkUfaQuzLxgZ0wQVnhVmQWNVljInynHgxjw54pUiJoL9hsf0BY0AYkRJ0WEWaxsd3E1vTN/A+SFtYb/waZruLMV9ZQ+wNrx6dLGZmq5V/r1UR4/c08bFjRlyxw+h9ww1ci4QdNqb4cYA42cD7yr7HdMSP9baRo6eJxDk4Pk5Edtr2vq+2Hfv/C77uS/BI1XXstyV4wJifCjtXRvyCVQXvi/iocOxD12GO8Z6x77Hxne/xGxtpTzhvN+Alwu90ZnFsYA5q3Mf0VFlw4P1g/t8T9NKzsRLrg6k78TeBBNoTbpuZrUrvtcpxDHl9g/465Noj9BH2Tvedbxvrjf/NopvioFZN4Dknc2SRY+NgcZHf13W4zmSyZNy+v/2jE+/1PvgWE6/0PYV/P5itXAghhBBCCCGEEEIIIYQQQvzQoB+shBBCCCGEEEIIIYQQQgghxEnRD1ZCCCGEEEIIIYQQQgghhBDipOgHKyGEEEIIIYQQQgghhBBCCHFSDjFKf2GkXbz8xSMvFptfENkX7BqIjGwDUvJbkJeu9/G8tzf+97tHMyLsQ3lpGgVrBSgzpzz+Lnix8ud5dAFC1pIIYsFhmRKRYoqSYqwsMzMUEWa+TEJcvskI99PHaydgpNsTASvKvnMic0Op5KnJiHARxX+lxTaYQtvoiVhvMBCZQ7XOknhecIca8apaAqbG/Y6I9V76djnfx3qvvuzPMyzvl8OW0Fa2d20s1Pprt89jkfrKX7s89+dFebuZWZNs3fYmbUKZAiTAxTy+37ECeTzpa33Cnv54lGf+vnfX8VmD95MMBzh8lotYr/VD/94r8CYTp6WBe9WCH9KCa9jGIRZKYLwaWbWDwDrLvLDywcOH5P78g5ds3AHD7+72LhS5+vjSbT/59udu+5Pf9ttmZk+GZ/4y+20o00O/zrCyzKwk0uK3kZ/+oz/mtj97Gdvqb36ycduf38WJqEvx5cc5Jk38vmT08vCMjFqL0tfte+fzUOaDR14Y/dG7y1DmauUb/SL6xW1R+zYOHmNLyd8RTRe+PTdkzF/v/cWu1/H+Pn555rb//rf8wPuNJ9fhmGcNzOtpvPgEOtWePQMMPihINjMj3tajkoK8OA2CZjMcRIkn2EYQ7zI5O0pr8ZiRDHTjAOcZYoUNINHtSYDQQ2zWkFitA1FwP+A2OS8zogNV5cfdehY7SQ4xRAZyZhbWonga5w0z5g5mkuI3b78NYN9h3uIQspAHmbCdogTbSDuFyieH2AjtkvZr2MfGAwy9k4zEBzDWpPDecxKcYD9n99fDPJGQB41u6uSN26+vDTvIM+G0nk5lKJNC/Pmn/qVfDWX++n/5Z8O+YzIMsBYmQnIL++KYi+9rIgPAfZ7wkbzkAdrp0MX7a/cwVpLJt935MrttjG/GHu8Q4lryTDi8pyPrI75uMovjaTr5fVPv+0RL3svmxj/TvtmHMgMEqZt1jGM7mFsuLy5Dmdl8EfYdmwTWhR0bEwaco0mbghh1YINL5s+TZP7aTRPn/u3Gr6ObdZyz250/b7eP5/n8yRO3vSPvdQ7vo57P3HaWxTEVl0/5Mo5ZA4ypt+t47Vd3O7c9wbqnxMWnmS1W5377LLans/OV2+7aXSgzkLp42yhK31ZK8q0whZeRkjlmGH0c1vSxPU3QdgtYJ81I7FbBwp/NgRhTpOw7YOavlZFYPMTVOG+S8yZYiARPJXysGMoYS/Y9jN8whmJc8nqfP2/fxTrHuHUiMT4+Fs6PPyjM5779kM/pNsGcN7JvzzDM7aFeizbOx3Xt19QZeV/4fjBeMDMbYeyeWF+D9o7fxgfybRjj2L6K1+5ziLPDB784l+wbP48MJK7N4JnIp1ZLO9hJFyEHFCF99Lvxg9nKhRBCCCGEEEIIIYQQQgghxA8N+sFKCCGEEEIIIYQQQgghhBBCnBT9YCWEEEIIIYQQQgghhBBCCCFOykkdVkkV982X6Kkh+SAhB+kcZSlmdlFBzsjc53FsSc7+u52/9nlH8p9i7mFSg5gLOZvi74LzyuenXII3ZiBukhRyI2cW86qiwwrv5fVOvzliESJlQCcSczL0sK9pibMJ87yS28vesnysAybbt+jjmIj4C6sxIR6kcBzm88ziMeWQ3lumgJc6bUju1bU/LqtjhyzPMSmwb1+dxXe8WvjcyOOC5F7d+n19G9tyd+vrIjv323lK8vpPPgc1c4D1IEY4fycUsWQB+Ykz0iZJTtlj8u5XfN7u6yzm397foksi3vN86d/7YhUHtQKeFbUQZaxmyzN8X7Gd4u2QVL62fuHz4j//dB3K3F77MpgHup7Htj0/8znNFxexPRVwWD5FF9b7H73ntz9+4bbPL78VjrHxH7jNbhc9Vzc7eCaU15lZBQKyX3j8y6HMf/M07js2f/D3eG/BxYv4onfgL9t08T1f7yH/8kjyrve+TN77frFcxvb94SPfFn78SxehzEePvNfq/QfxPPPgmQxFYh5nmBNTMrdiLvaaxEXLpd93NSfuzHPfhhZQF9Uy5qT/xhPvFnuyjmPIGub6nrRV9FwxnUl6YodVDm4GzCNuZpYk6L8h81t/gLsFYTIsLAJtg50X7wd9Quz+0FdlZta0vh/14DgYxtiHR8iHztKTD9A2WCyJBwZPC3kv6Cqi7iLwYaBLwYy4xE7sqqSA7wbjczPisGJuWqj7kdaH3+7BxTOgV82if427i9D3RJzB6Ndlgl1ck0FbYR664Hxgax7cZt0Tw3d4L8w7ibvYHIF/SjplzFUHfY0aAk4LOovpoH+AdwShbkGoV3SITBMbD2BfWAybDS2sa7fRyYvuq4m4WEcY9xL4AJIWxNkJvo5uiOM0SuSYs7CqfexyBs7lgbgvRvAMj2SNNrTga2ric+82/p7b3atQZrEknuMjM/U4r8e2ig6Tns2tsCbuyDw5JX5fBt97+jZee3vn6/HuVVzvbbe+zOYullnf+rpG36+Z2Tj4fUNXwb/HtrBZ4z2TGB9c2tfr+N7X8AzLlfdnnV/GNdjVoyu3/eDxVSjz4IFfL2/ubkOZZ589CfveNpZnvi8XJM7JQDqD22ZmI0xeGN+ZRf8a+uWrKradovBjC5v7cYwayJjV4vdDFuviuIVuJ+ITykAanBUs7vALOfRdv74diE3g+2zXxrgxAb8yxuFmZj04aFl8gN5j9p38B4GLhW/LGfE4ote8IfXagkux34Hvj8QUTeHfcZ4T5x46LolXOHpVybyBrliMX8h3+vD9mPl2IfZGX6SZ2Xa7g20/J7D1awKNjv3WkGXoyWNxNn4DjM9QfA/f+9+uXwaEEEIIIYQQQgghhBBCCCHEjxz6wUoIIYQQQgghhBBCCCGEEEKcFP1gJYQQQgghhBBCCCGEEEIIIU6KfrASQgghhBBCCCGEEEIIIYQQJyXa+o5IlUeR1ywDGSUTsI5e9JekRH5egSyw8LK0XRtFY7hv38QyM3CSo1TMLIp3jQlYg3nXP0NJ5MIpWNjGjMjd4Lh0ItJf2J5Avjim5Lypfy9TGuVzI4hCh308D4rkRiLPrSyK308Jk4Kj43qfNLHM5EWNNXlf+DImOMaG2LYTeF9ZFq8dBJq3sZ7LFqSDZ7GtlAt/bhR11r0XopqZTZVvK+N5bCufPsfzzkOZ7MafJ3nfV1adE5knPGbVEZExCNsTIt2cL/wY01h8hon0k2Py6Ksrt93uonCx70Dy2US5aZH7NrdYRsFoXfmKLQv/Lop4iGVBLs6kkX57c7MJZT79h5+67c9+5yaU2e/8c+WVb9tnF76uzMyK0vet5WUcd1J4zow852K28Odd+fMkeewj+42vz2YdT9zvn7vtzctYNx12/dM2ye8KVm1/Ece1Byu/b17Eh7kDgTdxXlsBffVs5uv6K+96+bKZ2e//6iO3/XvfiW3h8cK3hWVBhL6wnbAhHw+DQof8FRF7zT0IWFls8gjqIn/ft828iu9lTH1f2v7Wy1Dm9nYLe6KMOcl9nU5EIntqMhDApkQImxwgiU0wfjvoUX0hdm2D2HJksmVsHERkjHEYa08JxGYdxOsjkcmPk39uFr6XMDYXZZQd476i8uNjWcXxMhyTxzL47kYygMAjhO23ARxXwprDzJIR2g9ZhyATOc8A48oAMVU3kLUA7BuJMD0B0XTC4gOo/JTEXLheSUKcTVv3Gze/c/E3b5NTY59h0nccl5lMGxcYyUCeG+fHt3Duz6A+RrKujdV6/3jFHja2XX9tNh6UpZ+n8jzOfzmszVMiIEdxeVHG+OErj9+HY/y/70GObma2Wft5dbvBedbs+vraH7PZhzLVzMe/i5Ufu1Eub2a224JwvidjQw/11cexfIK16MTqDxduJ6CFauvJmNX3vk6ato3nGf2+to/z5AANuiyg/nHsNrP1rb/Bu7v4nvfwzaWJnwZsGCEOI9+IWvg2gN/Y2Lze9f5iA37LsBjz5UXsJ0Xp62829+urywcPwjEPHj102xcXZ6HMYuG/MdQV+c4E7/yX/sxfDkX+/V/7i/G4I7Ja+Zg9TeP7w3mHvS/87jeQ9QyOayks6ssi9ne8n24g3yVa3yf2+9hQBygz9iTOgP6YwNyakW/Meen7VjWLa5V0fn8sOUz4nL7ddj0JHKGK2XxT1/D9YIxlMphHsxN/izqEX/ylPxf2pVAh+D3IzCy0niyOjX3nD+wa+O5F1lLDDMZl0pYzaCtjR24QbnrCid3MJoiHUwjgRxLzYFyYki8DGbZ3Ehdl8D2khu9ePZlrevYigCkEZSTGD2F2LEM+U3xXTh8lCCGEEEIIIYQQQgghhBBCiB9p9IOVEEIIIYQQQgghhBBCCCGEOCn6wUoIIYQQQgghhBBCCCGEEEKclKM6rD58+Mf8xRPi5wnJ2e/PA4p5HM3MigJcDZB7NWV5Gxtfpt/H/KdTDb4nkvd1gvvJMc+zmRWQTz5NfM5NonayKSSEJH4FyKuak/zEIQE+eMOGkeSKhZyWCcnnPkCu6jYIViIsf2WOuUVPzEjybnYJuNbIcSHV6hhz5WbYLiH/fkacAh3cD1EI2GYN97wjbdB8Xt6kiDmxMbdqg44Kcn8F9Ouc5IbNU6y/2JbTvT931UHO4Cq2kxR8KyM57xnmtieeAQM/FhuGqvy0v/effcnn5H7+5C4WeuW9R8kQ6ywHF0JdE69c7es+g+bEfDkhbTBTQMA40rUx3/WLp6/c9vXT21AmGf17H+CZtiQP9H7px6fp3ftdF2RoDH/2kSx8XS3eic6kR1/6ktt+9Xk8cWEXbnt9tg5lPvuW93uVb+mfoNQwd52T9PEP5v4dXdYxb/jN5POETySv+QLa6jtnvm382JcuwzFfAWfV41Vsz3N4hor5qXAfex/3ODsGFCSGEt/FDQTjWM86HBx3VvodHz4gdb5Zuu2PP30VynwGAoiB5NUfwXvJ3KOntlodoFMJrh32LqIIieT3hu0U4zmSlx6vlZF6nmDfmMXJC+MOlku/KPxcgS6CkQyG6EVg9ZeX4EGoYlxUgOeqBLdaUTIfDTg5UaJoFipwwPs14kQik/9f+LO/Gs99REZ0GrF5Kbh0SRHcJmXG/s0Oq4G4GtB7NbL2j77dJF6o+Eo6AAAgAElEQVQc+9o0kPaOzipwCEzERTPBQM1y62PthLWpRWcVOpuYlwvdBAlZPaDfC90qZsQh8BZqLOJYef8If0ARqhPD58cyzPWC416WEScLBrvkBvHclxfLUOajH/sxOMaPYXc3Mb67eeX9VDfgqzIz68CrsV7HdQDGFA24bFsSdzc7H2uF+cnMbMQ6jfNICvuKnDhjmBz2yLx67v1gLYktd3sf52x20SvbjuDsIuNGDm1qNvNlipS4wDoYC0mciAFnWpD3AevonnieR3yv+K2OOqz8czdtXGvOwBeEfiozswb8MxgfsGNmM/QExzrf7fy7m8/jIuTBA+/Cwpj6bSCDD0voDTWL8y8bUzE8KkgMiE6oNMneuG1m1sG1d23sR5u9bxvNnnzzg/iSfazOg/8U1kBddMyhX5N9n0qgHyUklkyHN89tLOaZoF0yT20O3i3mr8SlQfo2Tv5AQQaN8ImUfiOCmB1jIyNLJah75pXC9Qv62szYd27yTjHeJB9kk/Dd9H4/KvY9JsRGx2tC1jM5jGHhtxDSh4Ngk7mn4LwZddBibH5AHPsG3tLPW0IIIYQQQgghhBBCCCGEEOJHBf1gJYQQQgghhBBCCCGEEEIIIU6KfrASQgghhBBCCCGEEEIIIYQQJ+WoDqs+yD5ITkvIlcvyx4e0siTXf56DbwLyQWLaczMzTFk89OT+4Lic5JXMICc5yzE7hXzQPk9vSnJRppCzOCW/N45Ypyk5TzjM7yApU22aetwRyrS9z8HdjdGJlIFTK+RqN7MsjzllTwnRNFkGDag0kvsc8+CytgLtYDt5r05O8voX8AKzjvhCtr4flW18iAHOMyd5s2vwXOXgIemzmHsYvRCs/mbgTsl2zPHhn2vyKcZtYg6p3F+7IO6iAsYUbNpmsY8w1xoVzR2RxSOft/vi0SqU2T3z7WlLcsgm6OxgYw8O3bDNstDipUjzD2WKmvjOIN/7drMNZfqtzyU/q7zfa2xiP0IH2fsfPA5lJq+Rog6rEdouziP9PjYeSNNuaRnzqV/C+71cvhfvrwe3GHEz2tO469jg03XkNi/n/t2flaTvTm/26piZzWAcu1r5enx8Ec97ufDvaEYioxrmPBJ2hJCGqO/C/NrDvB78NOS8JXPGwTSQEiFNDj21gDF2RZycj+Z+Dng4j330ovbxyzWJnRroPAm6QewtcFhBrDaR+ARzbh+Ug5vqxCCeg3cacphbHEPxHGYWBtUpjxcfwFfQFyTO6H1fG8HByVynWH9s0E9h3M2JjwodVUWFXszYdvLCH8P8AHg3bE4KCwzSlg9x8XyRjB14pfr4IOieItURmyUZe3AYwfGJea/Qr0L7yAHruBAgkAEVHVXBKUBuMPpfWP79eC0k9ln0AxDfAnquyBiDL4bNCVPY9/Z5LA5xWIVYkiwYwjhHygzBXXZ/H02DF5ocg7FvkBObzefeWXVx+TCUubjw7swx3F8c07IUHVvEMXl947aHPi5oytKP3eheY/4OrIuqJg5m8HCVRSxTwbXZayGhwNH59OPnbnvfxXrcNv6bxnof1yId1H+Wx/X5auHXJ9PK1+OsjhWCoS53T8G3AfItpV74aDwnDhP0O83m4Igi3yVu73w7nNi3C/RXkufMIT4oCn9MXcU+MMM2RtYFt1v/rioSdyznsG7s4jesU9PsvZep6+KzYn/OyLeSGhzB1Sz2XVx74/eqcSDjMCyA2yb2ow68l8xnW0I8V5F+VKT4vRgcVj1xwUHcWjLHOsTHzGGVocMHv8tRr7cvE/ybZjYNWMehSJgPcxJn/PTv/+l44CkhbqfwOYpNDhhLsrkKgrU4jZM10OjbZT/GdopLARpLwnOx+5vw3FiGBtG4j50Xz0NOg7HShDFZPCb4QEkjxDEmxFIWx4uM/q7BvpJw9D+shBBCCCGEEEIIIYQQQgghxEnRD1ZCCCGEEEIIIYQQQgghhBDipOgHKyGEEEIIIYQQQgghhBBCCHFS9IOVEEIIIYQQQgghhBBCCCGEOClHVV32tZcFjjkR3YLEk1qRE18mIY+RZ/5a4NCj4tQBTPAocTUzS+B+EiK0TjIvKGNiwgnkeyjYnogkcRhAgDhGEWCSgyibiC+j6xgEg1Tc5sWOA5Gn7Vu/ryceuRGOy4hweJFFCeIpyYiUNPgUmZwdtockyjFTEE0X8BtyOsVrdyBb7onM0EC4PRAbX1f5PpLN4judQ1seRt9WSiLLzEHqt8nvQhl8xROTXsP2AKLxJI2SRGzvI5FldoU/rsAxx8wyGGMyi3VcknZxVEoQeLLxFDsz6dsDCFCbTWyn/RbEktAuJ+JNHGAf++sIHGILkP2ama0uztx2EACb2YQic2ga21e34ZgXky9083Es0zZeRFsv4ti0fuXFvM3GV/LN0yYcc/3J2m0XYxTeLlcLv6OO77f6fT/ptrd3bShjfy/uOjbYw2rSGK4Wvg5WRMhcw3jZkfmthld0eebPe3lBzos3SESk2J6ZJxUlstd38d0/u9m47d3enyglPWUGD3V1HvvJgwv/ECkaY80sDfMvCIiNCMIrf56LWewDl0vfJ7e3ZL6BeWFklcwGqCMShksSA+J9TxO75/skwFHAbDCfoFjZLIptExTqvr5BfydE7Dzk/r1nJFjLId5Eye5IBn2U82K8Z2aWQuydFSSGgH05CLeZyB5j6BikWeigKOnm+8h5qKn4ePTd8MZtM7Mc1iZTStYq+BxkHsc2FsTrrCoSEDKTODasQ8i4h+uDhFwM+98E7RKl2K/LQB+mfQ12kHgvgXVaAnWTkmOw/lgfngZ8V/HdYf8bg8H89IQxjtzi+H2M+ROrjyAgP+DvceE0tFdDmSKP89/sYu62Hz54GMpgW9jsfByQWFzPzGY+dmn3MU6sZz4WyNdkPQNjbl5AGyRhY1H581xcXYYyy/nKbbP5soe55W63i2UGcgNH5vkzH/+3Q3wfDTzLpo1jSw+BYsa+ssG5U3gBSYiYzQY4L8ajZmYpXGy+WoUyRenXFefLWGYFa6y08G2377fhmKb37bnrYuybJP7aZRn7aAlxfw19oCrjmIr79rvYnrZ3/v62ZB05g7hjPp+HMqem63zb2W1jPQ8jfOMoYyOEacgy/EhqcfyOMSubj3E7jtU4HlVhAWa2qPw4W5dx3C3wnuH2+j5+yxihD+dFvHZZQ9sgdWMwXjeN384z8h0lg04b5nm2viCXhnpPUxKbsA+5J4TdTYhZSHw3QgX0bOGd+npNJozzWT1DDE3Oi2uwcSTXhrF86uO1JhisQ8xKBvMJ7ofNrQYxfeifZpZn2IfvX9/gtYY+zoVD095bBoeHFAcdM0u+h7hV/8NKCCGEEEIIIYQQQgghhBBCnBT9YCWEEEIIIYQQQgghhBBCCCFOin6wEkIIIYQQQgghhBBCCCGEECflqA6rGvN1djEn6Tj5fckY8yJivvGR/OwWcjYn/rw58z/16A8i+ffBd1OlMU+pQZ7SborVPJLru+uwjJ8JOmtiEXRjUeC5QhpadgrISY/5P83MmgZzLJO8nJA/syB+hbo6rRvon/0Xf8Ztp8xPBY2O5WEPeVNJftYEzlPC+yMZU22AvSz/Pt4Oe1+oNMhIg+pb/y46zMvLHBro4SIuiQr64zjFPMI5OjMgZzC6AMzMEnBzdBlx3EAfRh+TGXksUiafTutamxp4/pjK2orE5/8eSS5fzF+/v4n5v++e+vzfyw/Ab0JykQfnD/NnHeAUef+j99z29fN1KLN56nOqT40/725N8gpD/vnf+frvhDL9132Zpo9jWrf1584nn/86ack8t4FxkDisMKf4RHxsWenPg/nf3xawdbC7nEEbqolnsgJ3TVuwfPa+f88X3vFQVWQ8h2ZHrUSo4yBt9W7t28c3P30RyvzOtz/3x2z9mMp8NBcrn0v/93z5USizXDx223PSXkJOaeiU7L2U4MIi6fDDvJUnJHZCbwzLXU0Tth+RkICfxDAD5pi//55ZbvEJ50lwnLB83+iwYs4hnNhHklM9QHxnCcZ8OB+TfO4hFj8g/z7lniLUYYN561nOd4yLDnp3JK8+FTcdjwEdVsylArFQzhwVyQG+BNiHrqmcvM8Rz8v8Wbh9SHunQQT6AO53d6FbjY3l6C9AF8DrG8R1wP19OMPZkDRTXE8kdD14QJkTg/Ecd8bBNj0Tesruf9YM56ScuZ3AG8jGabhWQZx7C3A5rVbRfYNjzW7jY+qczNeLmXf+9Iv4vWG5Wrrt7SbGxwmss7H9j8TfkRX+TazOFqHMFXitMuI0xld1t40Oq90+7js2O3DQ9CQ+6UZoQ+Tj08ic0sB2j23KX/tsHntBWfh1RBmXDFbW/h1dPb4KZRarc7d9vjgLZSpo4xN8P9jsyHcb8BC1TfRctZ33/WZkbj1f+fXTfObPmxO/O46FrD3j95jtbXQWX8G165pU8okZoH2x9ha9jizWvj+ODeFwcBKyuBb8SmQOrMAbtSD1vJz5dzEjDqsM2sIIc/1AvivhfEvnaOhr7LsqVjvON+z7VAYxPvt8loKXmXp/gqiWvLu3LB4Yma/rAJfoAH6qAQXlFv1T2A4msr7JwPvFPntP4DtDN5YZ6SPsOeG70dCC94r4K22E9k778P0uLHREoZ9qJO4p9MAGOTcpQ8eYA5ZJ30sr1f+wEkIIIYQQQgghhBBCCCGEECdFP1gJIYQQQgghhBBCCCGEEEKIk6IfrIQQQgghhBBCCCGEEEIIIcRJ0Q9WQgghhBBCCCGEEEIIIYQQ4qQc1dCeNV4OajsipRv8LaVjFJEaSNh6KqVD2Z4/JmF+MJBMM8lulvrzlqQKUZrXk58FJ3jOCeRzg8XnLoIAkYiMB5TIEqMvCpHhuVMiWEtALjpE96t1HUjYYhFDPWSSxucsSyJKPCL42vHdmJFnIw0qh3dY5LFMC69nAyLzIGg2swrqrE3jy+hAiJcR+WTV+HOv2nitGUhmxwquTVyBA0jpcxTVmlkBDQFF9mZmae6foYAXk5N+X2f+xGsi/UMnYkEE6iiDzJg9kFz/mHz+fz93259+/fNQpvnc12FN3gW2sWET2+nt514QfXHj5b5VHYWo2G2YsxydrWQ4sNU7Xr76B3/q94Uy1594ge6Lb71w23fP43M3m8Zt73dMEuzrIrX4nOVY+x0dSILHKJRFv3Z3kBSXtFP0txOJ8dsACuyZIH6A+WPoiTgZz5PEBjNCf97BILXr47X3MOdlRA4fjiLz5IuNv9ZnL6MA/cm1b2frtRdRo4zdzOz21rehs1Vsh793eAR7yJgK8UoKT4X1a2Y2QpmBPHcPIld2ngTaJovBJnLuYxJk1cyfDvEdxlNmUa5MwjmboEwC4zBKnM3MUkNJMelHQbxLRLwTvq94HhxKcKym7xjnUhJ+TriTzqMgUQ/xOxnnUBTM/h4PHpNJlPHM5PXSfcekR4lzH2PAEcdP1uGgXWIbfL0Pt3FOvF+2zNppkDSzro9FDigzolSdtMFwEGuCCc5ZpAjszXGMYw0Fn4kuRkNDJde+v8xf/vP/WTz3Ww6vMhgPaDuAObyA9UIR1+p57vehiN3MbIA1WUpijqqC+Zg8BMYz242PDWYzH+eameVnK7ddVvHay6U/br2M58kg+B5hrOz6NhyDbTdh4vri/jkLX9U8qUOZ7LRLfjMzG2DuatjaFsr0Y2xTIwwmGI+amWWw3p0m/15H8l2pLny9LZekPVe+zGIR63q18rFkTr4CTuYffhj9/NK2PmZ9XcYf0w8xeNo3fs01n81DmWru22+W+/pka8QUBvm8iHU+qyD2JeNl1/tnqKq3oGECGEcb65fQfqoqrkHrur63TA7Pn6b+vD1+THl9g7AZx4QcRoUCF8RmVmb+WnlOJml4hwls4/huFudsNp7jPDBi8GtmOXxrwu/FeRqvXeCyAHeYWQqxLQ1NoD/25INsSoOl09GFdUn8FjeQBVcLfXLbx7FnP/nnx/kuy2M959C+WFARYmhSBr/LjOw8sG/CtQpbY8Rd95637+Oktd/7ub3Z79x228S5H2OeCYNqMzNYg4S6er3XbaXk+xQ993dB/8NKCCGEEEIIIYQQQgghhBBCnBT9YCWEEEIIIYQQQgghhBBCCCFOin6wEkIIIYQQQgghhBBCCCGEECflqA6rtvC5CncH+G8mkgs6pHC1eKIBbEkdeH46zF9p0VuTlySnaw73l8f7Q49ISnL0gxrFejimJs6hEZw+UxpzT2ajz6VNf5HE+0EnA0tL2/r66lC+ZGZd5+uY+cfQRZAX8Q4zlHUdGcxxW5KcyQPkTG6CP8FsGPyz9UTogPlPC8j325M8tJ1hTnWSNxzyZo8kI+oErQO9CGbRh5FM6EgjeUshDy05rW0nfIZ4f2Xp981n4AYi+VAzzIFLEsFifnDmwUEXB6vjEfvNkXn19Wu33b6I4+DcfI7ws9lZKFPUkJcd3E5mZndP/Fhz81s+j3BVx/F0fgm5rMlsg/m40dFiZlbAMLx6GPOy13PfNs4v/XOvn0eX0O1L7wra3MbcyOtbXxfNJr7zsYG2jHl7ydiQZ36cTkgfaaDv9QOZ5zAHNGnv/8HPfT3uPDLBQUHK3EL977axrrsOfGtjdDntwMX39LnP2fzJ57F99yvffi6q2N8XkBf75lW8v2998sxvf/oylHlx7dti2/r76ds4r68W/jlJ2voQv6BvwcwsppOHvh9PG1wOu5a8FwwhmFcUhGtMt/Y9pLP+QpiwQzG/DFQic66kWIZNRKEM1g+pQ/T1sPuDvkb9QeSoeLE3H8TdTrDzkD+JO+AZDsvojqe4309FXwu6Ww55ziODrreRdVwMhcj8m8ILwpjQzCy7p7WwNRrOZ+jMMTvMYYXtm3lHBhg0MvQFkDElQ9fUAe0r3O/rO4Tz3D/GYbscWN3ACx2Im2AER8xIfCIn11gc4DILy1G6noFt4rpAH/II7aLr4rxagKMlL2MnubvxcWJJvgsswBtVo9PKzF698I7ZAeK5nnjoMOar6njtApzPVU08tSCJGqDt4NrdLPoxPn/2lJTxdfzwwYNQpgJXTreNrtinT6N/99gE8yMJpjuIYTritsE2Tl2dOPThep36XnAMIC5W8PC+eM7emX/XDy6vQpm88O33du0dwU9JW7i78/0E3Slmca1dV9G3VhTgTUJ3EVt3w3eIjPjCC/C/sXEGx2LmhPlbf/1vx+sfkaL07wbnP7PoT1osYj0vF95DXZI1fKx7X4dTS9ynGb4LEngcEOjH+IDMb1xQ+bsvRPbBNwfimsK2QZcBcJ4C5p+cuLv6FL+fke9Kmb9YR9op6oIm4mUOAeCR+Vf+1V9027smzjENzDsN6W8NjHvNGM+DXtx57uecgvgr0ZuWEy8uOtqYnwpjExaH4XiOcwRfox0gcD1gvEJvYAPbLO4Y4Fod+faE12IuKnR1kWktxLFvQv/DSgghhBBCCCGEEEIIIYQQQpwU/WAlhBBCCCGEEEIIIYQQQgghTop+sBJCCCGEEEIIIYQQQgghhBAnRT9YCSGEEEIIIYQQQgghhBBCiJNCbHhfICDI2xKpZQMCsAUT+sLPbCkx1o8gaus6fx6UZ5qZ5bkvMyvZteFaRRSh9SBmQwmwmdnYvln6mwbBplkG5r+OCAWxukZSN1h/2YTNIErQBti366I4tQXBWjER+Svcc5pnoUyZR7HsMRkHqI8s1ge6EpMuPkdqfl/aR/El/macZnv499gOBhC95gm7Nrbv2JZbaCz5EPtEiQJZEJ72Sbw/FCB2HRP2ofgy3l8NAuTCexStIeLlbYt25njeEjrAaLH+sGtlKB81Ln88JsON315Mi1AmhT7YEznnCE2ubWO9Nol/1tXHvv+fPYxtu6x93WeL+C7wvU/Ebjqlfl9ekrG7BJnvcunv73G8v8vbc7e9foV9z+z2xc5tv3hyG8psXni58HgHz9DE9m8jjA1ZbIMoseyoPR7Er7M45g7Nqc3rUX3bkUd5ce3b1Ibc9zD6uWEgMcT1nW+rm7sX/tpEFPxo7s97TuTm5eTf0X57F8psNr59NGFuNVuB5DpPffsoSB/44OGF2/7w/cehTIFzKXntI8wDPVxrT97Lq60fD16um1BmCxbgMSEi43gzpMxp2+pkGJdFshCTklIgrZ1IHJvBcRmZA++F2aAPkPWmKP1l4y7sShMcq8n9wr6MCKNRJoznNTNL0vviA3IMXodJusOOA+qPCZHpccfjAB85gbXTN69DvsvV/TFUBg3tiwiZx7AvXhtPnZC1CbaVAdZoWUZiHrA/x3jZzGDtxKZf7H+0TwATrAeZdLpvQUa+b0OZAY5j7+7U7XSEtjKS+8GhJzlgLGLVjKE+touMxFg5yNjD+t7M+tHPz2kfz5PADaXZ/e2gLPx5soKMaRm005Sslysf8xVlGcpkqX/OfeNj3Y7E/G3r5/nrl9fx2rm/9sXFeShTQ/zeNLtQ5uWLZ2HfscE2NpLvNgOMG6y/YwwxkoGjhQB4s/N1fbuJdVTO/HvFNmdmdnvz0m2/fPU8lBkGP5YsZnUoU5awjoBrdR1pL7DOGchaE6uCrXvywo/FOB4M5NvYAH00SeO1sZ8kKYlRoUrbNo67t+sY9x+TDD4+FVlc8xXw/mZ1fMe4LyXjDw7OCYw/UxXnTfzG0PVkTIX5jTQV67GvjeT7AbSfEd87myegX090Yj8khvZgPM9iihTil4E89wA7cawwMxtwvCbfwhL6XMcDn2O7j2Pa3dav+ddtLNPhO83jSy3hW2GawTdSMs4YtMue1TOMc7h2MTObIPBg39jwNwF87yxaiOsZ0o/gGbo+fpNs+xbK+LGSt39PjNXJ/Ejmy2mE9k4/ShzeTvU/rIQQQgghhBBCCCGEEEIIIcRJ0Q9WQgghhBBCCCGEEEIIIYQQ4qToByshhBBCCCGEEEIIIYQQQghxUo7qsMJcvg3xy2wht+nDJOZnNfO5fNGvZGbWQJLIqYFHRU+RmS3n/ph6HnMrhlz/RcwZmeW+TD/F/LEpeH3qAfLJkrzrEzxnStxFE3EGhDIp5D4Hd1FKcoi3qc+DuSO5ffH9DmnMNZwO/p5nM+KjOa3CKjiNNmN8jhySHSfEVdJBjvmMvBqs6y7k6SUeMHBYDWl070wF5P+dSK5heM0dcca0mc+tvUjAIdPHtr0bfF7aMaaltbKFfNJkKErPfd9KIQc1y6vawL56io0phdzIFck3X0D/S4jHbCJ5g49JAnVYkLzd2JzQe2BmBvoZ24/kuUbf328+8y/18nFsg7P53G3nLKfzym+z4QsdJ+iPMyP53KEupjK2r3Ll+/n8Krbl5WPvBTu7jJ6wp9/yeeO7V/7f18/iWNmvYV8f7y8HB0NB0jAbuBhzUjm79rSuNbNo4nu1jmWe3fo6ud3HdpjPfIOpx1hv+863zd3Wn/fzZ7E+tuCiXJQkJziMGw1xWJ2d+3f21S9/GMp88J73PCzBlTknObov5/69Xs5iYyiC9ycUCdoofMptbKr28s737ec3m1DmDjxXCcmZb+gbo/qgE7uBIG5ED4qZhT/zYt6tkM6bzRUpuhrgxKQuQow1EJ9Djy4JEsfCPEn1PBjjwJjKHBoJOjlJXIRPlZGBLQMfWwJzNLrYXl8b7vcAFw5z6mBudszF/3rfaef+AHMDBafCAd4vcupw1PfhesFtM7P+gDrMMDY7xMsAt8OunefoOIiDZRb2EYdG8uZ+NCUkboT66onjtW183L0nDiuMf5kv7tSgQ2sg42A2scAGz4M77ndEofeuKOJaCh1WrC2jFyKM02bWQYzFxtysQCev/47BPLno5mGewxxiW3wmMwv1VYB7ivm90BkzknFwgvEen9HMLMuxjmMbGMka++jAfMbmBpz8E+LpjnM0c8+ie8T/c9vFGHVARziZN9Ef3eyJa3zn4+OeeE8KWGvPZn4tVxTRk4buLtYHGuwnxAM9Qh23UDldT753mHcWZ0XsSwW2TfL9DL1y7S76Wm/vYvx7TGIMQzz1uE3GLBwfqYsSJlOsMRa7jZVvG00b+zY68xp0j5tZajDukjm6hu9GGItPCRmH0S0fSkRPLbt2Pr55fqkKNs75bXT8mJm16MAj7q4BY1TiTcqIj/GoTPfHOV3n45qWjEUNfD3I0zjmVhnMrbB+yElfH9FZRTyOOHYzd+aAMQ4Z73EfOlTJ7cX1FYlNMAYcSP2hs6oHByB6Rs2im5G5UPEZ+j6+X5zXU+q7PXwt9fZFuEIIIYQQQgghhBBCCCGEEOJHCv1gJYQQQgghhBBCCCGEEEIIIU6KfrASQgghhBBCCCGEEEIIIYQQJ0U/WAkhhBBCCCGEEEIIIYQQQoiTQuycXxwliOWTKf5etr0Fidj7RDIKTrM9Eddd73yhbYsy6Hh/j5YgzauJPC31wsqaiJ2zFKVmkTsQ/7W5l8/NiHg9NX9/I/m5ESWDCSmUwB1NKF8kcmGUA6LI7fX9oagtngcFb7O8imWSKPQ8JmPuxXXEeWjonx2mWB93Wy/sXMzieVaVl5mi7HEgdYhN47olMsoS+1q0+lWDL9PtiMy0hbaxhL5G7m+7BaHmJvaReu/vuc7j/a3eBakfSCz3XRSijnO/r0/qUGaCPpFksYdOOECQNnBqyXXX3S/3HdDyidsElIKbmfXwDtfPfD0/++ZNPM/k+9HVfhHKLN/zfb1YkHEPmkZKqj2B99UPIOrM41SXoIOXzIb53N9ffRYL1Qs/Lu+e+2s/q2LdXH/mZcj9lsjIodElKAm1KMEdiEAzJXPUsdnD8PjZ8/i8n1/7OfDlOorm+9z3ZybGHqB/54UXMndDHGvu4Dy3RBScQbwyEtHtAsTOP/EHHoUy75z586ygPbPZr4JuMUW3qpXwWB3px9hgcBr/rW8+C4d8/O21216vd6HMduvb5qwm78VQNBvluemJ/4aqaX2bY5L7DNpXRoTM2A2Z9HpKfB8IcTXGbiUAACAASURBVAYZqocB4rCWSIr3/hnGnkhtYd5O2HNmvrGgBDglA3GKdUEGVbxWRuZ+PCw0ZdK2ExjnqEMcXwwphOL6iUjN2b5jgu+G2aDDHhLDBLEzKXTf9EGFzCMKmWMb7GCOZu9iGHx7GjISm0Dck2Ugayd1k2XQBrE+LfZ9FkPgcdg/2bVHKNOTuWbf+PiqJf0c6zjDQMnoKz8qWB8kPCH9jYyVYb0Vz4NrJxxz2TvGcZCta5s9rCm62JbXm43bruq42MsLf/3ZDNcmLJbx15qG+EYHkJaP5HsItsPR7hem4z7WBvH90mER9uV5jHDyPMYCxwbvYZpi/InxCXtcXF+ysRnbM253ZC3XQrsrSxI/wfw7kheC4wabJ2Ns68/LxnPsJ7tdjBPxfvqOzL8QOw7QDvshtsPE/P3UVfyuVBa+3YW1sZkN8Fz9GPtF18V9xwTjTfa9DvfReeC+RmhmoYXDWJMlcUwtC39/BZk3MXxrcIFoZg3Mi2xsXtT+nVawCErJYiotof5ofODPk5M4NoNvrdhUyCdBM6wvspDDfp6T+LhrIO4gHykn8lzHZMJvMGS9UJe+n5KluU1jHIeREMXeH9Yatm0W5+JnwJGsOwboNzgfvz7O78NxBmMXM4vfVtl6HmIGdpokw7kfTsuDMgeOwWZx7sdnMjNLwvxDZswDvkn+I/Q/rIQQQgghhBBCCCGEEEIIIcRJ0Q9WQgghhBBCCCGEEEIIIYQQ4qToByshhBBCCCGEEEIIIYQQQghxUo7qsCoKyJ1L8i3eebWHffZ5zG+4nPu8n5t9LPPqpd/eQ07es8uYO/TqHXQskBz95vNOF8QNlJvP3ZuSak52fl9mkCOS+XFGn5A1JXmOM0g+OTHhS6h4yHHJci6jN4zkZ03huJzk224xB/0s5hrOTpzPegZ1RnQhlsJz7Ehe4/2tz+k8T2Ne87aGPKDQDnLSdtLJ76tIDlLMl97nJP84OKFYLuT2id9uKn9edH6YmfUv/P3sb2IbLDFh7Lvx/vJz3+h28CbSNLb/CtpcPcb+OQ6+fbHcyAN46GqL7bSw07bT3eQHy4nURwk5nhOS63gIecRJGXjN6xe+bY8kz/DdnXc37deXocyj3bnbrq9ITuyFbz/zq1jvee3vuarA4UbGtA5z56YxB2+RwTidx7ZcfNl76JaX/rxpSfIew7U2z0kbRB9hT0aiBjwWxIBUF6f3A7y89XXw9GX05V3f+Tq43RGHQAV1wFI/Y551eGcD8wlhrup42pAfumvi/TXgL+jJDWJYkcFYWJL7yzBP9gHpyVnGa0wzvYE6/+yz5+GYZ597P8duF92Bee7nth7dJWY2QKxUEk9nRrxWx2QLLpKUuJ0K8JSxHPOYA5/6U+ANYZ5z5hLEXOLNPo4Je3g/I4sTIcZhz4BOqDQ4cogfFb0xZLw0qFNWx9htkpCr/f587qwHoHuKeR/R3TKga8l4nR4T9Idh7M3K5KQNJlBmIu8Uc9wnh3gwoZ6ZVwddTuhWMYvPgMeYmfX47An2q/vbAWtP6LCqiBelrmE9CHMtdVjBc45k7dCAL6jv41wT9AApWSuc2LMa/GbsXQS/EjsPjBls/gsOKzyG+Zz9vpaMp+jiYd6W2zvveZzPl6EMtpUJPTMkfkcfRk/6EZZhbp7gsILxi3rU4LlZP9rAc++3MTaYgc+L+aqY1+rYFHBfWUJcSdAOR+JbC12erUHBudTBumzHYktYay+W0c+c4/hDvHahdZB+MYAkrmvAH01iwKbBMSu21Rz2dR1Z00x+nIUlmPXkm0Pb+X1z4q7GOm/JebbY5sl3Loydjg36uZhfBtsgunjMLPio2PcfHGfxyRMyHhXQl8uSfePzdc9cYVtoY9i+zOJ7X8L3jgX5bpPCtzEch83MJogHcuYIhYZZgAsdYwEzM/jkZh1xuGEsnpMYGr1EuCYxY/H6ccG4virjGB++T3ekb/X+PC1+K7f46WbocH4j3xdhXGZ9JGjeyBwYYtsDXHAJbKckpkgOcMxh3J/hYGlmBbgOU3QTH7CWYZ5a3Mf8WVinbOz8XlRr+h9WQgghhBBCCCGEEEIIIYQQ4qToByshhBBCCCGEEEIIIYQQQghxUvSDlRBCCCGEEEIIIYQQQgghhDgpR3VYjXPI9biPeRH3kKP804+j6yKvMad6/N2tBWfVau4f9b13Yx7M+QITtsb8p5jDmOU2rXJ/7iqJeV6zxN9PC16dimXyTny+VqKjsRLqAvPPm5lNo7/WBK6UfiL5kzHXcM9ykft9PckLX0J+1kVNmmByWj8AChSI3sEGeLaC+AFWlz6PMnPZ9JATdTLIq0q6aIt+ANJWRrhWNyd5zeE1t8ThM37q2/L62ucVLllOUkhvXQ+xbobHvlDyYaybNvP9bzEu3PYKfWhm1hTem9Rl8bkvoe2OLckNC+8ho16Zow6fgbb0vpWqJP6nGnKaE3Hg/tr37WEbigQ3ybD329sXLB+4v7+O5BG+u4Hc/8RPVV/4er58bx7KXD72bWO2At9fxXLnoqOFeCwynGtILmt/aUtLf60Li/c7wLVezWKlj+br5m4d58IRxvuS5DBOi9P7Ab79qc8N/+T5JpRZN75OWiJqwhz4zPuQonMFHQ8D8fmFPOYkDzXM40NCE9y7TTZH4z50RpKzBgYy5mMcxFKYYxNPIRf6chFz/xflDvbEeaKEeZylIsfDWKpvooQ4Knd3d/eWwZzyzP+EvpuS5G/Pc19n0ddD/EoQh7Usrz+4GZh7JFxrIvn20a0GbQU9QN85M9nnwZB5ojEqloEdJLbEMiO5vwHjLdoIcfuA5PZHBt9fQqQ+uA+PMTNLYbw6xGGFOfCZSxT9CSmJLdFxQJpp8D31xM+DDoFhePM2Owa9h2ZmGdTNYh7n8XhecBOQOg9+L+J6QW8aewZs3iy2O7HCKvQv6kKAbdKc7j3GjDlYIIbPiUsavZTEqdOCT4h1/e3WxzNNGx0/Ffiaqzm4SrL4vaGHdrDbxRgQ/X7M6xldatj3YqXju2J1s177GHW9iXHd2bn31KYkRs3eAs9qhvM4k2uEeYeMfRN+gyFjAKzrsf67ITayPczrbUfGVGjjeUXqNYy7xJUJ99N0vj13xLuHbYzFPDh3tF3sJ33v+0Fe+PtrmtgHthvfDmc18eWU8EzkPLutX4elxFNdVzFGPiYYN6Jn2cwsDYMAtfK+Yes750EnKbR/5mhMoR/VNfE+l74Ok4ysyUbfNna7WGaEtRx6f2riz4qC1Pv7OX4jfX0WXG9hTEbccKh0JJcu4DtOUcb3i9968pLU8ffgBvoiQF8RfkN6vRN8SlSEBJ4m4kvHM0/oaGSeethm4yA6q9haCo9jvla8nxCpML8m1AVbbqGvEt1dZvEbcll6p2Tbkph6QL8dWTugP4s8Qwrfz3KyTsm+h/83pf9hJYQQQgghhBBCCCGEEEIIIU6KfrASQgghhBBCCCGEEEIIIYQQJ0U/WAkhhBBCCCGEEEIIIYQQQoiToh+shBBCCCGEEEIIIYQQQgghxEmJNrcvkNncS/T2TZTYJr2XHI55lDKO5qVrzCl/ufQ7z+Ze9nV1FmV8KISciCg4AaFmUkRhWQZS7p7IcINDeg/PvYjPjRK2jNzfaEwy+Obz4BMMU5Tabff+fpgoeMxA1IaGdzNbgGxxVcxCmYyZCI8I1sdILMANGPCqIorXi5V/p7yzQZuD7XyK522h/bPmZaV/F+MyvtNx7e9v0cWOtEn9e193XkpqpO8Vc3/eZR1vsH7k99XL+Jw2Qj8C8SUK1M3Mqty3/yAkNrMRXkTZxd/tMxTnEsl7O0SR4zF59ye8zHi5jH3pYnXmtvttfBfPvnXjtm+exLGnXYN8Ff7WYRriefutf183T+N5NzvfnoqnsZ7nD/0Le3kTG92DGz+XPHjP183iYhmOqea+raDs1CyKJVPSiQccH0AsOX8Uxb1p4d9LXsYyKNncb2N724E6NIvD8kES8y+ab/z2C7f97RexLaz3IKOf2N/T+DIZ6d916eu/SHyltN0uHINyVSvii0bBaUpEvAPMi6+u4wu5rECqO8e+QyTYsJ1nROiLZYjAFsfDBYjfP/rqu+GY5zAvfPPZNpRpof4SIlcNEMktk9oek+vr6wNKgUgWZe1mtlwu3PZisQhlChDNpyApHkfSvkB23ndRRI1CdHIay7L7Zcc5zL/D5FtYamTOBlgrCNc6pKngNhMkQylSJLR/6tuGrkVF0CfmkHvCOmJ1hudhYuwcLjXBMQNpXznKxdn94SOQMWOEk+M7NjODZmlDD8LtgaxVQIw9MaM1wM6D+3LobPQ1hffCytyzbaS901o+7d+k4rzKHhXvMCEDAj7rAW72MMYVJVnzp77MOMbxdECJOomxehhzwzFmdn3n55Yih/XXIn4PweBtIGuOrvWx1ERuEKXpfe/Xgynpe3Xt1xNszOk7f63dNsZWbeevVZL3wPYdGxz6MjKv9y3W7QFzIIvDYK4PYyH7ZASFBjJwZBC3llVcKyUQO7JYbZxwrQ3rjCzGx4u5j3EKUn8YK83reH9ljrGJv3bfxrXD7Y1fw5Ykfl+tVm57GGJfT2AMzbP4DLNljOWOC87Z8R4nnJRHMg/gt8zvIw5jh+CaucjjtQusVzIxYN2n5HtiCa+5rnBNH9fVOL8kZB034T7y/SeDPlyWfrvt43nTnW9zLN7COakgbbmq/HMlLWvLpyXEauRDZQrzUp7G91XCd+6RzG8TtI0kjI2sgfn7YfHxCOPBwL4nwj5cJ5mZDaOftycsk7Cvw/fH7/gNlHyWtx5j6AHut4vttIN1Zfg+YmYJfKcnXSS07zyNY1VyQOz9j9D/sBJCCCGEEEIIIYQQQgghhBAnRT9YCSGEEEIIIYQQQgghhBBCiJOiH6yEEEIIIYQQQgghhBBCCCHESTmuwwpyRu7ymLsw6X0O0rSoQ5mrC8iDO495nQtwCi0gv2hFciZPGbidSM7UfICcjCT/aQW1mrNsopD/FNNyFlPM5TlCLs9siq8Pc1Uz/1JIz4r5rUlS+jU4rGhOS8jDmRMHyQJyypYFy1d+YukK3BJzqaSYj5X5VqCKtiT/aQ7tYB6cArEu8gFyPJPfnVtwq6V1vHafQ6ProwNpVvp8zdkV5H1dkdy50M8Xs/iO50to3yS3aQs5W6F7Wo73//pEfos4wDLImZqT3LA55F5lvqw2jc9+TH7yn/yy264XJP/vzPfJ9lV8jrSCXLnjbShzPYLDroF2SuROKeQ5n4gbr2392N3uYpn+DuYNMj68Al/W81vvrHrvw3fCMQ8fP3TbZ+fRc4X5uCcmhMJ2WWLdxEOqc79zNcS+1zf+vWyuY+72/a1/VyPJy54msV0cm3/wyUu3/WIfK2U/QF5uUnHJ5NvLvIxjyzuXPmaYQyyw25N2CDmbB5Ine9v4a29J3vAXz72r6+/9P78Vyqxfen/Zu5f+3T++jO1wCWHQVU1cM9AQRzKu9b1/hiL3ffTBRYy3Hj30Prj5PMZOt+jGoy6q+/OKY37tY9M0sY8h6LthDqsS45ySuCTCXH9/TvUB3l9PkpazfUhq949r6GzLQ65xMpdAM2BulAgTSWFO+gNOg1CHFdY5i2P9Ns4BZmYn1qyG52Dx+AB+JZZbHx2AuCx5fS10XYBLl/mVsM4weDMzA5dKRhxRE7RBdASakTgMnB5pH8fpCR1WJKZAt0uaxXk0S9GzgQI05ri53/eXZuBqJA6S5BBf1onbafA+EudPaMtsXphwPGBjxptFQCmLJ2Af0ylg30LHiFn0X49kHtvtN24b/UJ5ef/fD+930R+534M3ivizMpiPKrj2xcUFuRqucWOJ4McgDW6EfWwurGYx/j02OK4V5H104Ozqx/jtKbqlWFt98w7mnWzAn9X28dpViQ6rGM8FfyUZm4u6gG3/zhbE44ROn0Ud3yn6jBLiYc/DUtLXZ9fHhrjd3LntNX6EM7P5zMetsyK2wxzWsUVOHOvJqX1rMGaREjimkiEhHJjGiidDAM5d5NsYOtLI+0KXKAmhLYM2NytjW14t/Ls4A493NWPfJWC+OSC4ZO6dPPf3h9NLReo8L8ANtIvrjQG/v5Lbw/idKMS/ixzzeIRPpMyhCoXoq0DdEymDa12MfXvSAdARHL1XxBNK6hnLMMdWb2++n5zcX4jf0zje43qZuVgxfsEYeiRxN64zO/KtA/ehO9bMLIVvwexbdYiZ34D+h5UQQgghhBBCCCGEEEIIIYQ4KfrBSgghhBBCCCGEEEIIIYQQQpwU/WAlhBBCCCGEEEIIIYQQQgghTop+sBJCCCGEEEIIIYQQQgghhBAnhVj2vjiW4BK/uyViUvSKjVF0m4C49WJFJKMglsyDaDJK9FAUnFGxq/+Nb0yjwD0tvHysJz7RbeGPWyf+mHMjzw1ibHp7KG8j0t8pQ4Gtf6Ym+tVstyc78dogn8uITLgG8WVSEBkeESAfFRAeo8DSzCzFyidSZJT8zogVOQ91dL9IOQ3vlNxf7ttXPotlhtLv69vYH8fBX6vKvfiyuCQiY2i6FZF5JrBvHInIGLbzyZfpifl8yLzYeCL9vIW+lZexvS1AHLonIsVT84f/8XO3/eI56UvwSndJfNbyHAStRRSBNqOXPeN4MF/EQe7BozO3XZyT+6u8MDqZR7Fk6U9j84vYnmZn/p2eXfr7ObtYxfNWKM9lf78BcwITRKYgtQQR80TGwbzy91uv4nlX7/lneHz7IJRZv4J55PM4To9EznxsXm79PeyNTIqZl9iWWWyrKxjH3r+M4uSf+MqV237n3Ndt30ODMrMWxKMNGVueX+/d9m/+5rdDmZcvr932N77+26HMqye+3T248HXx5fcuwzGPzv24++MfvhPKXC1B4k7mjhzaL05jFRFwz2vf32Z1rPMMvO+HTOFMwpvigHVkiiLGXQjeN0qmv7P3ez4PSt+ZMxl3ofCXlqIyYXxBpAye5vsIy9gzYDx1wBOQc7BrgeCX2JmxvfP4CsXwsRC+q2MzhDg/lul6Pzf0fZwbshzaO4mXUCaeH1A/GVjUsz6eN8t9gwrPZGYGYmwUUZtFkXmWowyayKpD/cW2kkG/Lss4NhSlHwvTzI+VuA79zsXc1pjGZ8IaZWOl9Xjc29dOUWyeZ7EOUxDa03EveOiJwB3mjhHe8ciE5PeONGYJzJlFWYcyS/i4weJE3NN3Ps5umjiv4hh2d/cqlNnt/Jonz+O1sS3PZr6dVgWZ0zOMjyN3a39tNg5h/bEyMRY/Pr/xd/622/4TP/0vhDI7uHcy9MW+S8aWMN5Aox+H2Fb3ez+ed10czxcLiKGn+F5TjPHImjCFNU1V+fPM5vG8s9r37cvzi1AG+8V2fRPK7Jtbt53Ddy8W1273vi/dXF+HMov5wm2XF/EZlrO5206z2Nd32/u/hX2RJDC34pxjZjbhPHlAkJXgRG9mCavs331tjB/MLIP7SZI4/2LIXFck7oDvPatFHCMuVn7tVNcYz5CgFdp2/J5mlsGcROsmfBvw2/jN+fU+iJ0O+ObAyuA9j2S+GYfTtlOcb6cp3iN+c8dtM9J0ydg4mm9jPbyLnoyVA75j8kEdx+6JTF4Y47AYFffFumHfXv0xfUri2FAXJJZM8Jsyrl/J9+MU16JsDXkAUKcjOc/X/+E3DjnT6/s6uKQQQgghhBBCCCGEEEIIIYQQXwD6wUoIIYQQQgghhBBCCCGEEEKcFP1gJYQQQgghhBBCCCGEEEIIIU7KUR1WF2c+P+z1XfQ/bcH/MQwxv+J+DTk+H8XcpjXk2J3Q3UASMKaQlZHl/04hL3ZKqjBL4X4mkley8WXSDnK+pzE37Ih5S434SjK4FsmPnoIDbOz9c7ctcc10mPeV5PKEbcy1a2a2qHwbmI0xRzC752OCj1ZYfA7MkcrynwbPFQFTBA/QBkeS/7pHlxnxraSQK36+ivmaO3C/7bYxN2zeQx7/tb+fcortv5xBXn9Sf5jblOUIrqCOs5D3m/VPf+2G+EV6yB9bk/y/6HVLs/geysOyuB6NvCC5fWFXtYx1VoA/qZn2ocx+8g6rFvLpnsHYbmb28KvexXP+AfEXLP0YVp7FOq2W/v4W5yR/Ooz3JXh2WK55TEdMmmDIuTv1xJ0AOYLTApwM+BLMDNJzG1E7WHnmb2j53iKUyb/pD9x9dhfKzCzW17HBuYvlPk/RM0n61wXk6H//Ks4fP/6Bz2v+lce+HvMk+rPwSi1Jff7pS58nv7uLdd1tfZnNLcqdzF72vn9t1r7M5g68EGb26gqcbHV87vP5I7dNUrMHhxXOtGGMNbNZ4TvKklw7S30/TsichHmwMff320Bd+3o+RAGD7dbMrATnA+b1Z/twDsRxxcxsGjH/OPFPYL0SLxiL3yLwvvD9sbzr6PciZ41OUObPmt64zbyih+wJu8jEgP4OVlcpcxkekb/1X/9Vt/0v/8K/FsrgPRbEUxPGYdKW0TsS2jurZixCzpsW93tbJojVWJkMnisHL+44xNz/6DdiZBCcUycF+ILQfcHaCfVRYRns56xuUuwj5DynVVhZCiMAdU+hDphMC9jfWf/HdpqBJzdnYzA01JzEJTm0ryIn8Se4by4vo4cyhWl9mny7LIhLAr1F2902lOk7X6Yk/XzCbxDQWBaL6Hg9v/AuUDYZ5i9f+tOS9o79iK2lMrLv1BQFccegjmugkkbYvn9mwnFuIHN2C3LxPjjs4hjPxz78xha/w+Gnm/ncf69arGIMncJTPXx8FcvgImuI8XG3Bxe6Yb+O7fvu1nuv7tr4bWw9876seRHXrAl870jJF9Lbm9gHjwp61IizboD5gnnUcCxm3zsTdC7h+0vjnDigt4bGn37frCTff2D8Xs3jd945OKvwsylRo4cxin1rzeDAgfTzCfpNkmBjYXPd/d+9kgT9WcRRhmXIewhj/pFpWj/OoJPs9U7fTnvif0I/FXVEwUo2n/w7ZW2wA7dpxtascFzPxmXwY7VdHE/xnrGrHeIaxTni9XnBDb6P494OvklE9yHpnxnG/GwuBM8Vi3Whff9/VVTrf1gJIYQQQgghhBBCCCGEEEKIk6IfrIQQQgghhBBCCCGEEEIIIcRJ0Q9WQgghhBBCCCGEEEIIIYQQ4qToByshhBBCCCGEEEIIIYQQQghxUohS8ItjtvCixovLKCfbtF4Qtt9G0d7tzv/O9uo6CsvqBchUwZ6IMjUzs9FQVBglZyMKytIotUwz/1wFEeKVrd839f4ZhoQI80Akl5DXlyQgugtadSK5BQFi2xEzWhDSEQkhiAqLMsoxqzlIeKlrjsj5jkgG9UpcfJbAPWZUzO3fRUveaQrnGaEOUX76+log8MvJDY6+rbQ1EYyeewnptCYy0bXvs8Odr5tsE69dnKNwPkotRzArt8S0PEC7nLD+ctKHQUKfWjzvrPf3MyOywAR+yy9Im/zv/4vf8Dv+81DkqGREjIjNkjkPM5BhtkTCO6a+HpdXvj09+ug8HPPoD5+57YuP4nhVgbu3isO9pSAXz0l7DwLIA8Tm1BYPTNj5iSTVoJ2mIwgrJybFvV+YbvBM6YLMc+e+AqcyltntmrDv2Fyc+/ay7mOdrHfeSp5MUSBqg39eFPOamS0rXwdLEHqzoAcl7h15zfval3nnPIqnXy5gnI1dyYoCxpLJv5/tPh50e+f7374lJ4ZXz0TBI8hfR2zPpH2X0N9m2GnNrIA+SvywB0G6ylFZncVxDMGxBrfNzLIM5/E4f2CZQ8Yw3EXLwFw6kTkQZc9U+nvPtcaBSYBh/k1JQ4BrMSH4OOEzTG/cJrdL5zrsJAkrhVVxgBD51DDRc/L/tncmr9qt6V2+V/u+u/ma06XKVFU0KQeOogOHKv4FIgYHEjGdiBCI6EAhDQqKQ0GjEmJTEkQDiYIjdSCB6NiBRLCtSipVp06dr93t26zOwckgz+/+5exdqXP2+spc12yt73lX8/TPs/Z3XzKvaYc8uNZj2cfWXZ6r1ZpHSRidG22ai5h5bC1rMK07ERGLyuPrXF46Hw6p76PpzOu5nJs7ofW96oG8ey15Xpl2nxtxThLabswaspL39v3FunU3S+bz8xjVubtQcaj5HJH7064p1yGtmSvc1cdFRAwy1o5Driu73b441vVNRMTbT58Wx4dj+Zv9oTyOiLi+viqPr67z80kbPjvJ43Mr+TVKu9psc7t/8rScv2t/EhGxG8q5yzia/ZDUZk1/P+ffrc3mJO9f1M2uOJ6G/Nypztc5b7XWL4u0ZbPpMI5lmQ3HPD/WfS03NznsBznO9U7nDNqNbTa5P9Lq0Zs0rfSXrnuMSfpmHbPNfEGr2G63S2mef/isOJ7HfJ2TzaPyumbv4uXVTTr3kOh4W5uxYZZ9QN3bjLjfnKpOdbm892z680XWHbPZa22a8ndbXRNFxFYqR2/qcoS+5z32AWS/o65cJSzf82jWW9OxbLO1PO/o/j/Iou3KrR3Kcaptcz80teV7j7Z8zR7yA3IpY1Vdm/FX96LNM49T2V8dZ7MvoPMD7TPMWjhfN99b1zjDmNPoWnxn+tNBxomu1zpo2tGs7cist+R5bm5y33R9U/aFt9I36lorImKSe7lxfZh0zMp5rEuDb3eU539YAQAAAAAAAAAAAAAAwKrwwQoAAAAAAAAAAAAAAABWhQ9WAAAAAAAAAAAAAAAAsCoP6rDqtmUszreebFOam30Zs/kDE8v3al/GYv/m8xw78ey8jK/4ztvi3jFB1Wf5fjctOV7lpF4r5y5SD9Hi7lU+8yjv6WI99hK7tzHCh1nisTonhMbt13i305hjhOprO++AxlTfbPLN200ZE1j9WR8937qxV4/qTjJR1ns5d9qa+N6TeFGqXKobqYdtW2a0jREsZdGb2OJ6p67L/oKzp+W5GxOb+fJ1eaXTWfxUv5nLqntSPmD/JL/Dpi3rQWP8BYPEUT3MWi7Z3vPVDgAAIABJREFUzTOHOBmcP04f2cS31Xv3Te6r3jScr2AQH914zO963JcZstvl9n8Ut+D2tMyPuc2/6TflvbpNvncvviFTTVMMfOdBGAcpd8kLjS/90YXKw3tpr5z3Svr3WcJdO42Exqh3cb41XLIJIxxtX7aj07OzlObGlOdD831feLs4fv9ljjF/c/2yOB7H3L4H8UfMU64w2hVryVcuprr0+c7X8ERi8n/+3ccpzYcflF7Am4uLlGaQGNLDVMa8rkxs/bP3PlMc18Ybo9MVGx9dpIiDVHqjiDF5bpxIGjt+zGlsDHPlfo3wU2O7ubuf16x3ngh1rDjnSvLdqNvJxCxvGi0L48WUMc9U94SL9a8x07XcRxPPXR2qrr+sdAJj9Vk61t/jN78r99R96tu6dfI+jGN2LGj7n6Y8Dkz3cTklP4KWTSatD5xKQq47GYeAeq1mU+fUDzDIXGA4uuuKf8I5INTJYuYQ2mY7mdc6v5dmhukaYq41jfEpp7mt81is7V+7+29idThxQ0Bq2ua6lax9O3FWtfdwCWndicg+nHnKeXop4/y1+KoiIh5Vpd9yPIrj2Lgrb8UDsr/J8yb1PzmXhPq4F5lMOodU3eicyPiKZY1fmXWw+thG430aDsbJuTLbrXH+yfypaU27VO+ec8vpb3Qedo8/JR8OuV/TOuR8v5V0bPub7K6+uSr34banpRft5CzP5XS+Ms15/q7DwjBk38utuGxb6edOTnI71jmFPn9ExKsX5friw288S2nOTss5fb/J7u+1bWutOI7mNj/RfI8KpHVOjyNM730PJ6FexaVptS9xc2j1Erm9VnUVqQfW9EeLeuPNAn2W9ct+n+vyUc7pvLsyzkSdd8xmj1mdQq5cdL9A/Xa/0+8ekgvZT7QKMhlj3F7JJPMat97adOW+ZFrHOoeVepqMB1b9kHvjDVRn1cH4znQMqOtynenWevdyBsuceZ7M2CquzEH28tyMX+upc7ip18o5thRte98q/A8rAAAAAAAAAAAAAAAAWBU+WAEAAAAAAAAAAAAAAMCq8MEKAAAAAAAAAAAAAAAAVuVBHVabRr6PnfUpzXe9VT7SMOTYoa8OZRzEy32Oi/j152XMxU1fpnliYvBWdRm3sTLRHTV29lzleLqjxjU2LollL3GOQ2NE5ryZmjJ+ZmXiQaaY6ZVLU8ae1PccBxNXVY4X4+XS2KLnfc6breaFkWxV04NWy4S+/cmSy0KDpE4uTvVcvltfOUFPmY8HcTD1LravBHrVGK8R2Q3WdPk6p4/K8jn/TEoSh/1lcbx98U55n4tcDy6+Xj7P5jQ/XyuhoUfzDrWURIqRPeZ7qy9unkzMVCmrwXhAQlxd9eqRq+/GhJkNCV8bu9c5n68vJS6vybO6Ktukxsl3f/kwL2WedcYh0PdlvWxM08+hq3Nb6zqJLa+xrI0LcZrvjuGtaYxyL/mEtMm6UNKjuMUONznR7nV57vrDHD/55nV5Tq8b8Tt5NB6WP/KHnhTH51/PBT0cyrjzL14b94i4WvbGfXArsf1HmeakMSiyg0k9jxERnfgLPvtO9oV933eX7orKxOi/vBJngLStp2/luPlf/AOfK+/97lspTavN1owdGhdb39J50m5uypO3u/xOg7pllly+9/EyON/DQ7I/SBszMdW1P2p1XhsRXSfOVOO/cV6r385iYvZrW3aOxrrWcTNfW6/scn2S8XaR+OjWr6nXMFeuZ5WAuUyW3yWJje2IyyT3qnDm1D3cDpo3a5McX5H9CNaXoD4qldWG8YktunbJqBdCXVQRuc9QD2VExCCen8E4BO5Ko/H4I7wzUtH1zGScFLWc24qT07VxrU469kREzOJcqIz/rxI3UHLDmXs9NOodqYykQtdOfgz4eFdJRPaUNl053+zMelSnRtZhdSvOyWPO55fix9ls8lrvsHtUHB8P5Th6tcu+y+fPPiyOb6+vU5rtplyrVKad6zPfXJdzkM74mg6HMk2/zX7HXryevRmPVIB9ZfxC11eX6dzaqO8zImIj/qTD4Lwi6kK/uz6HjonOsyp9yWT2aQaZv/Rt3rvQlnN9mevUyxcviuP32nLdf3Ka25KuCZcwLmTxl8338Cqqe7E1Krrs/8z5t9+Ve4nD3vicb8Vt2Oa86c7W9Vn/s1/4R8Xxj/zgX05phqZcF1nPpGomrWfy48/UZuXfSj88G8/bIGkmMy4sOgaaNLXub0oa/95lmtG04fFQ1sHdzviNDmV9amXOX5u7j+IcGifnTRJ/kFmUHUb1duY0i3GCPiS723L8cErZSvZRZzN8qKe7NX1ap2O/DOxalyKyy9rOwySNmx8M4r5St1OE2YPRtmfVsfdwxcpJN2Y14nFrOnkWMzfXNjGObt4tfYzpQKpPeAK6/k4WAAAAAAAAAAAAAAAA/J6GD1YAAAAAAAAAAAAAAACwKnywAgAAAAAAAAAAAAAAgFXhgxUAAAAAAAAAAAAAAACsilHcf5qU38e6LsvTHj0pRebvjcbUNpeyu9c3WTT2/LWI2uTen/tMFo2dnKvBzJjQ5vJ5ZiPsmzWNyeWjiLFvb8vrHPb5uqebUvZoVZ6SXU4er+WwSDUYjbByqVWAmK/aitxtaySttciDJ3OhX/p3/7E4/sV8q0+VkyjrZWfK71a8evvYpTRVUxZGX2WxbdWIxHIsb3Ycc/50Udb3fWRxo7aabZVNpUNTvufJ47OU5tFnSxnucCyPX73Kbfj8/fLc6SbLH5fvFbGqMTIOUabZRif/ntv9lQg11WUbETGKAHE63qY0KrleIosU3zSOx1xXDtKv3LzI8sSL5yKV3ueyaKJsy9VU5uHhtuyTIyIOVyJlHIysdlEpt0my1HemSQ5uFZsb+aOKecchp5klu5Y55432sYu02duLnDfXl+W5y5euXAY53qc0N8/LelmPuZ23LsMemO/5rrI97Y653/jgWVk/rm9uUprdoayrl/vc970WQe7VUPYTVZfLsLXjZImOA595J7/DSf/dxfHv/9xbKc1O2oqKZ0/Pczt5563T4vjxSe77ZPg1CtlIE4RZUh2MnPZmJwJik+eD1HntPyNyG1xsvVy3rv7sP/lbxfGP/fm/kdKI+zzaNr+rvkXX5XZZ6YX0PqYEF5kvVEaYGyKirmynqodOOFweT2N5QuXoERGTPE895TS1iIHrJueD5k1yFpt30vlW7STAOs8wIm8VLU/mOppmbWpt/BFRiVxZ8yciotZzaSCNmDWvq3I+N4eRNkt/oCLxiIijCKyHYx4Dj4fhY48jIo7Hso6pMHoxbUQF0Vq/IiKa1D6NRH3SvND8zP20XjX9JiK0+2xcdZO6PE1mnr1yPU3tzfVp8oja73x0nfJYpeoREU2j+wtln9tv8nhdi6z9OOWxbXco5137XU7z/OWL4ng2wvvXz8v13+72uji+uHqZf3P5uryuKeP33n2nOJ6mxynNJPPWw1jOQXb7vH7d78t1UdPnurw9Kd/J9UODtNmLi1cpzevX+dzatF1+37OTsg4d96bNyZiymKWj1vFaKrjphqOT+p2fLmKWfrY2f5Ouben6+iqlefZhmej0rCznd07fzTeXBzqaeeLtdVnnr3Z5jn8jdVHnjZttbsebk3J+/Nbb76Q0XXciz5fHkuEgY4kZOyrTDtakdmOMnnN7ejr3WXJdqReZS0p9asy+TSN9qpvHjlI3jlVeI6c5hFmft4Muesp7jWbupnMRV0+Hncw7bvPaO2Ru28oCsTF9YZ0afr5sLY2/M/3QspRtYJlyXT4ccp4+JI28nF2PytyxMXVwIx3LSWPW3V3ZP7X13X1lng+b8pK1VG3mHSlNbeqprBH1uHLzImmzZlqUpqRuLaXrrUaOXcFUOmZVZg4te6I6p46I0O5zMd9LvhX4H1YAAAAAAAAAAAAAAACwKnywAgAAAAAAAAAAAAAAgFXhgxUAAAAAAAAAAAAAAACsyoM6rDTudFXnWJRnmzK+4vxWjj5ZVWXM3bbLMUhvLstYiS8uyniLhyE7Bd5+XN6rP8nxiTUkv3NN3UhI4GU0ETT7MnDkN68llvaXczzI3/dO+Z7vfiZfdnui73V3QHCNn+nib9dyHROuMjm2Tk5NzPBU43xk0zVpJeLpVJl6IOeM+iOqpkwzmmDW41i2iXou7724YNYpnqiLq3p37PjNXJZP2+fuoH9apnk+l3HWN71xd12WmfHh+/m9z6fyXidP8zvst2Vc3jOJDTuaePOit4t5yW3vtpWY2Bc5zfGmvPfpefaPvWmMJlb6IKGXL5/n8nr1zbLDOly7C0m97MvyGne5Aexfl+Uz3BgHhHoD76G1cT2Ghj5epMkeD/mddldlGd9c5ZjP++vyHfa3uc7tr8vr7C/L4911/s0op5w37HAr3gGTf4Po16aD8bbM68dcP5Hj3jhomigLzYSzjlH6ustDHt+eXZaZ+97TclxqH+W83qpL0Plv5N4aCjoi4t0nrRxnn0TyB0leuLE1OzzcZWVMMvHlF3mHo8TJvtzl/Ly4kTYw5PEweTtN3qTXci/qzq3I8Zj7hFrio89GuqIxyt1raTz0dF0XNzy5d4xjQf0FJqb6fdw2KYU6rbSTjYhJ5o6VkUg2kl8ppnpkF0olnYE6VSNy7H/np0o+BVvf7h6TlpVda4r6EyIi2uQKM/5FycfF1LlUD+Uys8mLWRy9o3GADrKY2h/zOKmekaPxXI3ipFDX2mKXQNKXm8FG/UveFfLxDg29j6My3gFdK6f7RMQs5av+uAjvFVgT1250/Zm9V249k2mk/bficOs2uY3ob0wRRyvOy9YMbrX4rg/77MV9/eJ5cTyKj/M45LFGvW5ujVY35ZrfaQ2HUeao4jepr0s3cUTE85flWu9gLrw9LWd2ri+/uhRX10V2Jl1cXKdza/Mv/9XPpnN/+k/9xeK4bnKZaZ/auMmaesTVRWL6YW0DOpeLiJh0I6LK5dHUZX1xTraXLy6K47Pz0qU2mbFVm+iVcWNdvSqve/nqdUqj48D5qThdTV/Yyd7TY9eQq7LtXC75+Q5HWYO4onsDnMC/HedQVVf8bFyiqsNzfuZa8uw+Tp+20n447wMOm3I/Zd/ldnSUPkvLJiJiqco01Vjee4j8m53sBRxM/VfHVmXcgRtxS2378p16rbcRMdflddudmc9MUg4mj7VeDoPx2B/XXfc/eXJ+Zxrda67Mfmcnc9tNm+tTpxvLMuk7mvxZ9N7Oiyl1eWPqsj5zN5q+O3nJyj7Y+4zv9rvr2nMYjJdP3n2UNNbRK/nnHPBaVMl1G5EEji+ef5jTfAvwP6wAAAAAAAAAAAAAAABgVfhgBQAAAAAAAAAAAAAAAKvCBysAAAAAAAAAAAAAAABYFT5YAQAAAAAAAAAAAAAAwKpkW9+nSCMi3vuIJR+dnKY0XYjsrjNyx5NSNHZzVd771sjuPnxWHp+c5+95h0rlqllmuIg/sFEhXEQ0cuoogrXrm/yb676U2L39npEkSh4vakj+6O7FkbrSjDPOiItz3pyfloL5bX+S0qgotLJWy3UZRTA3qMg0IibJ5yo7GaNZRFgZXUojbvGYG6lP95BBb5ZcV1SevVS5nqokte+MELkqRZLL8rQ4btss6z2eieTvJiWJ198s6+Dudc7A+XH57lciyxx3uaI2B8kvUy5zW5483OY6uP2/5bX7d/b5Qm8YX/hClmz+2q+W8ueLb2a58dWrMs28z/kh7sQYRCQ83uZ6evOs/NHts1wY01imqcyYkOywpoMapR++eFlWutubLN3cy2/GY24jo4hep6O596E8N0n/Pw6mDYu4exlz2bWDDhK5XFoR5S5GWjoa0flDU+sjOEG8nKrq3F+q7/z1TR7Hv/68rOPvPinlt2cnWYbbyHXdxKgNFZEa8bT+xvxJULOoPLs8nkx5qax+iZx/+rvZjB3jXKZ5dVsef/DKzItel3L4q31ux0etz0Y07t4qnzLtf0Wm2Yie5bkrk8+aJg22EVGJGFzlvZWZu6kXuGldHuqt8/OprNcWxaJ17uOPI8LUSlPqi9bT/KtKBeA6Lthpo/7GpdGnM8+Xsubud1gblTpHRHp/12foudmkqXTwl/o+m7wYZcyeZiN9n8u+xonhk/zZvGbTaLuRdmXWKo1Irhsjru9FjN33Wbjdizy+buRe5oFtWWmaNK6bPkYGrc6Uw9r1VPu0ycjrW1kfN5HnQlVVnpvM/EH7NJW1O6/5MJZ1sD/N9eB7vvj58j5jvlBXlXXleMjzzeFwkOPy3pVOQiLirbfeKY7PHuf9kKdPyzVZZ+rpIHlTy70ur/K64PAbv1Ec99tnKU2/Ke+l5RQRcdiV7/365auUZr8/pHNvIq3UKfsn380iSVyi8twyy7FZuE732Jc4Svsa3dgqm0+V2Z+6uCzXhLf/48vF8dkjs7cj9xqnPJccj2W7GIZc7o3kzVbm6zo1iIgYpd7VfW4n1aYcX7rTnMdbmZtPc87jts/rkjXp+k0617dl3h/MunWR119ycaV1aiP9XOXm69LXNKZf03Gz2+T6NAxlWRxNnz/syn2Z6VbW4ub59kNZD2azn1BLW+vaXObbk/Lco0dnxXF/nt8pmnItdb0zew7Sbmadf0VEjDLnMYPbZpPrxUOy3Uo/49YhusZw/VWl87vMJHNHPR6GPB7PUp9aU8at1N1+a9Is5Tk3H05IkqbObeQ+8/dayt1dRvNiHMr6peNKRMQkaRZdL0ae2tZmnVR9wvNP/ocVAAAAAAAAAAAAAAAArAofrAAAAAAAAAAAAAAAAGBV+GAFAAAAAAAAAAAAAAAAq/KgDitV7SxLjrUcEuu860z88Shjg3atcdBsy9i4T7dlDMbbY46dq7FCz/ucPZPEKN/tdilNJZeeGhPbMcXllICyJs75+Xn5fH2fXRzqp5ptbHt1ZpTHgwmZquGST0zc3KePHhXHG5N/WpqfdIzLTwJ9otpETW0lHquNqywxR6cm17k6NM5r+e8af/Sj5ysTNaYZa+zl0SoOxENknCx1X557+0lZxl2ff7Pbiu9pl2NF315LjFkTI/VkU+bxoZcY3pHlWMtW/CJjrqfa9mbjGJrnMk93F9+Z3/Zf/vpFcfz86zl+/PFaYv9XJvayBMdtJH+Gy1wHn3257Bt3r76e0pw9lhjB5tZtWz7fYGKjD+KjOsrxzrgGq0Vdfqb+SxptrxERG+1zxXFgHjemSRwVs/FcTeJ2cG5BqcujCgkjQrUaazBKF7Df55fROOujyZNhKs+9vsnl+rUPS6/eu4/LcfLtxzkO9anMMzoTE1yHUhezWc85xVAr/W6KeW3ieM/aZxnPh7p2BjNuXUso7/dflvn31Q9Kd0FExIevynHrxugmRmkni4lXnl/rzXOuKM5bozH5nTNEf+ccOSnuvJSxc660MtfVsSwix0N391bfi8t39Qfpb5IHK0ybMO+gnh/n9Fm0H5Pj2tSv5ABzwqOkxnKuNc2Lu51ya/Mv/vWX0rkf/Qs/VhzPKq2IiGm52zWlk1t1EdgmW6l7yvSVsi5qulwWnfQrjRvMlo8vd43z7841xpfYi9NAfT0REZ34TLRNOz+b1l3nn9C6vBiXir73m9Z3RhiFl60rUl6u3eoQ6XwJ8rvU75mqM4t8uDX7DaePSh/O4voMGVedw0q9jjqmO49FK+vszcmZSSP7AKY/TW1WOsKdcUhdXsn6yvipNFPdmKBN32lvmnt43d4E+q7Mg42Z4B10sqvi1UhNN5WZ+i0jImrpH02XFQdxAl/dZDfZdlO2i36b95FuxQ10fV3OCy8vsjde/cOur9a5k3OudBvdExF/nZn7dlo3qzzn6TbiGJrydWZxdg9m/6U2fcSa9G1+j6N4yo7OHySbekbXmuZH6mOr7uGhdd35Zlvm89m5u4zstd7mvdb9ruxnD+IJXMycZ5a+b7vJDUk9x73ZYz45KfN4I/7Drsvlsp3L654bj9o0yv6ZKZdFPOxLbxpSu67D6iDeqOT3jDyOa510uDap3OW0+ujmZZl25tY6VNWmw9K+3E3D0nzlHuuvUA+0GVvVAe/mTifSv+sYPRzzBtXS6Bw1P56ecvZp2z98G7xZPS8AAAAAAAAAAAAAAAD8noMPVgAAAAAAAAAAAAAAALAqfLACAAAAAAAAAAAAAACAVeGDFQAAAAAAAAAAAAAAAKxKNhN+mizl7ZyQvBZzl/FVxtiXYrG+MzLcrrzX2JdyshMjXFQZqAp/IyL01OmpkWkfRRRshGpTK9I1kb+qaDIiohGJX2sEcJU8YG1UaFUtFr+qlK6NQ7b8qTT56dMsfz19JPLCzlxHntkkWZ1WZHeL+axbiRByNIkaEc6NkcV/RxGVdnLd2choJ7nuYqyMjXyLdpLyuhFJap2fb5rK3x1FWNmfZmFr15dtYjrLUr/mcSlkdHLqU2nDs9gN90/ST6JJMsOc5jCJPN7cu1HJuxGCx3/Np940vvbfnxXH++f5XftKpNJt7k8bkbiqFHy4znXn4liW8XCV+6v9Wfm7pjeSchGMjqOrp2V59a3UyzkLSFUga/2QatQ0Ukt1Yao31Eo4Z5Wq5zQqIJ1Mmsmd1HvF+kLrG3F6X+9zphxnGbOX3G8cJpFTm7+5eXlZ3uw3v3FRHL91auYLc9kG3j034+9GBcSZ++S0K+viGsnIHTFLdo1mXnSUOnWxy3n8jedlm/w/v17Ks7/yvojWI+LlZXmdYTEy30bFxW7QlGMjkbWNZUXOH+V5Ti3i8L7P9WmzKc/VRoyd8kPF6+Z5VPqr/XBEFubWZq6rnd1iKuUk5TOLlXs2ZZXGUvMSKl92Qt9Z560yHrt+uJJzemzP6XUjUjm4l7CS5DcMlSuPRjw9TmUf28xmPaNZn9KYfJZjU02jqcuC7/qcqGl0MM3XqaQCaRnXYfryuv3Y44iITuZBnZGzt9IX6Hi8LDnPF1l2N64BaFaYJpznEOuP85n7tMlP5jqNlEUnfW7b5jLWuVHf5zJWyfs45L5yrHRNbebZMiboO7jn6zblPLau81hTVfmZcyLNi/I3rv6P0gcvZq45T+V765gRkdeenRkv6/o742+nz87K8thsTH95W86xWt3UiohZ9gsqabu6ho6IqKUvnCPPj0fJ//1xn9K03UaOc+ey2ZZl1MiYfdjJhD4iKumcXbtu7tE36x7WOJT3HoZ8YW3ri6lPy6L1zo39+ixmLm4XiuuhY1BEnqO6/nKRRcU85nqq07la8qNtTP2Xelo3rs8vM/rMrMkq6X8q7WMjImQvs5ZN5WE0e2OSN4/O8x7W4zNpI2azutuU76DbJq5L67qy3z3ZnqQ0R2lai24oRES1yH7xnG82HdbdXD2OZf80mfo1yPgx6kI33HzO1eXy2pPsEY2T24sur7M13xE2Y1kPdP31W1cqjty6aJG1k7Y9Oz/WdZLZy9cxWef8Ebkv0PF3mnPeLINO+vPzpf7TrCHd+vTb4TtjlgAAAAAAAAAAAAAAAAD/38IHKwAAAAAAAAAAAAAAAFgVPlgBAAAAAAAAAAAAAADAqjyowyrFrzXxYRdxIcz13fFi1RUUEVFV5avVvfqz8qtrjH4Xv3aR5+mMZKs7lD4MF8966Mv4nuoZaFzc46qMy1mb0NVLdY84whI3uIoy5vJyyPd+tCljeX7Xe6cpzYmEgm2MA6yWfJ9N/N21+YV//EvF8Y/+xA+kNIuU+2LrivgBTKz6jTZBKTBz2ei0HTknitQDdTJ9dJ3yeZYlV6hJ4+Trdbr8Tl0jcdc7c92NxFRPKSIqCZx6lFjyfZf9Io+lUUzGG3Yr13EaC833ySX6DuDmmXiQbnNZzAd5WRMjXOu3xqBeTCzyRWORm7+POErxVO3d3pHJxGvWsMGT/KYxfgeNEeziEzfqnjHxuDX+fiNxe49j2b9GmJjLJnbzn/v5703nPgl++EsPX5d/7SuXxfHXXuQY+DcyBk5NdiVVvYyTZuw/zGWlev/lbXHc1y/Tb3bXZRl9/t0c1/xzcu6p8Vdu7uEhUt+a9vmT+TMibZK73K3Fy9vyuh+8yPXuK18tfV7/88tlXnzwOnsRriZ1izkXyD0cVhqD28m8ljdLanl6lmPMJ1eKiX3eJmeV85KJQ1LSqOspInLYcOdqkL7O+kHkcRbTjtpFnRkSL904TdTt5K5bafUxj6eewllj9uefpPmC9VzJsesJ08/uJ9l54xglz+o5t+1Jzs1zrsvzrGsTzTUzJqqfx7gutOCTrypyrH/n4qgr9XWIx9fUf3Wn1KlSZq+P8xvpvZal7HPH0Xje1LNq3lvz7yd/8odTmt8NP/0zP/SJXOe+aJtM3tDfSlVwj+mJ5k9EdkC1su5wjigV6Kl7MCJi1H7OuDXHvXpx8/NtT8v1StOVv3FtZLst5xx978aju908laywKnEotcZhNTXiLDTXrWVvo3UuZ3mvzUme132nrK568didnefyuLkt68cxV5fodBzX9brZFqkb9aTlSaAqTLxrsSyPzviZ1c0+iUeqM26ScSifx3kx1WmifXdERDXLGl4mv0fjv23EZfSlL/3dlObT458+4L0yzg2kc5bKrFsnmR9MxoWu69RK56xm3NR7Oa/OLH1o0+Z+4+ys7Nc221xXHg3nxfEg88bJOKx0uDnZmnWcDPVavyKyO2zRvTu3J6jzY9M8Z53z5CTJeeSWCupefGh+5T/8+we71/f/sT9eHA/S6ereYUSkdcfBeK62MvY393FYmXVRqofSjtLaJSLqtIeb76x+SOsilnc/at4Mzm0rfbnzTetyy/mqPuG1E//DCgAAAAAAAAAAAAAAAFaFD1YAAAAAAAAAAAAAAACwKnywAgAAAAAAAAAAAAAAgFXhgxUAAAAAAAAAAAAAAACsijPhfmr8w5/75Ye8XcFf+vE/Wxw7OegUasfMgrVaxIQqL42IqFoRtTkRaX1aHC+9ysmylL4RGaVznA0iB2wrc+9JfiiyexXuNCzCAAAEnUlEQVS0RkR89r13iuMn51mc2rQiCxyNUFNMbct2n9K8afzzf/Bv1n6Ej+WHfvwH0rn7qO5GqQdDZYR9tdblSo6ziHqpVSCb68FGJJsqVY/Iwvat3Kudc93eyL2ORiR6Io7BqjJibPndL//8wwkkP0kOV2UejblbieUgglYjC1V5Yp06H9PWpTud53zdo9RBJ8aexUxqJa5yrm/LutL0+bpZHZ+f78/83OfSOfjW+cE/+nZx/Fd+8SspzW4s62rVbVMa9e5Wc27flYjvb8eyIn71w+v0m5cvL4vj//W/83W/+N3vFsd/8AufTWkei6zaiVL1kVW4fZxzf3S1L3/0/vPXKc03X14Uxy9ujinN89dlXry6LtvN7ZTbyShziLrNfX7VloLkuc7v0CbReO6/f/Wvfn954q+vq2M/OclS9VoMx12X86Oupd81YttJJL/ap1ZGSJ7+xMxkT6XyZ1MW90EF0TouuP5yNtJfRYt9afLzVdr87vEKf/tv/rW7E31K/L2//zOr3ft35u5xcxFBtJMr6/xIy8+tQ1QmXpu6rG1Ex/mPrpNH6XSddG3pr4z4Wetuba9bnvvpn/qRlAa+RezC5Fvvn5zgW9cZ+dj8fa6Ucdf3KclmknZk/O27pVzHTqYd1VGumZNUvTbjqqx5lsnsW8gw7/pgTbPoXGvJ7bOtyrnAXJt5t44Jpq3p+LjZ5L0DXW+9scjrNW0uD62ai6kwtdT5SupqZ8bEupG9pybnWduVv2vNBLSRcmwbszaSvaZRfuP2vbTaufHmP/3Kv03n4NujMmvmpi/rU92bfRqpY3Vv6rJcuta5m+kTdMiezBptme/ud/tO+gnTtxzG8to6fzkcc9ub5Xk2ae81ok3tL6dZ5JzOX37m7/xU+g18Ovy3//KfH+Q+f/hP/Ml0TrcudV0XETFP2jlK23NzVD1lxvUqzY/v3hs7DuVk4HDMm4KDrFdnM0fT+bsb+z9p+B9WAAAAAAAAAAAAAAAAsCp8sAIAAAAAAAAAAAAAAIBV4YMVAAAAAAAAAAAAAAAArEqVY4QDAAAAAAAAAAAAAAAAPBz8DysAAAAAAAAAAAAAAABYFT5YAQAAAAAAAAAAAAAAwKrwwQoAAAAAAAAAAAAAAABWhQ9WAAAAAAAAAAAAAAAAsCp8sAIAAAAAAAAAAAAAAIBV4YMVAAAAAAAAAAAAAAAArAofrAAAAAAAAAAAAAAAAGBV+GAFAAAAAAAAAAAAAAAAq8IHKwAAAAAAAAAAAAAAAFgVPlgBAAAAAAAAAAAAAADAqvDBCgAAAAAAAAAAAAAAAFaFD1YAAAAAAAAAAAAAAACwKnywAgAAAAAAAAAAAAAAgFXhgxUAAAAAAAAAAAAAAACsCh+sAAAAAAAAAAAAAAAAYFX4YAUAAAAAAAAAAAAAAACrwgcrAAAAAAAAAAAAAAAAWBU+WAEAAAAAAAAAAAAAAMCq8MEKAAAAAAAAAAAAAAAAVoUPVgAAAAAAAAAAAAAAALAqfLACAAAAAAAAAAAAAACAVeGDFQAAAAAAAAAAAAAAAKwKH6wAAAAAAAAAAAAAAABgVf4f2lDSIpigqNMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2160x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Visualize some augmented images!\n",
    "# hint: you can create new datasets and loaders to accomplish this\n",
    "\n",
    "# Based on the visualizations, should we keep all the augmentations?\n",
    "\n",
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "])\n",
    "\n",
    "data_aug_vis = dset.SVHN('./data/',\n",
    "                         transform=tfs\n",
    "                         )\n",
    "\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i, (x, y) in enumerate(data_aug_vis):\n",
    "    if i == 10:\n",
    "        break\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2LrmsYHoguB"
   },
   "source": [
    "Все ли агментации одинаково полезны на этом наборе данных? Могут ли быть среди них те, которые собьют модель с толку?\n",
    "\n",
    "Выберите из них только корректные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T07:54:45.436870Z",
     "start_time": "2019-05-20T07:54:43.704703Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "evro9ksXGs9u"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "    transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43, 0.44, 0.47],\n",
    "                         std=[0.20, 0.20, 0.20])\n",
    "])\n",
    "\n",
    "# TODO create new instances of loaders with the augmentations you chose\n",
    "data_aug_train = dset.SVHN('./data/',\n",
    "                           transform=tfs\n",
    "                           )\n",
    "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size,\n",
    "                                               sampler=train_sampler, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler, num_workers=0)  # pin_memory=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T21:33:37.155199Z",
     "start_time": "2019-05-18T21:32:18.241967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 time 15.888985872268677\n",
      "epoch 1 time 15.673996448516846\n",
      "epoch 2 time 15.785985469818115\n",
      "epoch 3 time 15.747260808944702\n",
      "epoch 4 time 15.810038566589355\n",
      "summary time 78.9092493057251\n"
     ]
    }
   ],
   "source": [
    "dataloader_test(train_aug_loader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T21:35:13.861341Z",
     "start_time": "2019-05-18T21:33:37.157197Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PeO6Zw0DHqPR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.593767, Train accuracy: 0.818585, Val accuracy: 0.832162\n",
      "Average loss: 0.546778, Train accuracy: 0.834471, Val accuracy: 0.838578\n",
      "Average loss: 0.534573, Train accuracy: 0.838720, Val accuracy: 0.839601\n",
      "Average loss: 0.510066, Train accuracy: 0.846500, Val accuracy: 0.862467\n",
      "Average loss: 0.501522, Train accuracy: 0.848719, Val accuracy: 0.853457\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's train with augmentations!\n",
    "\n",
    "# Note we shouldn't use augmentations on validation\n",
    "\n",
    "loss_history, train_history, val_history = train_model(\n",
    "    nn_model, train_aug_loader, val_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0bcioK6JBDK"
   },
   "source": [
    "# LeNet\n",
    "Попробуем имплементировать классическую архитектуру сверточной нейронной сети, предложенную Яном ЛеКуном в 1998 году. В свое время она достигла впечатляющих результатов на MNIST, посмотрим как она справится с SVHN?\n",
    "Она описана в статье [\"Gradient Based Learning Applied to Document Recognition\"](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), попробуйте прочитать ключевые части и имплементировать предложенную архитетуру на PyTorch.\n",
    "\n",
    "Реализовывать слои и функцию ошибки LeNet, которых нет в PyTorch, **не нужно** - просто возьмите их размеры и переведите в уже известные нам Convolutional, Pooling и Fully Connected layers.\n",
    "\n",
    "Если в статье не очень понятно, можно просто погуглить LeNet и разобраться в деталях :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T21:35:13.874336Z",
     "start_time": "2019-05-18T21:35:13.863335Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ieEzZUglJAUB"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement LeNet-like architecture for SVHN task\n",
    "lenet_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 6, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(6, 16, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(16, 120, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    Flattener(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(84, 10),\n",
    "    nn.LogSoftmax(dim=-1)\n",
    ")\n",
    "\n",
    "lenet_model.type(torch.cuda.FloatTensor)\n",
    "lenet_model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.SGD(lenet_model.parameters(), lr=1e-1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T21:38:33.165197Z",
     "start_time": "2019-05-18T21:35:13.876340Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WMmaPfdeKk9H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.627626, Train accuracy: 0.437617, Val accuracy: 0.778991\n",
      "Average loss: 0.596999, Train accuracy: 0.822544, Val accuracy: 0.856051\n",
      "Average loss: 0.480291, Train accuracy: 0.855646, Val accuracy: 0.874684\n",
      "Average loss: 0.429099, Train accuracy: 0.872027, Val accuracy: 0.871818\n",
      "Average loss: 0.389770, Train accuracy: 0.882452, Val accuracy: 0.879599\n",
      "Average loss: 0.363545, Train accuracy: 0.890694, Val accuracy: 0.886219\n",
      "Average loss: 0.344985, Train accuracy: 0.895591, Val accuracy: 0.891885\n",
      "Average loss: 0.323041, Train accuracy: 0.901665, Val accuracy: 0.877892\n",
      "Average loss: 0.309723, Train accuracy: 0.907194, Val accuracy: 0.890861\n",
      "Average loss: 0.300170, Train accuracy: 0.908576, Val accuracy: 0.898710\n"
     ]
    }
   ],
   "source": [
    "# Let's train it!\n",
    "loss_history, train_history, val_history = train_model(\n",
    "    lenet_model, train_aug_loader, val_loader, loss, optimizer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_O9qiYySvuj"
   },
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T05:45:18.451931Z",
     "start_time": "2019-05-20T05:45:18.445932Z"
    }
   },
   "outputs": [],
   "source": [
    "# The key hyperparameters we're going to tune are learning speed, annealing rate and regularization\n",
    "# We also encourage you to try different optimizers as well\n",
    "\n",
    "Hyperparams = namedtuple(\n",
    "    \"Hyperparams\", ['learning_rate', 'anneal_epochs', 'reg'])\n",
    "RunResult = namedtuple(\n",
    "    \"RunResult\", ['model', 'train_history', 'val_history', 'final_val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T05:28:20.650720Z",
     "start_time": "2019-05-18T21:38:33.167179Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "i6mhfdQ9K-N3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start lr=0.053613361100516184, l2=3.824569722466999e-05\n",
      "Average loss: 2.123905, Train accuracy: 0.242381, Val accuracy: 0.457716\n",
      "Average loss: 1.263296, Train accuracy: 0.602703, Val accuracy: 0.715105\n",
      "Average loss: 0.895068, Train accuracy: 0.730795, Val accuracy: 0.747799\n",
      "Average loss: 0.762092, Train accuracy: 0.774750, Val accuracy: 0.795099\n",
      "Average loss: 0.683060, Train accuracy: 0.799321, Val accuracy: 0.819535\n",
      "Average loss: 0.634133, Train accuracy: 0.814695, Val accuracy: 0.830046\n",
      "Average loss: 0.593672, Train accuracy: 0.828328, Val accuracy: 0.842127\n",
      "Average loss: 0.562474, Train accuracy: 0.837082, Val accuracy: 0.850044\n",
      "Average loss: 0.535280, Train accuracy: 0.845118, Val accuracy: 0.853730\n",
      "Average loss: 0.513553, Train accuracy: 0.852063, Val accuracy: 0.860214\n",
      "End\n",
      "Start lr=0.009589551308362443, l2=2.081221569986337e-07\n",
      "Average loss: 2.256694, Train accuracy: 0.175613, Val accuracy: 0.190840\n",
      "Average loss: 2.235075, Train accuracy: 0.188837, Val accuracy: 0.190840\n",
      "Average loss: 2.214831, Train accuracy: 0.189690, Val accuracy: 0.192683\n",
      "Average loss: 2.148209, Train accuracy: 0.221940, Val accuracy: 0.261620\n",
      "Average loss: 1.987329, Train accuracy: 0.322424, Val accuracy: 0.379838\n",
      "Average loss: 1.786332, Train accuracy: 0.417773, Val accuracy: 0.458535\n",
      "Average loss: 1.593151, Train accuracy: 0.492083, Val accuracy: 0.523445\n",
      "Average loss: 1.420387, Train accuracy: 0.553954, Val accuracy: 0.595522\n",
      "Average loss: 1.273747, Train accuracy: 0.605979, Val accuracy: 0.640161\n",
      "Average loss: 1.158649, Train accuracy: 0.645548, Val accuracy: 0.670739\n",
      "End\n",
      "Start lr=0.13592941213664708, l2=1.2650337203959038e-05\n",
      "Average loss: 1.527189, Train accuracy: 0.483875, Val accuracy: 0.761654\n",
      "Average loss: 0.730365, Train accuracy: 0.783674, Val accuracy: 0.823425\n",
      "Average loss: 0.594746, Train accuracy: 0.826042, Val accuracy: 0.828203\n",
      "Average loss: 0.526211, Train accuracy: 0.845391, Val accuracy: 0.853594\n",
      "Average loss: 0.476152, Train accuracy: 0.859980, Val accuracy: 0.867791\n",
      "Average loss: 0.445314, Train accuracy: 0.867846, Val accuracy: 0.874343\n",
      "Average loss: 0.417284, Train accuracy: 0.876497, Val accuracy: 0.878370\n",
      "Average loss: 0.393977, Train accuracy: 0.883937, Val accuracy: 0.880691\n",
      "Average loss: 0.375258, Train accuracy: 0.889363, Val accuracy: 0.884786\n",
      "Average loss: 0.360082, Train accuracy: 0.893202, Val accuracy: 0.888950\n",
      "End\n",
      "Start lr=0.012676822469850557, l2=6.979813907830667e-06\n",
      "Average loss: 2.252296, Train accuracy: 0.178361, Val accuracy: 0.190840\n",
      "Average loss: 2.227731, Train accuracy: 0.188991, Val accuracy: 0.191386\n",
      "Average loss: 2.163419, Train accuracy: 0.214739, Val accuracy: 0.255614\n",
      "Average loss: 1.959189, Train accuracy: 0.335921, Val accuracy: 0.412463\n",
      "Average loss: 1.686024, Train accuracy: 0.458844, Val accuracy: 0.508225\n",
      "Average loss: 1.442874, Train accuracy: 0.545456, Val accuracy: 0.586103\n",
      "Average loss: 1.249639, Train accuracy: 0.615722, Val accuracy: 0.655314\n",
      "Average loss: 1.109474, Train accuracy: 0.663738, Val accuracy: 0.700771\n",
      "Average loss: 1.011299, Train accuracy: 0.696140, Val accuracy: 0.721998\n",
      "Average loss: 0.940836, Train accuracy: 0.718374, Val accuracy: 0.742884\n",
      "End\n",
      "Start lr=0.2267439254064292, l2=4.391800892596086e-07\n",
      "Average loss: 1.261459, Train accuracy: 0.583575, Val accuracy: 0.812436\n",
      "Average loss: 0.615744, Train accuracy: 0.818056, Val accuracy: 0.849430\n",
      "Average loss: 0.502566, Train accuracy: 0.850732, Val accuracy: 0.852570\n",
      "Average loss: 0.447582, Train accuracy: 0.867915, Val accuracy: 0.871476\n",
      "Average loss: 0.409474, Train accuracy: 0.878408, Val accuracy: 0.887584\n",
      "Average loss: 0.384564, Train accuracy: 0.886138, Val accuracy: 0.889700\n",
      "Average loss: 0.360068, Train accuracy: 0.893185, Val accuracy: 0.894273\n",
      "Average loss: 0.343195, Train accuracy: 0.899055, Val accuracy: 0.895775\n",
      "Average loss: 0.324612, Train accuracy: 0.903525, Val accuracy: 0.894751\n",
      "Average loss: 0.312704, Train accuracy: 0.907211, Val accuracy: 0.898846\n",
      "End\n",
      "Start lr=0.15628579248441185, l2=2.373424250023866e-06\n",
      "Average loss: 1.443254, Train accuracy: 0.516210, Val accuracy: 0.776875\n",
      "Average loss: 0.696453, Train accuracy: 0.792888, Val accuracy: 0.834278\n",
      "Average loss: 0.564545, Train accuracy: 0.833123, Val accuracy: 0.841922\n",
      "Average loss: 0.498276, Train accuracy: 0.854213, Val accuracy: 0.860419\n",
      "Average loss: 0.449579, Train accuracy: 0.866942, Val accuracy: 0.878097\n",
      "Average loss: 0.421282, Train accuracy: 0.876804, Val accuracy: 0.880145\n",
      "Average loss: 0.394971, Train accuracy: 0.884124, Val accuracy: 0.885878\n",
      "Average loss: 0.373825, Train accuracy: 0.889875, Val accuracy: 0.887243\n",
      "Average loss: 0.356082, Train accuracy: 0.895506, Val accuracy: 0.891543\n",
      "Average loss: 0.343156, Train accuracy: 0.898560, Val accuracy: 0.892567\n",
      "End\n",
      "Start lr=0.286118382967511, l2=1.3095350204826676e-06\n",
      "Average loss: 1.157191, Train accuracy: 0.621267, Val accuracy: 0.827384\n",
      "Average loss: 0.571212, Train accuracy: 0.831980, Val accuracy: 0.857348\n",
      "Average loss: 0.477412, Train accuracy: 0.857438, Val accuracy: 0.862398\n",
      "Average loss: 0.426820, Train accuracy: 0.874040, Val accuracy: 0.874070\n",
      "Average loss: 0.390859, Train accuracy: 0.884295, Val accuracy: 0.888131\n",
      "Average loss: 0.365461, Train accuracy: 0.892127, Val accuracy: 0.892021\n",
      "Average loss: 0.343785, Train accuracy: 0.900232, Val accuracy: 0.893523\n",
      "Average loss: 0.328906, Train accuracy: 0.903133, Val accuracy: 0.892089\n",
      "Average loss: 0.312579, Train accuracy: 0.908218, Val accuracy: 0.899939\n",
      "Average loss: 0.299029, Train accuracy: 0.911937, Val accuracy: 0.899666\n",
      "End\n",
      "Start lr=0.5, l2=4.1268208457029516e-05\n",
      "Average loss: 1.000878, Train accuracy: 0.677644, Val accuracy: 0.848406\n",
      "Average loss: 0.512454, Train accuracy: 0.848497, Val accuracy: 0.863013\n",
      "Average loss: 0.431553, Train accuracy: 0.871685, Val accuracy: 0.864787\n",
      "Average loss: 0.390366, Train accuracy: 0.884722, Val accuracy: 0.883489\n",
      "Average loss: 0.361776, Train accuracy: 0.892485, Val accuracy: 0.889837\n",
      "Average loss: 0.343573, Train accuracy: 0.897911, Val accuracy: 0.893181\n",
      "Average loss: 0.323302, Train accuracy: 0.904225, Val accuracy: 0.894000\n",
      "Average loss: 0.310368, Train accuracy: 0.908149, Val accuracy: 0.899802\n",
      "Average loss: 0.297937, Train accuracy: 0.910914, Val accuracy: 0.902942\n",
      "Average loss: 0.287028, Train accuracy: 0.914121, Val accuracy: 0.893181\n",
      "End\n",
      "Start lr=0.01457526531412588, l2=2.45691646298279e-07\n",
      "Average loss: 2.250198, Train accuracy: 0.179965, Val accuracy: 0.190840\n",
      "Average loss: 2.219966, Train accuracy: 0.189673, Val accuracy: 0.197256\n",
      "Average loss: 2.102415, Train accuracy: 0.253268, Val accuracy: 0.327827\n",
      "Average loss: 1.819092, Train accuracy: 0.404822, Val accuracy: 0.476008\n",
      "Average loss: 1.520374, Train accuracy: 0.518309, Val accuracy: 0.572452\n",
      "Average loss: 1.285682, Train accuracy: 0.600416, Val accuracy: 0.639137\n",
      "Average loss: 1.120754, Train accuracy: 0.660274, Val accuracy: 0.695447\n",
      "Average loss: 1.007038, Train accuracy: 0.697420, Val accuracy: 0.731281\n",
      "Average loss: 0.928549, Train accuracy: 0.722912, Val accuracy: 0.746434\n",
      "Average loss: 0.872512, Train accuracy: 0.742586, Val accuracy: 0.762064\n",
      "End\n",
      "Start lr=0.013280438914733433, l2=8.412497049736118e-07\n",
      "Average loss: 2.251585, Train accuracy: 0.178497, Val accuracy: 0.190840\n",
      "Average loss: 2.225203, Train accuracy: 0.189144, Val accuracy: 0.192274\n",
      "Average loss: 2.144486, Train accuracy: 0.225694, Val accuracy: 0.282165\n",
      "Average loss: 1.910322, Train accuracy: 0.362591, Val accuracy: 0.434441\n",
      "Average loss: 1.625894, Train accuracy: 0.481657, Val accuracy: 0.532455\n",
      "Average loss: 1.387106, Train accuracy: 0.563304, Val accuracy: 0.601938\n",
      "Average loss: 1.205910, Train accuracy: 0.631778, Val accuracy: 0.667053\n",
      "Average loss: 1.074595, Train accuracy: 0.675084, Val accuracy: 0.712102\n",
      "Average loss: 0.982435, Train accuracy: 0.705389, Val accuracy: 0.729302\n",
      "Average loss: 0.916474, Train accuracy: 0.727519, Val accuracy: 0.748208\n",
      "End\n",
      "Start lr=0.005238078763948325, l2=1.0715933998226711e-06\n",
      "Average loss: 2.269563, Train accuracy: 0.163652, Val accuracy: 0.190840\n",
      "Average loss: 2.241601, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.236704, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.230294, Train accuracy: 0.188803, Val accuracy: 0.190840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.218182, Train accuracy: 0.189213, Val accuracy: 0.191386\n",
      "Average loss: 2.194141, Train accuracy: 0.193001, Val accuracy: 0.205447\n",
      "Average loss: 2.149113, Train accuracy: 0.223697, Val accuracy: 0.238072\n",
      "Average loss: 2.076260, Train accuracy: 0.270279, Val accuracy: 0.314245\n",
      "Average loss: 1.977486, Train accuracy: 0.329779, Val accuracy: 0.366118\n",
      "Average loss: 1.870136, Train accuracy: 0.384312, Val accuracy: 0.414511\n",
      "End\n",
      "Start lr=0.01926764296855264, l2=2.614673211801092e-05\n",
      "Average loss: 2.245991, Train accuracy: 0.182831, Val accuracy: 0.190840\n",
      "Average loss: 2.179420, Train accuracy: 0.206771, Val accuracy: 0.267695\n",
      "Average loss: 1.866076, Train accuracy: 0.380354, Val accuracy: 0.455942\n",
      "Average loss: 1.482138, Train accuracy: 0.529604, Val accuracy: 0.601051\n",
      "Average loss: 1.202394, Train accuracy: 0.629048, Val accuracy: 0.677838\n",
      "Average loss: 1.028905, Train accuracy: 0.688206, Val accuracy: 0.714354\n",
      "Average loss: 0.927280, Train accuracy: 0.723697, Val accuracy: 0.751962\n",
      "Average loss: 0.855815, Train accuracy: 0.747381, Val accuracy: 0.774009\n",
      "Average loss: 0.804514, Train accuracy: 0.762840, Val accuracy: 0.781107\n",
      "Average loss: 0.767574, Train accuracy: 0.776081, Val accuracy: 0.788615\n",
      "End\n",
      "Start lr=0.005238078763948325, l2=3.746050032748989e-07\n",
      "Average loss: 2.269562, Train accuracy: 0.163720, Val accuracy: 0.190840\n",
      "Average loss: 2.241607, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.236712, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.230297, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.218196, Train accuracy: 0.189179, Val accuracy: 0.191250\n",
      "Average loss: 2.194221, Train accuracy: 0.192642, Val accuracy: 0.205037\n",
      "Average loss: 2.149202, Train accuracy: 0.224004, Val accuracy: 0.238414\n",
      "Average loss: 2.076538, Train accuracy: 0.270348, Val accuracy: 0.314791\n",
      "Average loss: 1.978611, Train accuracy: 0.330290, Val accuracy: 0.364617\n",
      "Average loss: 1.871260, Train accuracy: 0.383169, Val accuracy: 0.413692\n",
      "End\n",
      "Start lr=0.07778380719652361, l2=6.742622241778349e-07\n",
      "Average loss: 1.906925, Train accuracy: 0.336809, Val accuracy: 0.638659\n",
      "Average loss: 0.955730, Train accuracy: 0.710525, Val accuracy: 0.777763\n",
      "Average loss: 0.727942, Train accuracy: 0.785244, Val accuracy: 0.792710\n",
      "Average loss: 0.634021, Train accuracy: 0.815650, Val accuracy: 0.836939\n",
      "Average loss: 0.572731, Train accuracy: 0.832116, Val accuracy: 0.848201\n",
      "Average loss: 0.536233, Train accuracy: 0.843002, Val accuracy: 0.853525\n",
      "Average loss: 0.500211, Train accuracy: 0.854469, Val accuracy: 0.862467\n",
      "Average loss: 0.473960, Train accuracy: 0.860577, Val accuracy: 0.864583\n",
      "Average loss: 0.453264, Train accuracy: 0.867215, Val accuracy: 0.873183\n",
      "Average loss: 0.434504, Train accuracy: 0.873119, Val accuracy: 0.873661\n",
      "End\n",
      "Start lr=0.022153107287919412, l2=2.389892566231048e-06\n",
      "Average loss: 2.243465, Train accuracy: 0.183838, Val accuracy: 0.190840\n",
      "Average loss: 2.130468, Train accuracy: 0.235078, Val accuracy: 0.344550\n",
      "Average loss: 1.711503, Train accuracy: 0.446644, Val accuracy: 0.516210\n",
      "Average loss: 1.323118, Train accuracy: 0.585418, Val accuracy: 0.650195\n",
      "Average loss: 1.078492, Train accuracy: 0.671621, Val accuracy: 0.713944\n",
      "Average loss: 0.939507, Train accuracy: 0.717708, Val accuracy: 0.740018\n",
      "Average loss: 0.858837, Train accuracy: 0.747739, Val accuracy: 0.771347\n",
      "Average loss: 0.800536, Train accuracy: 0.765587, Val accuracy: 0.787660\n",
      "Average loss: 0.757693, Train accuracy: 0.777685, Val accuracy: 0.793734\n",
      "Average loss: 0.726111, Train accuracy: 0.788486, Val accuracy: 0.801515\n",
      "End\n",
      "Start lr=0.07087370814634028, l2=1.1562801312073753e-07\n",
      "Average loss: 1.975125, Train accuracy: 0.308518, Val accuracy: 0.599140\n",
      "Average loss: 1.022814, Train accuracy: 0.687472, Val accuracy: 0.768480\n",
      "Average loss: 0.766525, Train accuracy: 0.774033, Val accuracy: 0.779537\n",
      "Average loss: 0.662768, Train accuracy: 0.806880, Val accuracy: 0.826565\n",
      "Average loss: 0.596396, Train accuracy: 0.826127, Val accuracy: 0.839806\n",
      "Average loss: 0.556674, Train accuracy: 0.838481, Val accuracy: 0.849635\n",
      "Average loss: 0.519616, Train accuracy: 0.849230, Val accuracy: 0.858235\n",
      "Average loss: 0.492400, Train accuracy: 0.856875, Val accuracy: 0.861921\n",
      "Average loss: 0.470287, Train accuracy: 0.863086, Val accuracy: 0.868337\n",
      "Average loss: 0.450615, Train accuracy: 0.867829, Val accuracy: 0.871272\n",
      "End\n",
      "Start lr=0.2997421251594706, l2=4.804870439655134e-06\n",
      "Average loss: 1.147147, Train accuracy: 0.624987, Val accuracy: 0.824858\n",
      "Average loss: 0.568631, Train accuracy: 0.831911, Val accuracy: 0.857552\n",
      "Average loss: 0.473773, Train accuracy: 0.859434, Val accuracy: 0.863218\n",
      "Average loss: 0.423509, Train accuracy: 0.875200, Val accuracy: 0.876800\n",
      "Average loss: 0.387962, Train accuracy: 0.885728, Val accuracy: 0.890383\n",
      "Average loss: 0.364483, Train accuracy: 0.890745, Val accuracy: 0.893523\n",
      "Average loss: 0.341728, Train accuracy: 0.900369, Val accuracy: 0.892158\n",
      "Average loss: 0.326128, Train accuracy: 0.903099, Val accuracy: 0.888813\n",
      "Average loss: 0.312261, Train accuracy: 0.907876, Val accuracy: 0.900962\n",
      "Average loss: 0.300193, Train accuracy: 0.910402, Val accuracy: 0.900689\n",
      "End\n",
      "Start lr=0.3289666123287841, l2=1.4933932161242535e-07\n",
      "Average loss: 1.112860, Train accuracy: 0.637221, Val accuracy: 0.828612\n",
      "Average loss: 0.552194, Train accuracy: 0.836740, Val accuracy: 0.859054\n",
      "Average loss: 0.463226, Train accuracy: 0.862744, Val accuracy: 0.873183\n",
      "Average loss: 0.414817, Train accuracy: 0.876651, Val accuracy: 0.878029\n",
      "Average loss: 0.379569, Train accuracy: 0.886633, Val accuracy: 0.890042\n",
      "Average loss: 0.355881, Train accuracy: 0.894618, Val accuracy: 0.891885\n",
      "Average loss: 0.335121, Train accuracy: 0.901239, Val accuracy: 0.893386\n",
      "Average loss: 0.320345, Train accuracy: 0.905180, Val accuracy: 0.893454\n",
      "Average loss: 0.304225, Train accuracy: 0.910095, Val accuracy: 0.899597\n",
      "Average loss: 0.295015, Train accuracy: 0.912227, Val accuracy: 0.899324\n",
      "End\n",
      "Start lr=0.03367075328875411, l2=2.669478494034318e-06\n",
      "Average loss: 2.228327, Train accuracy: 0.188001, Val accuracy: 0.201897\n",
      "Average loss: 1.801492, Train accuracy: 0.399294, Val accuracy: 0.550884\n",
      "Average loss: 1.229400, Train accuracy: 0.616814, Val accuracy: 0.667873\n",
      "Average loss: 0.965746, Train accuracy: 0.709330, Val accuracy: 0.743567\n",
      "Average loss: 0.837028, Train accuracy: 0.752261, Val accuracy: 0.778240\n",
      "Average loss: 0.763984, Train accuracy: 0.775842, Val accuracy: 0.788615\n",
      "Average loss: 0.714710, Train accuracy: 0.791216, Val accuracy: 0.809911\n",
      "Average loss: 0.675368, Train accuracy: 0.803177, Val accuracy: 0.821309\n",
      "Average loss: 0.643392, Train accuracy: 0.812221, Val accuracy: 0.826428\n",
      "Average loss: 0.617713, Train accuracy: 0.822237, Val accuracy: 0.830933\n",
      "End\n",
      "Start lr=0.07778380719652361, l2=8.470868266557403e-05\n",
      "Average loss: 1.909508, Train accuracy: 0.335665, Val accuracy: 0.636612\n",
      "Average loss: 0.956708, Train accuracy: 0.710798, Val accuracy: 0.777421\n",
      "Average loss: 0.726824, Train accuracy: 0.786216, Val accuracy: 0.790936\n",
      "Average loss: 0.631310, Train accuracy: 0.816179, Val accuracy: 0.837008\n",
      "Average loss: 0.570222, Train accuracy: 0.834113, Val accuracy: 0.847792\n",
      "Average loss: 0.532960, Train accuracy: 0.844521, Val accuracy: 0.855778\n",
      "Average loss: 0.497070, Train accuracy: 0.856192, Val accuracy: 0.862262\n",
      "Average loss: 0.471089, Train accuracy: 0.861789, Val accuracy: 0.865743\n",
      "Average loss: 0.450758, Train accuracy: 0.866891, Val accuracy: 0.873592\n",
      "Average loss: 0.431772, Train accuracy: 0.872829, Val accuracy: 0.873524\n",
      "End\n",
      "Start lr=0.009589551308362443, l2=3.6946012051993025e-07\n",
      "Average loss: 2.256680, Train accuracy: 0.175613, Val accuracy: 0.190840\n",
      "Average loss: 2.235024, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.214566, Train accuracy: 0.189622, Val accuracy: 0.192683\n",
      "Average loss: 2.147780, Train accuracy: 0.222435, Val accuracy: 0.262098\n",
      "Average loss: 1.987298, Train accuracy: 0.322441, Val accuracy: 0.379974\n",
      "Average loss: 1.787068, Train accuracy: 0.418490, Val accuracy: 0.458330\n",
      "Average loss: 1.593810, Train accuracy: 0.492168, Val accuracy: 0.524060\n",
      "Average loss: 1.420192, Train accuracy: 0.553476, Val accuracy: 0.595659\n",
      "Average loss: 1.273206, Train accuracy: 0.606218, Val accuracy: 0.640366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.158125, Train accuracy: 0.645889, Val accuracy: 0.669784\n",
      "End\n",
      "Start lr=0.08536763237353458, l2=1.148312414543511e-05\n",
      "Average loss: 1.853524, Train accuracy: 0.356841, Val accuracy: 0.666507\n",
      "Average loss: 0.907282, Train accuracy: 0.725984, Val accuracy: 0.788615\n",
      "Average loss: 0.701587, Train accuracy: 0.794014, Val accuracy: 0.798512\n",
      "Average loss: 0.613808, Train accuracy: 0.820991, Val accuracy: 0.841035\n",
      "Average loss: 0.554884, Train accuracy: 0.838157, Val accuracy: 0.852433\n",
      "Average loss: 0.518820, Train accuracy: 0.848514, Val accuracy: 0.858030\n",
      "Average loss: 0.484305, Train accuracy: 0.858189, Val accuracy: 0.865470\n",
      "Average loss: 0.459154, Train accuracy: 0.864519, Val accuracy: 0.868814\n",
      "Average loss: 0.438947, Train accuracy: 0.870423, Val accuracy: 0.875367\n",
      "Average loss: 0.420366, Train accuracy: 0.877385, Val accuracy: 0.875367\n",
      "End\n",
      "Start lr=0.08536763237353458, l2=4.871780218794631e-06\n",
      "Average loss: 1.851176, Train accuracy: 0.358410, Val accuracy: 0.664392\n",
      "Average loss: 0.910379, Train accuracy: 0.725421, Val accuracy: 0.788547\n",
      "Average loss: 0.702482, Train accuracy: 0.793451, Val accuracy: 0.798717\n",
      "Average loss: 0.614474, Train accuracy: 0.821520, Val accuracy: 0.840284\n",
      "Average loss: 0.555726, Train accuracy: 0.837815, Val accuracy: 0.853252\n",
      "Average loss: 0.520275, Train accuracy: 0.847354, Val accuracy: 0.857416\n",
      "Average loss: 0.485129, Train accuracy: 0.858700, Val accuracy: 0.865402\n",
      "Average loss: 0.459270, Train accuracy: 0.865560, Val accuracy: 0.869156\n",
      "Average loss: 0.439121, Train accuracy: 0.871430, Val accuracy: 0.876049\n",
      "Average loss: 0.421693, Train accuracy: 0.876924, Val accuracy: 0.876049\n",
      "End\n",
      "Start lr=0.06164233697210333, l2=5.366976945540476e-07\n",
      "Average loss: 2.055112, Train accuracy: 0.273283, Val accuracy: 0.535185\n",
      "Average loss: 1.133283, Train accuracy: 0.647852, Val accuracy: 0.741110\n",
      "Average loss: 0.834563, Train accuracy: 0.752107, Val accuracy: 0.758856\n",
      "Average loss: 0.716135, Train accuracy: 0.789595, Val accuracy: 0.811480\n",
      "Average loss: 0.641853, Train accuracy: 0.813125, Val accuracy: 0.830250\n",
      "Average loss: 0.595128, Train accuracy: 0.826707, Val accuracy: 0.841581\n",
      "Average loss: 0.554715, Train accuracy: 0.839129, Val accuracy: 0.851409\n",
      "Average loss: 0.524995, Train accuracy: 0.848292, Val accuracy: 0.857348\n",
      "Average loss: 0.500245, Train accuracy: 0.854059, Val accuracy: 0.863900\n",
      "Average loss: 0.479212, Train accuracy: 0.860492, Val accuracy: 0.867313\n",
      "End\n",
      "Start lr=0.09369087114301924, l2=3.2622220097116733e-06\n",
      "Average loss: 1.788472, Train accuracy: 0.383561, Val accuracy: 0.689646\n",
      "Average loss: 0.860772, Train accuracy: 0.741989, Val accuracy: 0.799468\n",
      "Average loss: 0.672113, Train accuracy: 0.803382, Val accuracy: 0.804450\n",
      "Average loss: 0.590272, Train accuracy: 0.829284, Val accuracy: 0.845949\n",
      "Average loss: 0.534032, Train accuracy: 0.843378, Val accuracy: 0.856256\n",
      "Average loss: 0.499729, Train accuracy: 0.853053, Val accuracy: 0.861238\n",
      "Average loss: 0.466181, Train accuracy: 0.863154, Val accuracy: 0.866494\n",
      "Average loss: 0.441395, Train accuracy: 0.870935, Val accuracy: 0.871749\n",
      "Average loss: 0.422961, Train accuracy: 0.876037, Val accuracy: 0.878302\n",
      "Average loss: 0.405658, Train accuracy: 0.880319, Val accuracy: 0.876937\n",
      "End\n",
      "Start lr=0.005487493827465278, l2=2.840883690183301e-06\n",
      "Average loss: 2.268344, Train accuracy: 0.164915, Val accuracy: 0.190840\n",
      "Average loss: 2.241240, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.236049, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.228824, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.214325, Train accuracy: 0.189537, Val accuracy: 0.192001\n",
      "Average loss: 2.184815, Train accuracy: 0.197881, Val accuracy: 0.219644\n",
      "Average loss: 2.129744, Train accuracy: 0.236512, Val accuracy: 0.255000\n",
      "Average loss: 2.044109, Train accuracy: 0.290158, Val accuracy: 0.337315\n",
      "Average loss: 1.935807, Train accuracy: 0.354042, Val accuracy: 0.386936\n",
      "Average loss: 1.822558, Train accuracy: 0.405982, Val accuracy: 0.437786\n",
      "End\n",
      "Start lr=0.05117655109495131, l2=8.708431497690725e-06\n",
      "Average loss: 2.144552, Train accuracy: 0.232775, Val accuracy: 0.431438\n",
      "Average loss: 1.321473, Train accuracy: 0.583217, Val accuracy: 0.703433\n",
      "Average loss: 0.921598, Train accuracy: 0.721377, Val accuracy: 0.740769\n",
      "Average loss: 0.780468, Train accuracy: 0.768966, Val accuracy: 0.790253\n",
      "Average loss: 0.698507, Train accuracy: 0.794492, Val accuracy: 0.815166\n",
      "Average loss: 0.647920, Train accuracy: 0.810139, Val accuracy: 0.824722\n",
      "Average loss: 0.606332, Train accuracy: 0.824643, Val accuracy: 0.840216\n",
      "Average loss: 0.574635, Train accuracy: 0.834198, Val accuracy: 0.847860\n",
      "Average loss: 0.546079, Train accuracy: 0.841945, Val accuracy: 0.851273\n",
      "Average loss: 0.523516, Train accuracy: 0.848565, Val accuracy: 0.856665\n",
      "End\n",
      "Start lr=0.012676822469850557, l2=3.3306003436245885e-05\n",
      "Average loss: 2.252297, Train accuracy: 0.178361, Val accuracy: 0.190840\n",
      "Average loss: 2.227710, Train accuracy: 0.188974, Val accuracy: 0.191250\n",
      "Average loss: 2.164134, Train accuracy: 0.213886, Val accuracy: 0.255477\n",
      "Average loss: 1.960959, Train accuracy: 0.335341, Val accuracy: 0.409665\n",
      "Average loss: 1.687749, Train accuracy: 0.458315, Val accuracy: 0.507064\n",
      "Average loss: 1.446063, Train accuracy: 0.543784, Val accuracy: 0.582145\n",
      "Average loss: 1.254452, Train accuracy: 0.613453, Val accuracy: 0.654358\n",
      "Average loss: 1.113329, Train accuracy: 0.661673, Val accuracy: 0.700020\n",
      "Average loss: 1.013732, Train accuracy: 0.695151, Val accuracy: 0.719541\n",
      "Average loss: 0.941954, Train accuracy: 0.718732, Val accuracy: 0.741110\n",
      "End\n",
      "Start lr=0.02928510409028334, l2=6.604193962330305e-07\n",
      "Average loss: 2.235961, Train accuracy: 0.186039, Val accuracy: 0.192001\n",
      "Average loss: 1.941157, Train accuracy: 0.335972, Val accuracy: 0.484813\n",
      "Average loss: 1.382110, Train accuracy: 0.563611, Val accuracy: 0.627124\n",
      "Average loss: 1.060521, Train accuracy: 0.675938, Val accuracy: 0.720156\n",
      "Average loss: 0.899865, Train accuracy: 0.731324, Val accuracy: 0.761450\n",
      "Average loss: 0.811763, Train accuracy: 0.760144, Val accuracy: 0.774282\n",
      "Average loss: 0.756708, Train accuracy: 0.779869, Val accuracy: 0.796533\n",
      "Average loss: 0.713050, Train accuracy: 0.792137, Val accuracy: 0.810730\n",
      "Average loss: 0.679307, Train accuracy: 0.801061, Val accuracy: 0.816736\n",
      "Average loss: 0.651939, Train accuracy: 0.812272, Val accuracy: 0.823698\n",
      "End\n",
      "Start lr=0.005748784976988678, l2=6.335804992658255e-06\n",
      "Average loss: 2.267149, Train accuracy: 0.166126, Val accuracy: 0.190840\n",
      "Average loss: 2.240864, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.235348, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.227161, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.209790, Train accuracy: 0.190305, Val accuracy: 0.193229\n",
      "Average loss: 2.173818, Train accuracy: 0.205474, Val accuracy: 0.231042\n",
      "Average loss: 2.106771, Train accuracy: 0.248149, Val accuracy: 0.277251\n",
      "Average loss: 2.006639, Train accuracy: 0.313091, Val accuracy: 0.355607\n",
      "Average loss: 1.888194, Train accuracy: 0.376173, Val accuracy: 0.412259\n",
      "Average loss: 1.768038, Train accuracy: 0.428830, Val accuracy: 0.458877\n",
      "End\n",
      "Start lr=0.07778380719652361, l2=1.0940547072057436e-07\n",
      "Average loss: 1.907824, Train accuracy: 0.336501, Val accuracy: 0.636339\n",
      "Average loss: 0.957398, Train accuracy: 0.710866, Val accuracy: 0.780493\n",
      "Average loss: 0.728729, Train accuracy: 0.785551, Val accuracy: 0.792028\n",
      "Average loss: 0.633330, Train accuracy: 0.815292, Val accuracy: 0.836393\n",
      "Average loss: 0.571545, Train accuracy: 0.833652, Val accuracy: 0.848133\n",
      "Average loss: 0.535311, Train accuracy: 0.844231, Val accuracy: 0.855232\n",
      "Average loss: 0.498830, Train accuracy: 0.855766, Val accuracy: 0.863695\n",
      "Average loss: 0.472899, Train accuracy: 0.860867, Val accuracy: 0.866221\n",
      "Average loss: 0.451676, Train accuracy: 0.867044, Val accuracy: 0.872637\n",
      "Average loss: 0.433131, Train accuracy: 0.873102, Val accuracy: 0.873114\n",
      "End\n",
      "Start lr=0.007254143892479701, l2=1.0865157746525372e-06\n",
      "Average loss: 2.261939, Train accuracy: 0.171023, Val accuracy: 0.190840\n",
      "Average loss: 2.238810, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.230188, Train accuracy: 0.188803, Val accuracy: 0.190840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.210760, Train accuracy: 0.189776, Val accuracy: 0.193980\n",
      "Average loss: 2.161041, Train accuracy: 0.214654, Val accuracy: 0.242236\n",
      "Average loss: 2.059980, Train accuracy: 0.278231, Val accuracy: 0.331513\n",
      "Average loss: 1.917212, Train accuracy: 0.361977, Val accuracy: 0.398812\n",
      "Average loss: 1.765888, Train accuracy: 0.427772, Val accuracy: 0.466862\n",
      "Average loss: 1.616440, Train accuracy: 0.484558, Val accuracy: 0.520579\n",
      "Average loss: 1.476105, Train accuracy: 0.535065, Val accuracy: 0.562487\n",
      "End\n",
      "Start lr=0.05616620164890138, l2=4.939621743878326e-05\n",
      "Average loss: 2.105175, Train accuracy: 0.250691, Val accuracy: 0.480786\n",
      "Average loss: 1.221477, Train accuracy: 0.617804, Val accuracy: 0.723432\n",
      "Average loss: 0.872317, Train accuracy: 0.738542, Val accuracy: 0.753327\n",
      "Average loss: 0.744462, Train accuracy: 0.781046, Val accuracy: 0.803358\n",
      "Average loss: 0.667354, Train accuracy: 0.803877, Val accuracy: 0.823289\n",
      "Average loss: 0.619080, Train accuracy: 0.818278, Val accuracy: 0.832981\n",
      "Average loss: 0.579427, Train accuracy: 0.831894, Val accuracy: 0.844038\n",
      "Average loss: 0.548893, Train accuracy: 0.841211, Val accuracy: 0.851341\n",
      "Average loss: 0.523262, Train accuracy: 0.847985, Val accuracy: 0.858371\n",
      "Average loss: 0.501600, Train accuracy: 0.855032, Val accuracy: 0.860283\n",
      "End\n",
      "Start lr=0.2375405081051399, l2=1.8761746914391194e-07\n",
      "Average loss: 1.244063, Train accuracy: 0.589513, Val accuracy: 0.811207\n",
      "Average loss: 0.607472, Train accuracy: 0.820889, Val accuracy: 0.854140\n",
      "Average loss: 0.500589, Train accuracy: 0.852404, Val accuracy: 0.859668\n",
      "Average loss: 0.444290, Train accuracy: 0.867829, Val accuracy: 0.872159\n",
      "Average loss: 0.403709, Train accuracy: 0.881190, Val accuracy: 0.886424\n",
      "Average loss: 0.379612, Train accuracy: 0.888151, Val accuracy: 0.890519\n",
      "Average loss: 0.356220, Train accuracy: 0.894669, Val accuracy: 0.890792\n",
      "Average loss: 0.339621, Train accuracy: 0.900437, Val accuracy: 0.888199\n",
      "Average loss: 0.323232, Train accuracy: 0.905505, Val accuracy: 0.899324\n",
      "Average loss: 0.311464, Train accuracy: 0.907723, Val accuracy: 0.902123\n",
      "End\n",
      "Start lr=0.07778380719652361, l2=2.308677994187167e-06\n",
      "Average loss: 1.907719, Train accuracy: 0.336484, Val accuracy: 0.637226\n",
      "Average loss: 0.957412, Train accuracy: 0.710320, Val accuracy: 0.778036\n",
      "Average loss: 0.727839, Train accuracy: 0.785807, Val accuracy: 0.792506\n",
      "Average loss: 0.632894, Train accuracy: 0.815531, Val accuracy: 0.836871\n",
      "Average loss: 0.571696, Train accuracy: 0.832372, Val accuracy: 0.847724\n",
      "Average loss: 0.534393, Train accuracy: 0.843446, Val accuracy: 0.855095\n",
      "Average loss: 0.499170, Train accuracy: 0.854691, Val accuracy: 0.862194\n",
      "Average loss: 0.472163, Train accuracy: 0.860953, Val accuracy: 0.865129\n",
      "Average loss: 0.451699, Train accuracy: 0.867010, Val accuracy: 0.872364\n",
      "Average loss: 0.432119, Train accuracy: 0.873324, Val accuracy: 0.872568\n",
      "End\n",
      "Start lr=0.03695361016762888, l2=3.3537101520029288e-06\n",
      "Average loss: 2.219070, Train accuracy: 0.192130, Val accuracy: 0.248447\n",
      "Average loss: 1.692769, Train accuracy: 0.444801, Val accuracy: 0.600300\n",
      "Average loss: 1.133913, Train accuracy: 0.649268, Val accuracy: 0.691079\n",
      "Average loss: 0.911489, Train accuracy: 0.726956, Val accuracy: 0.755239\n",
      "Average loss: 0.801050, Train accuracy: 0.763778, Val accuracy: 0.789093\n",
      "Average loss: 0.737242, Train accuracy: 0.783316, Val accuracy: 0.796737\n",
      "Average loss: 0.691931, Train accuracy: 0.798434, Val accuracy: 0.816395\n",
      "Average loss: 0.654717, Train accuracy: 0.809098, Val accuracy: 0.826974\n",
      "Average loss: 0.623292, Train accuracy: 0.818449, Val accuracy: 0.831274\n",
      "Average loss: 0.597928, Train accuracy: 0.827151, Val accuracy: 0.837349\n",
      "End\n",
      "Start lr=0.006924431856969366, l2=6.742622241778349e-05\n",
      "Average loss: 2.262934, Train accuracy: 0.170375, Val accuracy: 0.190908\n",
      "Average loss: 2.239304, Train accuracy: 0.188837, Val accuracy: 0.190840\n",
      "Average loss: 2.231611, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.215847, Train accuracy: 0.189196, Val accuracy: 0.192478\n",
      "Average loss: 2.176218, Train accuracy: 0.204365, Val accuracy: 0.225855\n",
      "Average loss: 2.093158, Train accuracy: 0.257721, Val accuracy: 0.305849\n",
      "Average loss: 1.963853, Train accuracy: 0.337303, Val accuracy: 0.375879\n",
      "Average loss: 1.820388, Train accuracy: 0.406853, Val accuracy: 0.445226\n",
      "Average loss: 1.675331, Train accuracy: 0.462581, Val accuracy: 0.500717\n",
      "Average loss: 1.535668, Train accuracy: 0.513139, Val accuracy: 0.541874\n",
      "End\n",
      "Start lr=0.02431300790032677, l2=4.1268208457029516e-07\n",
      "Average loss: 2.241536, Train accuracy: 0.184793, Val accuracy: 0.191250\n",
      "Average loss: 2.081071, Train accuracy: 0.262942, Val accuracy: 0.392806\n",
      "Average loss: 1.599554, Train accuracy: 0.488141, Val accuracy: 0.558460\n",
      "Average loss: 1.224477, Train accuracy: 0.620500, Val accuracy: 0.676609\n",
      "Average loss: 1.009920, Train accuracy: 0.693410, Val accuracy: 0.733192\n",
      "Average loss: 0.891399, Train accuracy: 0.732945, Val accuracy: 0.751894\n",
      "Average loss: 0.820523, Train accuracy: 0.760042, Val accuracy: 0.779537\n",
      "Average loss: 0.768628, Train accuracy: 0.775040, Val accuracy: 0.795782\n",
      "Average loss: 0.729913, Train accuracy: 0.785978, Val accuracy: 0.800218\n",
      "Average loss: 0.700461, Train accuracy: 0.797188, Val accuracy: 0.809160\n",
      "End\n",
      "Start lr=0.20660062000576696, l2=6.248788072006888e-05\n",
      "Average loss: 1.311302, Train accuracy: 0.566666, Val accuracy: 0.804177\n",
      "Average loss: 0.628888, Train accuracy: 0.814780, Val accuracy: 0.852229\n",
      "Average loss: 0.512428, Train accuracy: 0.849555, Val accuracy: 0.852297\n",
      "Average loss: 0.454255, Train accuracy: 0.865969, Val accuracy: 0.874343\n",
      "Average loss: 0.411777, Train accuracy: 0.878886, Val accuracy: 0.885742\n",
      "Average loss: 0.387206, Train accuracy: 0.885472, Val accuracy: 0.888813\n",
      "Average loss: 0.362333, Train accuracy: 0.893560, Val accuracy: 0.888472\n",
      "Average loss: 0.344112, Train accuracy: 0.897843, Val accuracy: 0.891338\n",
      "Average loss: 0.329512, Train accuracy: 0.902177, Val accuracy: 0.897072\n",
      "Average loss: 0.317445, Train accuracy: 0.905027, Val accuracy: 0.898915\n",
      "End\n",
      "Start lr=0.04885049786496128, l2=4.1268208457029516e-05\n",
      "Average loss: 2.161877, Train accuracy: 0.223646, Val accuracy: 0.405638\n",
      "Average loss: 1.374859, Train accuracy: 0.564004, Val accuracy: 0.694970\n",
      "Average loss: 0.943126, Train accuracy: 0.714108, Val accuracy: 0.737424\n",
      "Average loss: 0.793489, Train accuracy: 0.765263, Val accuracy: 0.788069\n",
      "Average loss: 0.709332, Train accuracy: 0.790926, Val accuracy: 0.812914\n",
      "Average loss: 0.658187, Train accuracy: 0.807102, Val accuracy: 0.821719\n",
      "Average loss: 0.616507, Train accuracy: 0.821281, Val accuracy: 0.838100\n",
      "Average loss: 0.584541, Train accuracy: 0.830273, Val accuracy: 0.846359\n",
      "Average loss: 0.556217, Train accuracy: 0.838276, Val accuracy: 0.851273\n",
      "Average loss: 0.532755, Train accuracy: 0.845733, Val accuracy: 0.856324\n",
      "End\n",
      "Start lr=0.005748784976988678, l2=1.0069386314760271e-07\n",
      "Average loss: 2.267150, Train accuracy: 0.166092, Val accuracy: 0.190840\n",
      "Average loss: 2.240851, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.235337, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.227165, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.209747, Train accuracy: 0.190356, Val accuracy: 0.193366\n",
      "Average loss: 2.173758, Train accuracy: 0.205696, Val accuracy: 0.231179\n",
      "Average loss: 2.106767, Train accuracy: 0.248319, Val accuracy: 0.277524\n",
      "Average loss: 2.006818, Train accuracy: 0.313142, Val accuracy: 0.355948\n",
      "Average loss: 1.888307, Train accuracy: 0.376224, Val accuracy: 0.412327\n",
      "Average loss: 1.768235, Train accuracy: 0.428779, Val accuracy: 0.458330\n",
      "End\n",
      "Start lr=0.0063092844153301054, l2=4.973895958790067e-06\n",
      "Average loss: 2.264971, Train accuracy: 0.168549, Val accuracy: 0.190908\n",
      "Average loss: 2.240129, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.233721, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.222848, Train accuracy: 0.188837, Val accuracy: 0.191250\n",
      "Average loss: 2.197074, Train accuracy: 0.194093, Val accuracy: 0.201829\n",
      "Average loss: 2.142470, Train accuracy: 0.225779, Val accuracy: 0.259027\n",
      "Average loss: 2.046372, Train accuracy: 0.286711, Val accuracy: 0.324415\n",
      "Average loss: 1.919880, Train accuracy: 0.360594, Val accuracy: 0.403522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.786403, Train accuracy: 0.419735, Val accuracy: 0.454918\n",
      "Average loss: 1.653436, Train accuracy: 0.472170, Val accuracy: 0.501126\n",
      "End\n",
      "Start lr=0.005748784976988678, l2=2.9205555121827452e-05\n",
      "Average loss: 2.267153, Train accuracy: 0.166109, Val accuracy: 0.190840\n",
      "Average loss: 2.240862, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.235357, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.227195, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.209810, Train accuracy: 0.190339, Val accuracy: 0.193366\n",
      "Average loss: 2.173891, Train accuracy: 0.205644, Val accuracy: 0.231315\n",
      "Average loss: 2.106982, Train accuracy: 0.248234, Val accuracy: 0.277046\n",
      "Average loss: 2.007130, Train accuracy: 0.313193, Val accuracy: 0.357040\n",
      "Average loss: 1.888801, Train accuracy: 0.375849, Val accuracy: 0.411781\n",
      "Average loss: 1.768654, Train accuracy: 0.428506, Val accuracy: 0.458330\n",
      "End\n",
      "Start lr=0.36104045091927334, l2=1.28264983052806e-05\n",
      "Average loss: 1.088721, Train accuracy: 0.646128, Val accuracy: 0.833254\n",
      "Average loss: 0.546116, Train accuracy: 0.837645, Val accuracy: 0.862535\n",
      "Average loss: 0.458957, Train accuracy: 0.863222, Val accuracy: 0.866972\n",
      "Average loss: 0.409638, Train accuracy: 0.878016, Val accuracy: 0.881851\n",
      "Average loss: 0.374215, Train accuracy: 0.889687, Val accuracy: 0.889291\n",
      "Average loss: 0.352921, Train accuracy: 0.895659, Val accuracy: 0.893932\n",
      "Average loss: 0.330967, Train accuracy: 0.901887, Val accuracy: 0.891407\n",
      "Average loss: 0.316850, Train accuracy: 0.906341, Val accuracy: 0.888677\n",
      "Average loss: 0.301082, Train accuracy: 0.911494, Val accuracy: 0.900348\n",
      "Average loss: 0.288092, Train accuracy: 0.915384, Val accuracy: 0.898505\n",
      "End\n",
      "Start lr=0.011025653699515227, l2=1.5459277364194785e-05\n",
      "Average loss: 2.254415, Train accuracy: 0.176808, Val accuracy: 0.190840\n",
      "Average loss: 2.232121, Train accuracy: 0.188854, Val accuracy: 0.190840\n",
      "Average loss: 2.197319, Train accuracy: 0.194826, Val accuracy: 0.209474\n",
      "Average loss: 2.074075, Train accuracy: 0.270279, Val accuracy: 0.336496\n",
      "Average loss: 1.847138, Train accuracy: 0.391376, Val accuracy: 0.444134\n",
      "Average loss: 1.616542, Train accuracy: 0.483090, Val accuracy: 0.518872\n",
      "Average loss: 1.413591, Train accuracy: 0.557144, Val accuracy: 0.593202\n",
      "Average loss: 1.244469, Train accuracy: 0.616080, Val accuracy: 0.658522\n",
      "Average loss: 1.120249, Train accuracy: 0.659728, Val accuracy: 0.690533\n",
      "Average loss: 1.029706, Train accuracy: 0.689230, Val accuracy: 0.714832\n",
      "End\n",
      "Start lr=0.03695361016762888, l2=3.0442722120643e-07\n",
      "Average loss: 2.219694, Train accuracy: 0.191653, Val accuracy: 0.242714\n",
      "Average loss: 1.696776, Train accuracy: 0.443368, Val accuracy: 0.599823\n",
      "Average loss: 1.135030, Train accuracy: 0.649404, Val accuracy: 0.691147\n",
      "Average loss: 0.914332, Train accuracy: 0.726086, Val accuracy: 0.756262\n",
      "Average loss: 0.805137, Train accuracy: 0.761577, Val accuracy: 0.788479\n",
      "Average loss: 0.741278, Train accuracy: 0.782343, Val accuracy: 0.797352\n",
      "Average loss: 0.695395, Train accuracy: 0.797359, Val accuracy: 0.814279\n",
      "Average loss: 0.657704, Train accuracy: 0.808125, Val accuracy: 0.826223\n",
      "Average loss: 0.625976, Train accuracy: 0.818380, Val accuracy: 0.832708\n",
      "Average loss: 0.599935, Train accuracy: 0.827304, Val accuracy: 0.834755\n",
      "End\n",
      "Start lr=0.149182362014167, l2=7.479522515621829e-05\n",
      "Average loss: 1.473679, Train accuracy: 0.504129, Val accuracy: 0.774555\n",
      "Average loss: 0.704833, Train accuracy: 0.792052, Val accuracy: 0.830797\n",
      "Average loss: 0.576894, Train accuracy: 0.830956, Val accuracy: 0.835847\n",
      "Average loss: 0.510563, Train accuracy: 0.849947, Val accuracy: 0.861170\n",
      "Average loss: 0.463212, Train accuracy: 0.863734, Val accuracy: 0.871613\n",
      "Average loss: 0.435168, Train accuracy: 0.872197, Val accuracy: 0.877551\n",
      "Average loss: 0.407126, Train accuracy: 0.880336, Val accuracy: 0.878165\n",
      "Average loss: 0.385734, Train accuracy: 0.886138, Val accuracy: 0.882465\n",
      "Average loss: 0.367649, Train accuracy: 0.891359, Val accuracy: 0.889973\n",
      "Average loss: 0.354306, Train accuracy: 0.893731, Val accuracy: 0.890588\n",
      "End\n",
      "Start lr=0.5, l2=6.424033659394191e-07\n",
      "Average loss: 0.996923, Train accuracy: 0.678173, Val accuracy: 0.848270\n",
      "Average loss: 0.507490, Train accuracy: 0.849418, Val accuracy: 0.868883\n",
      "Average loss: 0.433477, Train accuracy: 0.870372, Val accuracy: 0.864924\n",
      "Average loss: 0.392297, Train accuracy: 0.882896, Val accuracy: 0.881510\n",
      "Average loss: 0.363367, Train accuracy: 0.891718, Val accuracy: 0.889632\n",
      "Average loss: 0.342030, Train accuracy: 0.898645, Val accuracy: 0.895092\n",
      "Average loss: 0.324235, Train accuracy: 0.904600, Val accuracy: 0.894888\n",
      "Average loss: 0.308291, Train accuracy: 0.908985, Val accuracy: 0.890588\n",
      "Average loss: 0.297417, Train accuracy: 0.911801, Val accuracy: 0.901235\n",
      "Average loss: 0.289135, Train accuracy: 0.914275, Val accuracy: 0.895775\n",
      "End\n",
      "Start lr=0.39624144917695886, l2=2.8018665564591953e-05\n",
      "Average loss: 1.058019, Train accuracy: 0.656827, Val accuracy: 0.841240\n",
      "Average loss: 0.528791, Train accuracy: 0.844077, Val accuracy: 0.861511\n",
      "Average loss: 0.444128, Train accuracy: 0.868136, Val accuracy: 0.867313\n",
      "Average loss: 0.401066, Train accuracy: 0.881070, Val accuracy: 0.880622\n",
      "Average loss: 0.371260, Train accuracy: 0.889585, Val accuracy: 0.891611\n",
      "Average loss: 0.349210, Train accuracy: 0.895523, Val accuracy: 0.895775\n",
      "Average loss: 0.328347, Train accuracy: 0.902774, Val accuracy: 0.893454\n",
      "Average loss: 0.315311, Train accuracy: 0.906375, Val accuracy: 0.897754\n",
      "Average loss: 0.301042, Train accuracy: 0.911545, Val accuracy: 0.900075\n",
      "Average loss: 0.289990, Train accuracy: 0.913012, Val accuracy: 0.899188\n",
      "End\n",
      "Start lr=0.009589551308362443, l2=2.3246970599856456e-06\n",
      "Average loss: 2.256682, Train accuracy: 0.175613, Val accuracy: 0.190840\n",
      "Average loss: 2.235014, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.214534, Train accuracy: 0.189656, Val accuracy: 0.192751\n",
      "Average loss: 2.147839, Train accuracy: 0.222520, Val accuracy: 0.262303\n",
      "Average loss: 1.987306, Train accuracy: 0.322288, Val accuracy: 0.379633\n",
      "Average loss: 1.786469, Train accuracy: 0.418285, Val accuracy: 0.458399\n",
      "Average loss: 1.593013, Train accuracy: 0.492697, Val accuracy: 0.523036\n",
      "Average loss: 1.419645, Train accuracy: 0.554005, Val accuracy: 0.595249\n",
      "Average loss: 1.272619, Train accuracy: 0.606764, Val accuracy: 0.641117\n",
      "Average loss: 1.157599, Train accuracy: 0.645838, Val accuracy: 0.670876\n",
      "End\n",
      "Start lr=0.1796906831902314, l2=1.514189325304352e-05\n",
      "Average loss: 1.368924, Train accuracy: 0.545285, Val accuracy: 0.793188\n",
      "Average loss: 0.656826, Train accuracy: 0.806914, Val accuracy: 0.846495\n",
      "Average loss: 0.533750, Train accuracy: 0.842405, Val accuracy: 0.852706\n",
      "Average loss: 0.473527, Train accuracy: 0.860560, Val accuracy: 0.867791\n",
      "Average loss: 0.429089, Train accuracy: 0.872846, Val accuracy: 0.882807\n",
      "Average loss: 0.403346, Train accuracy: 0.881343, Val accuracy: 0.887311\n",
      "Average loss: 0.376667, Train accuracy: 0.888561, Val accuracy: 0.888267\n",
      "Average loss: 0.358823, Train accuracy: 0.893748, Val accuracy: 0.892021\n",
      "Average loss: 0.342548, Train accuracy: 0.898935, Val accuracy: 0.897550\n",
      "Average loss: 0.330782, Train accuracy: 0.902416, Val accuracy: 0.898369\n",
      "End\n",
      "Start lr=0.08536763237353458, l2=7.689283720758306e-07\n",
      "Average loss: 1.851630, Train accuracy: 0.357267, Val accuracy: 0.663709\n",
      "Average loss: 0.910887, Train accuracy: 0.724738, Val accuracy: 0.787114\n",
      "Average loss: 0.701468, Train accuracy: 0.792769, Val accuracy: 0.799672\n",
      "Average loss: 0.612943, Train accuracy: 0.822066, Val accuracy: 0.843287\n",
      "Average loss: 0.554099, Train accuracy: 0.838020, Val accuracy: 0.853389\n",
      "Average loss: 0.518358, Train accuracy: 0.848787, Val accuracy: 0.857484\n",
      "Average loss: 0.483697, Train accuracy: 0.858939, Val accuracy: 0.865470\n",
      "Average loss: 0.458693, Train accuracy: 0.865799, Val accuracy: 0.868064\n",
      "Average loss: 0.438857, Train accuracy: 0.871549, Val accuracy: 0.875299\n",
      "Average loss: 0.420440, Train accuracy: 0.876600, Val accuracy: 0.873865\n",
      "End\n",
      "Start lr=0.24885117821660557, l2=1.4426439512181588e-05\n",
      "Average loss: 1.217066, Train accuracy: 0.599802, Val accuracy: 0.817214\n",
      "Average loss: 0.593518, Train accuracy: 0.825120, Val accuracy: 0.856802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.492226, Train accuracy: 0.855151, Val accuracy: 0.858098\n",
      "Average loss: 0.437255, Train accuracy: 0.871566, Val accuracy: 0.878029\n",
      "Average loss: 0.399104, Train accuracy: 0.881036, Val accuracy: 0.891680\n",
      "Average loss: 0.372582, Train accuracy: 0.890813, Val accuracy: 0.891407\n",
      "Average loss: 0.350094, Train accuracy: 0.897451, Val accuracy: 0.895229\n",
      "Average loss: 0.335521, Train accuracy: 0.899976, Val accuracy: 0.891611\n",
      "Average loss: 0.320595, Train accuracy: 0.905180, Val accuracy: 0.899597\n",
      "Average loss: 0.306375, Train accuracy: 0.909293, Val accuracy: 0.902327\n",
      "End\n",
      "Start lr=0.21643806405415297, l2=4.331483223376394e-05\n",
      "Average loss: 1.291401, Train accuracy: 0.573730, Val accuracy: 0.806157\n",
      "Average loss: 0.620497, Train accuracy: 0.817664, Val accuracy: 0.852024\n",
      "Average loss: 0.507235, Train accuracy: 0.849981, Val accuracy: 0.855163\n",
      "Average loss: 0.449995, Train accuracy: 0.867351, Val accuracy: 0.875162\n",
      "Average loss: 0.407024, Train accuracy: 0.879893, Val accuracy: 0.886561\n",
      "Average loss: 0.382873, Train accuracy: 0.887486, Val accuracy: 0.886629\n",
      "Average loss: 0.356595, Train accuracy: 0.894294, Val accuracy: 0.893113\n",
      "Average loss: 0.340539, Train accuracy: 0.900983, Val accuracy: 0.894273\n",
      "Average loss: 0.323750, Train accuracy: 0.904208, Val accuracy: 0.896731\n",
      "Average loss: 0.311702, Train accuracy: 0.907228, Val accuracy: 0.899870\n",
      "End\n",
      "Start lr=0.05616620164890138, l2=2.3734242500238664e-05\n",
      "Average loss: 2.104691, Train accuracy: 0.250742, Val accuracy: 0.481059\n",
      "Average loss: 1.214784, Train accuracy: 0.620807, Val accuracy: 0.728346\n",
      "Average loss: 0.866667, Train accuracy: 0.741255, Val accuracy: 0.753191\n",
      "Average loss: 0.740869, Train accuracy: 0.782275, Val accuracy: 0.802676\n",
      "Average loss: 0.663679, Train accuracy: 0.805429, Val accuracy: 0.826223\n",
      "Average loss: 0.615144, Train accuracy: 0.820001, Val accuracy: 0.834414\n",
      "Average loss: 0.574801, Train accuracy: 0.833345, Val accuracy: 0.847724\n",
      "Average loss: 0.544107, Train accuracy: 0.842849, Val accuracy: 0.854140\n",
      "Average loss: 0.518485, Train accuracy: 0.849060, Val accuracy: 0.858917\n",
      "Average loss: 0.496461, Train accuracy: 0.856482, Val accuracy: 0.862057\n",
      "End\n",
      "Start lr=0.015996335688986923, l2=4.45295850994266e-07\n",
      "Average loss: 2.248858, Train accuracy: 0.180835, Val accuracy: 0.190840\n",
      "Average loss: 2.211893, Train accuracy: 0.191124, Val accuracy: 0.213637\n",
      "Average loss: 2.039315, Train accuracy: 0.291847, Val accuracy: 0.371033\n",
      "Average loss: 1.707362, Train accuracy: 0.448828, Val accuracy: 0.516688\n",
      "Average loss: 1.408226, Train accuracy: 0.557639, Val accuracy: 0.613610\n",
      "Average loss: 1.185557, Train accuracy: 0.635959, Val accuracy: 0.668623\n",
      "Average loss: 1.043604, Train accuracy: 0.686261, Val accuracy: 0.720975\n",
      "Average loss: 0.947507, Train accuracy: 0.717111, Val accuracy: 0.749915\n",
      "Average loss: 0.880679, Train accuracy: 0.738303, Val accuracy: 0.760835\n",
      "Average loss: 0.832599, Train accuracy: 0.755281, Val accuracy: 0.770323\n",
      "End\n",
      "Start lr=0.07778380719652361, l2=1.3744790926775367e-06\n",
      "Average loss: 1.907310, Train accuracy: 0.336262, Val accuracy: 0.636066\n",
      "Average loss: 0.961306, Train accuracy: 0.707931, Val accuracy: 0.775647\n",
      "Average loss: 0.731313, Train accuracy: 0.784493, Val accuracy: 0.790663\n",
      "Average loss: 0.635012, Train accuracy: 0.814797, Val accuracy: 0.837827\n",
      "Average loss: 0.573057, Train accuracy: 0.831195, Val accuracy: 0.847314\n",
      "Average loss: 0.536858, Train accuracy: 0.843224, Val accuracy: 0.854276\n",
      "Average loss: 0.500552, Train accuracy: 0.854111, Val accuracy: 0.862330\n",
      "Average loss: 0.473790, Train accuracy: 0.860867, Val accuracy: 0.864719\n",
      "Average loss: 0.453273, Train accuracy: 0.867624, Val accuracy: 0.874684\n",
      "Average loss: 0.434544, Train accuracy: 0.872146, Val accuracy: 0.871886\n",
      "End\n",
      "Start lr=0.032140365586421596, l2=2.9408201705870606e-07\n",
      "Average loss: 2.231506, Train accuracy: 0.187216, Val accuracy: 0.195345\n",
      "Average loss: 1.857092, Train accuracy: 0.375576, Val accuracy: 0.524265\n",
      "Average loss: 1.280268, Train accuracy: 0.599393, Val accuracy: 0.657088\n",
      "Average loss: 0.996188, Train accuracy: 0.697864, Val accuracy: 0.737219\n",
      "Average loss: 0.858244, Train accuracy: 0.745367, Val accuracy: 0.771961\n",
      "Average loss: 0.781154, Train accuracy: 0.769938, Val accuracy: 0.783086\n",
      "Average loss: 0.730776, Train accuracy: 0.786762, Val accuracy: 0.806566\n",
      "Average loss: 0.689714, Train accuracy: 0.799150, Val accuracy: 0.817350\n",
      "Average loss: 0.656870, Train accuracy: 0.808535, Val accuracy: 0.823903\n",
      "Average loss: 0.630396, Train accuracy: 0.818159, Val accuracy: 0.828339\n",
      "End\n",
      "Start lr=0.009589551308362443, l2=2.744343303228368e-05\n",
      "Average loss: 2.256689, Train accuracy: 0.175630, Val accuracy: 0.190840\n",
      "Average loss: 2.235058, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.214764, Train accuracy: 0.189639, Val accuracy: 0.192683\n",
      "Average loss: 2.148460, Train accuracy: 0.221718, Val accuracy: 0.261416\n",
      "Average loss: 1.988724, Train accuracy: 0.322066, Val accuracy: 0.378745\n",
      "Average loss: 1.788374, Train accuracy: 0.417107, Val accuracy: 0.457784\n",
      "Average loss: 1.595076, Train accuracy: 0.491724, Val accuracy: 0.522831\n",
      "Average loss: 1.421293, Train accuracy: 0.553203, Val accuracy: 0.595249\n",
      "Average loss: 1.273961, Train accuracy: 0.605962, Val accuracy: 0.640025\n",
      "Average loss: 1.158581, Train accuracy: 0.645531, Val accuracy: 0.670330\n",
      "End\n",
      "Start lr=0.09815203250201357, l2=3.720236681413066e-05\n",
      "Average loss: 1.750188, Train accuracy: 0.399191, Val accuracy: 0.703774\n",
      "Average loss: 0.841814, Train accuracy: 0.749053, Val accuracy: 0.801993\n",
      "Average loss: 0.661873, Train accuracy: 0.806522, Val accuracy: 0.806703\n",
      "Average loss: 0.581527, Train accuracy: 0.831178, Val accuracy: 0.847997\n",
      "Average loss: 0.525846, Train accuracy: 0.845954, Val accuracy: 0.857621\n",
      "Average loss: 0.490957, Train accuracy: 0.856056, Val accuracy: 0.861989\n",
      "Average loss: 0.458699, Train accuracy: 0.864775, Val accuracy: 0.868814\n",
      "Average loss: 0.433833, Train accuracy: 0.871890, Val accuracy: 0.871749\n",
      "Average loss: 0.415064, Train accuracy: 0.878460, Val accuracy: 0.878302\n",
      "Average loss: 0.399115, Train accuracy: 0.881343, Val accuracy: 0.879803\n",
      "End\n",
      "Start lr=0.12975121056998687, l2=3.643858983763541e-06\n",
      "Average loss: 1.559051, Train accuracy: 0.472460, Val accuracy: 0.755170\n",
      "Average loss: 0.742206, Train accuracy: 0.779988, Val accuracy: 0.821582\n",
      "Average loss: 0.602316, Train accuracy: 0.823533, Val accuracy: 0.828408\n",
      "Average loss: 0.532427, Train accuracy: 0.844197, Val accuracy: 0.860214\n",
      "Average loss: 0.482051, Train accuracy: 0.857523, Val accuracy: 0.868268\n",
      "Average loss: 0.451308, Train accuracy: 0.867727, Val accuracy: 0.873456\n",
      "Average loss: 0.422863, Train accuracy: 0.875422, Val accuracy: 0.875913\n",
      "Average loss: 0.400189, Train accuracy: 0.881173, Val accuracy: 0.877892\n",
      "Average loss: 0.382150, Train accuracy: 0.887196, Val accuracy: 0.884513\n",
      "Average loss: 0.367447, Train accuracy: 0.891376, Val accuracy: 0.887243\n",
      "End\n",
      "Start lr=0.286118382967511, l2=2.423172794237601e-07\n",
      "Average loss: 1.156810, Train accuracy: 0.620943, Val accuracy: 0.823152\n",
      "Average loss: 0.575785, Train accuracy: 0.829591, Val accuracy: 0.857075\n",
      "Average loss: 0.481623, Train accuracy: 0.856380, Val accuracy: 0.864719\n",
      "Average loss: 0.429331, Train accuracy: 0.873341, Val accuracy: 0.875435\n",
      "Average loss: 0.392725, Train accuracy: 0.883869, Val accuracy: 0.890246\n",
      "Average loss: 0.367720, Train accuracy: 0.890694, Val accuracy: 0.893591\n",
      "Average loss: 0.347112, Train accuracy: 0.896683, Val accuracy: 0.892431\n",
      "Average loss: 0.331211, Train accuracy: 0.901273, Val accuracy: 0.890451\n",
      "Average loss: 0.315921, Train accuracy: 0.906324, Val accuracy: 0.896731\n",
      "Average loss: 0.303334, Train accuracy: 0.909071, Val accuracy: 0.899597\n",
      "End\n",
      "Start lr=0.006924431856969366, l2=2.5966559729348724e-06\n",
      "Average loss: 2.262931, Train accuracy: 0.170375, Val accuracy: 0.190908\n",
      "Average loss: 2.239287, Train accuracy: 0.188837, Val accuracy: 0.190840\n",
      "Average loss: 2.231541, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.215855, Train accuracy: 0.189230, Val accuracy: 0.192410\n",
      "Average loss: 2.176299, Train accuracy: 0.204843, Val accuracy: 0.226333\n",
      "Average loss: 2.093460, Train accuracy: 0.257687, Val accuracy: 0.306464\n",
      "Average loss: 1.964968, Train accuracy: 0.336911, Val accuracy: 0.375879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.820502, Train accuracy: 0.407723, Val accuracy: 0.447068\n",
      "Average loss: 1.674415, Train accuracy: 0.463621, Val accuracy: 0.500444\n",
      "Average loss: 1.532701, Train accuracy: 0.514316, Val accuracy: 0.545014\n",
      "End\n",
      "Start lr=0.08943247645287175, l2=2.5966559729348724e-07\n",
      "Average loss: 1.828060, Train accuracy: 0.366003, Val accuracy: 0.675108\n",
      "Average loss: 0.890631, Train accuracy: 0.732604, Val accuracy: 0.791891\n",
      "Average loss: 0.688328, Train accuracy: 0.797512, Val accuracy: 0.801925\n",
      "Average loss: 0.603717, Train accuracy: 0.825103, Val accuracy: 0.843151\n",
      "Average loss: 0.544658, Train accuracy: 0.840682, Val accuracy: 0.854890\n",
      "Average loss: 0.510651, Train accuracy: 0.850357, Val accuracy: 0.861375\n",
      "Average loss: 0.477037, Train accuracy: 0.860612, Val accuracy: 0.867245\n",
      "Average loss: 0.452363, Train accuracy: 0.867061, Val accuracy: 0.870726\n",
      "Average loss: 0.432701, Train accuracy: 0.872539, Val accuracy: 0.877005\n",
      "Average loss: 0.414859, Train accuracy: 0.877914, Val accuracy: 0.876391\n",
      "End\n",
      "Start lr=0.20660062000576696, l2=1.4933932161242533e-06\n",
      "Average loss: 1.306189, Train accuracy: 0.568269, Val accuracy: 0.800764\n",
      "Average loss: 0.631661, Train accuracy: 0.812852, Val accuracy: 0.850181\n",
      "Average loss: 0.513139, Train accuracy: 0.848138, Val accuracy: 0.856051\n",
      "Average loss: 0.455887, Train accuracy: 0.866823, Val accuracy: 0.867381\n",
      "Average loss: 0.413568, Train accuracy: 0.877470, Val accuracy: 0.886083\n",
      "Average loss: 0.389591, Train accuracy: 0.885609, Val accuracy: 0.884240\n",
      "Average loss: 0.365766, Train accuracy: 0.892144, Val accuracy: 0.890042\n",
      "Average loss: 0.346590, Train accuracy: 0.897195, Val accuracy: 0.893181\n",
      "Average loss: 0.331619, Train accuracy: 0.901887, Val accuracy: 0.898027\n",
      "Average loss: 0.318981, Train accuracy: 0.905368, Val accuracy: 0.898915\n",
      "End\n",
      "Start lr=0.02431300790032677, l2=1.7999285067824765e-06\n",
      "Average loss: 2.241593, Train accuracy: 0.184776, Val accuracy: 0.191318\n",
      "Average loss: 2.080924, Train accuracy: 0.262959, Val accuracy: 0.393898\n",
      "Average loss: 1.599495, Train accuracy: 0.488312, Val accuracy: 0.559552\n",
      "Average loss: 1.223806, Train accuracy: 0.619237, Val accuracy: 0.677906\n",
      "Average loss: 1.008388, Train accuracy: 0.694775, Val accuracy: 0.733261\n",
      "Average loss: 0.889831, Train accuracy: 0.734037, Val accuracy: 0.751894\n",
      "Average loss: 0.819791, Train accuracy: 0.760195, Val accuracy: 0.780766\n",
      "Average loss: 0.768003, Train accuracy: 0.775706, Val accuracy: 0.797625\n",
      "Average loss: 0.728875, Train accuracy: 0.786251, Val accuracy: 0.800696\n",
      "Average loss: 0.698964, Train accuracy: 0.797802, Val accuracy: 0.809842\n",
      "End\n",
      "Start lr=0.022153107287919412, l2=1.3650078065460137e-06\n",
      "Average loss: 2.243526, Train accuracy: 0.183838, Val accuracy: 0.190840\n",
      "Average loss: 2.131084, Train accuracy: 0.234976, Val accuracy: 0.344140\n",
      "Average loss: 1.711510, Train accuracy: 0.446524, Val accuracy: 0.516825\n",
      "Average loss: 1.323642, Train accuracy: 0.585179, Val accuracy: 0.651218\n",
      "Average loss: 1.078712, Train accuracy: 0.671740, Val accuracy: 0.714149\n",
      "Average loss: 0.939349, Train accuracy: 0.717930, Val accuracy: 0.740223\n",
      "Average loss: 0.858541, Train accuracy: 0.747620, Val accuracy: 0.771005\n",
      "Average loss: 0.800301, Train accuracy: 0.765604, Val accuracy: 0.787591\n",
      "Average loss: 0.757256, Train accuracy: 0.777327, Val accuracy: 0.793939\n",
      "Average loss: 0.725418, Train accuracy: 0.788759, Val accuracy: 0.801515\n",
      "End\n",
      "Start lr=0.006022517701293912, l2=2.9408201705870607e-06\n",
      "Average loss: 2.266024, Train accuracy: 0.167577, Val accuracy: 0.190908\n",
      "Average loss: 2.240499, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.234577, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.225188, Train accuracy: 0.188820, Val accuracy: 0.191045\n",
      "Average loss: 2.203992, Train accuracy: 0.191465, Val accuracy: 0.195686\n",
      "Average loss: 2.159812, Train accuracy: 0.214688, Val accuracy: 0.241826\n",
      "Average loss: 2.079002, Train accuracy: 0.266048, Val accuracy: 0.300867\n",
      "Average loss: 1.964819, Train accuracy: 0.337491, Val accuracy: 0.379633\n",
      "Average loss: 1.838278, Train accuracy: 0.398133, Val accuracy: 0.434237\n",
      "Average loss: 1.711221, Train accuracy: 0.450995, Val accuracy: 0.480445\n",
      "End\n",
      "Start lr=0.032140365586421596, l2=1.2052609368708414e-07\n",
      "Average loss: 2.231282, Train accuracy: 0.187233, Val accuracy: 0.195345\n",
      "Average loss: 1.852673, Train accuracy: 0.377333, Val accuracy: 0.526517\n",
      "Average loss: 1.276319, Train accuracy: 0.600741, Val accuracy: 0.657361\n",
      "Average loss: 0.993443, Train accuracy: 0.699212, Val accuracy: 0.738107\n",
      "Average loss: 0.856015, Train accuracy: 0.746221, Val accuracy: 0.773326\n",
      "Average loss: 0.779537, Train accuracy: 0.770535, Val accuracy: 0.784793\n",
      "Average loss: 0.729357, Train accuracy: 0.787479, Val accuracy: 0.806703\n",
      "Average loss: 0.688992, Train accuracy: 0.798963, Val accuracy: 0.817146\n",
      "Average loss: 0.656391, Train accuracy: 0.808279, Val accuracy: 0.823562\n",
      "Average loss: 0.630288, Train accuracy: 0.818090, Val accuracy: 0.828817\n",
      "End\n",
      "Start lr=0.006609705742330143, l2=3.9865810735804386e-07\n",
      "Average loss: 2.263951, Train accuracy: 0.169266, Val accuracy: 0.190908\n",
      "Average loss: 2.239719, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.232705, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.219516, Train accuracy: 0.188974, Val accuracy: 0.191728\n",
      "Average loss: 2.187401, Train accuracy: 0.197761, Val accuracy: 0.212272\n",
      "Average loss: 2.119673, Train accuracy: 0.240231, Val accuracy: 0.280936\n",
      "Average loss: 2.006078, Train accuracy: 0.312204, Val accuracy: 0.353901\n",
      "Average loss: 1.870335, Train accuracy: 0.383937, Val accuracy: 0.424476\n",
      "Average loss: 1.731279, Train accuracy: 0.440552, Val accuracy: 0.477715\n",
      "Average loss: 1.594993, Train accuracy: 0.492424, Val accuracy: 0.519691\n",
      "End\n",
      "Start lr=0.13592941213664708, l2=2.1844360711494283e-05\n",
      "Average loss: 1.529954, Train accuracy: 0.482579, Val accuracy: 0.761313\n",
      "Average loss: 0.733795, Train accuracy: 0.782548, Val accuracy: 0.823562\n",
      "Average loss: 0.595442, Train accuracy: 0.825189, Val accuracy: 0.829500\n",
      "Average loss: 0.527313, Train accuracy: 0.844999, Val accuracy: 0.856119\n",
      "Average loss: 0.476648, Train accuracy: 0.859588, Val accuracy: 0.871272\n",
      "Average loss: 0.446061, Train accuracy: 0.868426, Val accuracy: 0.875640\n",
      "Average loss: 0.418062, Train accuracy: 0.877009, Val accuracy: 0.875708\n",
      "Average loss: 0.395685, Train accuracy: 0.882623, Val accuracy: 0.880076\n",
      "Average loss: 0.376909, Train accuracy: 0.888407, Val accuracy: 0.886015\n",
      "Average loss: 0.361382, Train accuracy: 0.892827, Val accuracy: 0.888335\n",
      "End\n",
      "Start lr=0.02320794416806391, l2=1.2476595526308683e-07\n",
      "Average loss: 2.242545, Train accuracy: 0.184213, Val accuracy: 0.190908\n",
      "Average loss: 2.108020, Train accuracy: 0.248166, Val accuracy: 0.367483\n",
      "Average loss: 1.656887, Train accuracy: 0.467119, Val accuracy: 0.536346\n",
      "Average loss: 1.272979, Train accuracy: 0.602890, Val accuracy: 0.664118\n",
      "Average loss: 1.043635, Train accuracy: 0.682490, Val accuracy: 0.723978\n",
      "Average loss: 0.915197, Train accuracy: 0.725898, Val accuracy: 0.746570\n",
      "Average loss: 0.839797, Train accuracy: 0.753745, Val accuracy: 0.775442\n",
      "Average loss: 0.784674, Train accuracy: 0.770570, Val accuracy: 0.792710\n",
      "Average loss: 0.743569, Train accuracy: 0.782241, Val accuracy: 0.797488\n",
      "Average loss: 0.712728, Train accuracy: 0.793724, Val accuracy: 0.805747\n",
      "End\n",
      "Start lr=0.04451075427225197, l2=3.2174181506763714e-06\n",
      "Average loss: 2.188305, Train accuracy: 0.209535, Val accuracy: 0.363388\n",
      "Average loss: 1.479621, Train accuracy: 0.525270, Val accuracy: 0.666098\n",
      "Average loss: 0.998722, Train accuracy: 0.696840, Val accuracy: 0.724592\n",
      "Average loss: 0.830431, Train accuracy: 0.752909, Val accuracy: 0.778036\n",
      "Average loss: 0.739481, Train accuracy: 0.781644, Val accuracy: 0.804245\n",
      "Average loss: 0.684859, Train accuracy: 0.798741, Val accuracy: 0.814961\n",
      "Average loss: 0.642229, Train accuracy: 0.813296, Val accuracy: 0.829363\n",
      "Average loss: 0.607379, Train accuracy: 0.823550, Val accuracy: 0.839738\n",
      "Average loss: 0.577169, Train accuracy: 0.832031, Val accuracy: 0.843560\n",
      "Average loss: 0.552435, Train accuracy: 0.840631, Val accuracy: 0.850795\n",
      "End\n",
      "Start lr=0.013912797011035628, l2=5.2567911220184196e-06\n",
      "Average loss: 2.250881, Train accuracy: 0.179180, Val accuracy: 0.190840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.222783, Train accuracy: 0.189230, Val accuracy: 0.192888\n",
      "Average loss: 2.125299, Train accuracy: 0.238184, Val accuracy: 0.303802\n",
      "Average loss: 1.866454, Train accuracy: 0.384773, Val accuracy: 0.454986\n",
      "Average loss: 1.573180, Train accuracy: 0.500700, Val accuracy: 0.552863\n",
      "Average loss: 1.333963, Train accuracy: 0.582858, Val accuracy: 0.623166\n",
      "Average loss: 1.160507, Train accuracy: 0.647988, Val accuracy: 0.681796\n",
      "Average loss: 1.038189, Train accuracy: 0.687114, Val accuracy: 0.723159\n",
      "Average loss: 0.953012, Train accuracy: 0.714637, Val accuracy: 0.737970\n",
      "Average loss: 0.892924, Train accuracy: 0.735761, Val accuracy: 0.755307\n",
      "End\n",
      "Start lr=0.286118382967511, l2=2.5966559729348725e-05\n",
      "Average loss: 1.163844, Train accuracy: 0.618503, Val accuracy: 0.823425\n",
      "Average loss: 0.574405, Train accuracy: 0.829847, Val accuracy: 0.859600\n",
      "Average loss: 0.478091, Train accuracy: 0.857677, Val accuracy: 0.859259\n",
      "Average loss: 0.426785, Train accuracy: 0.874194, Val accuracy: 0.869360\n",
      "Average loss: 0.390145, Train accuracy: 0.884688, Val accuracy: 0.891543\n",
      "Average loss: 0.366141, Train accuracy: 0.891871, Val accuracy: 0.893386\n",
      "Average loss: 0.343254, Train accuracy: 0.898543, Val accuracy: 0.894069\n",
      "Average loss: 0.330793, Train accuracy: 0.902655, Val accuracy: 0.893523\n",
      "Average loss: 0.315705, Train accuracy: 0.906784, Val accuracy: 0.901372\n",
      "Average loss: 0.302723, Train accuracy: 0.910589, Val accuracy: 0.895092\n",
      "End\n",
      "Start lr=0.47727422833091715, l2=1.1247371783647507e-05\n",
      "Average loss: 1.001599, Train accuracy: 0.677576, Val accuracy: 0.849771\n",
      "Average loss: 0.511194, Train accuracy: 0.847319, Val accuracy: 0.864992\n",
      "Average loss: 0.431889, Train accuracy: 0.871020, Val accuracy: 0.861102\n",
      "Average loss: 0.389647, Train accuracy: 0.883067, Val accuracy: 0.879940\n",
      "Average loss: 0.358627, Train accuracy: 0.893151, Val accuracy: 0.888677\n",
      "Average loss: 0.337991, Train accuracy: 0.899942, Val accuracy: 0.897072\n",
      "Average loss: 0.321331, Train accuracy: 0.905368, Val accuracy: 0.897413\n",
      "Average loss: 0.307524, Train accuracy: 0.908030, Val accuracy: 0.896935\n",
      "Average loss: 0.294433, Train accuracy: 0.912825, Val accuracy: 0.899870\n",
      "Average loss: 0.284072, Train accuracy: 0.915316, Val accuracy: 0.897345\n",
      "End\n",
      "Start lr=0.26070041439998437, l2=9.140310748756223e-05\n",
      "Average loss: 1.207914, Train accuracy: 0.604409, Val accuracy: 0.820558\n",
      "Average loss: 0.589693, Train accuracy: 0.826298, Val accuracy: 0.858644\n",
      "Average loss: 0.490227, Train accuracy: 0.854674, Val accuracy: 0.856665\n",
      "Average loss: 0.439502, Train accuracy: 0.870986, Val accuracy: 0.877210\n",
      "Average loss: 0.399879, Train accuracy: 0.881121, Val accuracy: 0.888745\n",
      "Average loss: 0.375192, Train accuracy: 0.889807, Val accuracy: 0.891680\n",
      "Average loss: 0.352920, Train accuracy: 0.896700, Val accuracy: 0.888677\n",
      "Average loss: 0.335421, Train accuracy: 0.900744, Val accuracy: 0.892977\n",
      "Average loss: 0.322350, Train accuracy: 0.904805, Val accuracy: 0.897072\n",
      "Average loss: 0.308654, Train accuracy: 0.908764, Val accuracy: 0.901167\n",
      "End\n",
      "Start lr=0.02431300790032677, l2=7.636298261282242e-05\n",
      "Average loss: 2.241632, Train accuracy: 0.184742, Val accuracy: 0.191113\n",
      "Average loss: 2.082432, Train accuracy: 0.262362, Val accuracy: 0.392601\n",
      "Average loss: 1.601241, Train accuracy: 0.487953, Val accuracy: 0.558392\n",
      "Average loss: 1.225300, Train accuracy: 0.618810, Val accuracy: 0.677019\n",
      "Average loss: 1.009958, Train accuracy: 0.693973, Val accuracy: 0.731964\n",
      "Average loss: 0.891267, Train accuracy: 0.733713, Val accuracy: 0.752235\n",
      "Average loss: 0.821196, Train accuracy: 0.759257, Val accuracy: 0.779810\n",
      "Average loss: 0.769004, Train accuracy: 0.775330, Val accuracy: 0.796464\n",
      "Average loss: 0.729756, Train accuracy: 0.786694, Val accuracy: 0.800014\n",
      "Average loss: 0.700059, Train accuracy: 0.797512, Val accuracy: 0.809842\n",
      "End\n",
      "Start lr=0.47727422833091715, l2=6.883952069645496e-06\n",
      "Average loss: 0.994446, Train accuracy: 0.680203, Val accuracy: 0.848406\n",
      "Average loss: 0.507708, Train accuracy: 0.850681, Val accuracy: 0.868473\n",
      "Average loss: 0.431358, Train accuracy: 0.871924, Val accuracy: 0.871613\n",
      "Average loss: 0.389793, Train accuracy: 0.884193, Val accuracy: 0.884786\n",
      "Average loss: 0.356102, Train accuracy: 0.892810, Val accuracy: 0.892158\n",
      "Average loss: 0.339274, Train accuracy: 0.899089, Val accuracy: 0.894342\n",
      "Average loss: 0.319626, Train accuracy: 0.905487, Val accuracy: 0.895502\n",
      "Average loss: 0.305435, Train accuracy: 0.909856, Val accuracy: 0.899802\n",
      "Average loss: 0.293374, Train accuracy: 0.912722, Val accuracy: 0.902123\n",
      "Average loss: 0.283771, Train accuracy: 0.915981, Val accuracy: 0.897618\n",
      "End\n",
      "Start lr=0.04248767179543224, l2=2.4231727942376005e-06\n",
      "Average loss: 2.197433, Train accuracy: 0.203972, Val accuracy: 0.338885\n",
      "Average loss: 1.532473, Train accuracy: 0.505733, Val accuracy: 0.652174\n",
      "Average loss: 1.027025, Train accuracy: 0.687199, Val accuracy: 0.718791\n",
      "Average loss: 0.847128, Train accuracy: 0.747620, Val accuracy: 0.774418\n",
      "Average loss: 0.752062, Train accuracy: 0.779272, Val accuracy: 0.801925\n",
      "Average loss: 0.695572, Train accuracy: 0.795789, Val accuracy: 0.810184\n",
      "Average loss: 0.651498, Train accuracy: 0.810395, Val accuracy: 0.827862\n",
      "Average loss: 0.617110, Train accuracy: 0.820769, Val accuracy: 0.836871\n",
      "Average loss: 0.586954, Train accuracy: 0.830034, Val accuracy: 0.840762\n",
      "Average loss: 0.562069, Train accuracy: 0.837133, Val accuracy: 0.847792\n",
      "End\n",
      "Start lr=0.005487493827465278, l2=2.0244465099768016e-05\n",
      "Average loss: 2.268352, Train accuracy: 0.164932, Val accuracy: 0.190840\n",
      "Average loss: 2.241238, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.236052, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.228838, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.214355, Train accuracy: 0.189588, Val accuracy: 0.192274\n",
      "Average loss: 2.184790, Train accuracy: 0.198034, Val accuracy: 0.219439\n",
      "Average loss: 2.129753, Train accuracy: 0.236392, Val accuracy: 0.254454\n",
      "Average loss: 2.044113, Train accuracy: 0.290090, Val accuracy: 0.337247\n",
      "Average loss: 1.935852, Train accuracy: 0.354128, Val accuracy: 0.387073\n",
      "Average loss: 1.822554, Train accuracy: 0.405931, Val accuracy: 0.437786\n",
      "End\n",
      "Start lr=0.006022517701293912, l2=4.483855948021191e-07\n",
      "Average loss: 2.266020, Train accuracy: 0.167594, Val accuracy: 0.190908\n",
      "Average loss: 2.240499, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.234575, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.225177, Train accuracy: 0.188820, Val accuracy: 0.191045\n",
      "Average loss: 2.203948, Train accuracy: 0.191329, Val accuracy: 0.195413\n",
      "Average loss: 2.159690, Train accuracy: 0.214449, Val accuracy: 0.242031\n",
      "Average loss: 2.078891, Train accuracy: 0.266065, Val accuracy: 0.301345\n",
      "Average loss: 1.964783, Train accuracy: 0.337355, Val accuracy: 0.380315\n",
      "Average loss: 1.838132, Train accuracy: 0.398543, Val accuracy: 0.434441\n",
      "Average loss: 1.711124, Train accuracy: 0.450841, Val accuracy: 0.480923\n",
      "End\n",
      "Start lr=0.00915369140147684, l2=4.098383671757261e-05\n",
      "Average loss: 2.257503, Train accuracy: 0.174760, Val accuracy: 0.190840\n",
      "Average loss: 2.235844, Train accuracy: 0.188854, Val accuracy: 0.190840\n",
      "Average loss: 2.218575, Train accuracy: 0.189127, Val accuracy: 0.191932\n",
      "Average loss: 2.165179, Train accuracy: 0.210968, Val accuracy: 0.244147\n",
      "Average loss: 2.028411, Train accuracy: 0.298877, Val accuracy: 0.356972\n",
      "Average loss: 1.839771, Train accuracy: 0.396444, Val accuracy: 0.439833\n",
      "Average loss: 1.651184, Train accuracy: 0.471880, Val accuracy: 0.502901\n",
      "Average loss: 1.476569, Train accuracy: 0.534229, Val accuracy: 0.575183\n",
      "Average loss: 1.324501, Train accuracy: 0.589684, Val accuracy: 0.624053\n",
      "Average loss: 1.201809, Train accuracy: 0.630635, Val accuracy: 0.656064\n",
      "End\n",
      "Start lr=0.016758013254694205, l2=1.5037553212997384e-06\n",
      "Average loss: 2.248163, Train accuracy: 0.181483, Val accuracy: 0.190840\n",
      "Average loss: 2.207282, Train accuracy: 0.193069, Val accuracy: 0.224831\n",
      "Average loss: 2.007684, Train accuracy: 0.310275, Val accuracy: 0.391304\n",
      "Average loss: 1.655664, Train accuracy: 0.469935, Val accuracy: 0.536755\n",
      "Average loss: 1.349790, Train accuracy: 0.579139, Val accuracy: 0.636202\n",
      "Average loss: 1.135409, Train accuracy: 0.653380, Val accuracy: 0.680841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.005744, Train accuracy: 0.698853, Val accuracy: 0.730462\n",
      "Average loss: 0.918416, Train accuracy: 0.727690, Val accuracy: 0.758310\n",
      "Average loss: 0.857439, Train accuracy: 0.745794, Val accuracy: 0.765067\n",
      "Average loss: 0.813628, Train accuracy: 0.762038, Val accuracy: 0.776944\n",
      "End\n",
      "Start lr=0.18824679033962347, l2=1.1016459496336569e-07\n",
      "Average loss: 1.343862, Train accuracy: 0.554141, Val accuracy: 0.797283\n",
      "Average loss: 0.646207, Train accuracy: 0.810719, Val accuracy: 0.844994\n",
      "Average loss: 0.528100, Train accuracy: 0.844231, Val accuracy: 0.849498\n",
      "Average loss: 0.469110, Train accuracy: 0.861175, Val accuracy: 0.866425\n",
      "Average loss: 0.425137, Train accuracy: 0.874450, Val accuracy: 0.881783\n",
      "Average loss: 0.399500, Train accuracy: 0.881053, Val accuracy: 0.885332\n",
      "Average loss: 0.373191, Train accuracy: 0.890728, Val accuracy: 0.888472\n",
      "Average loss: 0.355293, Train accuracy: 0.895233, Val accuracy: 0.894273\n",
      "Average loss: 0.339548, Train accuracy: 0.900471, Val accuracy: 0.898710\n",
      "Average loss: 0.326745, Train accuracy: 0.903389, Val accuracy: 0.900007\n",
      "End\n",
      "Start lr=0.3140145720917128, l2=4.577840538376616e-06\n",
      "Average loss: 1.126739, Train accuracy: 0.632597, Val accuracy: 0.832025\n",
      "Average loss: 0.558047, Train accuracy: 0.835205, Val accuracy: 0.859327\n",
      "Average loss: 0.468919, Train accuracy: 0.862028, Val accuracy: 0.861375\n",
      "Average loss: 0.419529, Train accuracy: 0.875764, Val accuracy: 0.884308\n",
      "Average loss: 0.384057, Train accuracy: 0.885592, Val accuracy: 0.890110\n",
      "Average loss: 0.360643, Train accuracy: 0.893390, Val accuracy: 0.890997\n",
      "Average loss: 0.340445, Train accuracy: 0.900710, Val accuracy: 0.890451\n",
      "Average loss: 0.325582, Train accuracy: 0.904686, Val accuracy: 0.891748\n",
      "Average loss: 0.309890, Train accuracy: 0.908712, Val accuracy: 0.900007\n",
      "Average loss: 0.296379, Train accuracy: 0.912091, Val accuracy: 0.897208\n",
      "End\n",
      "Start lr=0.17152346431574594, l2=1.1805165285688056e-05\n",
      "Average loss: 1.399056, Train accuracy: 0.532812, Val accuracy: 0.786158\n",
      "Average loss: 0.673896, Train accuracy: 0.801215, Val accuracy: 0.840966\n",
      "Average loss: 0.544787, Train accuracy: 0.839027, Val accuracy: 0.843151\n",
      "Average loss: 0.482475, Train accuracy: 0.857540, Val accuracy: 0.867381\n",
      "Average loss: 0.436658, Train accuracy: 0.871105, Val accuracy: 0.879257\n",
      "Average loss: 0.409307, Train accuracy: 0.879876, Val accuracy: 0.878370\n",
      "Average loss: 0.383553, Train accuracy: 0.887537, Val accuracy: 0.885810\n",
      "Average loss: 0.364513, Train accuracy: 0.892622, Val accuracy: 0.887448\n",
      "Average loss: 0.347748, Train accuracy: 0.897400, Val accuracy: 0.893181\n",
      "Average loss: 0.333577, Train accuracy: 0.900710, Val accuracy: 0.891816\n",
      "End\n",
      "Start lr=0.08943247645287175, l2=3.904735236885556e-05\n",
      "Average loss: 1.823032, Train accuracy: 0.369280, Val accuracy: 0.676541\n",
      "Average loss: 0.889715, Train accuracy: 0.732212, Val accuracy: 0.791414\n",
      "Average loss: 0.689222, Train accuracy: 0.797666, Val accuracy: 0.801788\n",
      "Average loss: 0.604480, Train accuracy: 0.824728, Val accuracy: 0.843628\n",
      "Average loss: 0.546153, Train accuracy: 0.840699, Val accuracy: 0.857757\n",
      "Average loss: 0.511607, Train accuracy: 0.849367, Val accuracy: 0.861579\n",
      "Average loss: 0.477380, Train accuracy: 0.861055, Val accuracy: 0.867381\n",
      "Average loss: 0.452929, Train accuracy: 0.865986, Val accuracy: 0.869565\n",
      "Average loss: 0.433574, Train accuracy: 0.872624, Val accuracy: 0.876322\n",
      "Average loss: 0.415811, Train accuracy: 0.877589, Val accuracy: 0.877005\n",
      "End\n",
      "Start lr=0.053613361100516184, l2=1.9287915080207776e-07\n",
      "Average loss: 2.124344, Train accuracy: 0.242535, Val accuracy: 0.459013\n",
      "Average loss: 1.263758, Train accuracy: 0.603095, Val accuracy: 0.714490\n",
      "Average loss: 0.895082, Train accuracy: 0.731000, Val accuracy: 0.747526\n",
      "Average loss: 0.762982, Train accuracy: 0.774511, Val accuracy: 0.794690\n",
      "Average loss: 0.683776, Train accuracy: 0.798758, Val accuracy: 0.820900\n",
      "Average loss: 0.634068, Train accuracy: 0.813364, Val accuracy: 0.831001\n",
      "Average loss: 0.593012, Train accuracy: 0.828550, Val accuracy: 0.842878\n",
      "Average loss: 0.562125, Train accuracy: 0.837099, Val accuracy: 0.851614\n",
      "Average loss: 0.535281, Train accuracy: 0.844214, Val accuracy: 0.853048\n",
      "Average loss: 0.512823, Train accuracy: 0.852114, Val accuracy: 0.857075\n",
      "End\n",
      "Start lr=0.005748784976988678, l2=1.5892828656229765e-05\n",
      "Average loss: 2.267151, Train accuracy: 0.166092, Val accuracy: 0.190840\n",
      "Average loss: 2.240850, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.235338, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.227169, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.209760, Train accuracy: 0.190322, Val accuracy: 0.193366\n",
      "Average loss: 2.173804, Train accuracy: 0.205593, Val accuracy: 0.231247\n",
      "Average loss: 2.106867, Train accuracy: 0.248336, Val accuracy: 0.277387\n",
      "Average loss: 2.006889, Train accuracy: 0.313227, Val accuracy: 0.355198\n",
      "Average loss: 1.888559, Train accuracy: 0.376071, Val accuracy: 0.411986\n",
      "Average loss: 1.768536, Train accuracy: 0.428847, Val accuracy: 0.457989\n",
      "End\n",
      "Start lr=0.013912797011035628, l2=4.905583706365046e-07\n",
      "Average loss: 2.250907, Train accuracy: 0.179180, Val accuracy: 0.190840\n",
      "Average loss: 2.222935, Train accuracy: 0.189213, Val accuracy: 0.192820\n",
      "Average loss: 2.126178, Train accuracy: 0.237604, Val accuracy: 0.301686\n",
      "Average loss: 1.868300, Train accuracy: 0.383118, Val accuracy: 0.452870\n",
      "Average loss: 1.575679, Train accuracy: 0.499642, Val accuracy: 0.550406\n",
      "Average loss: 1.335688, Train accuracy: 0.582637, Val accuracy: 0.622551\n",
      "Average loss: 1.161093, Train accuracy: 0.647886, Val accuracy: 0.681728\n",
      "Average loss: 1.039199, Train accuracy: 0.687523, Val accuracy: 0.723227\n",
      "Average loss: 0.954423, Train accuracy: 0.714551, Val accuracy: 0.738721\n",
      "Average loss: 0.894247, Train accuracy: 0.735266, Val accuracy: 0.755512\n",
      "End\n",
      "Start lr=0.009589551308362443, l2=3.2397426295281954e-07\n",
      "Average loss: 2.256688, Train accuracy: 0.175613, Val accuracy: 0.190840\n",
      "Average loss: 2.235008, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.214516, Train accuracy: 0.189656, Val accuracy: 0.192751\n",
      "Average loss: 2.147750, Train accuracy: 0.222366, Val accuracy: 0.261893\n",
      "Average loss: 1.987322, Train accuracy: 0.322493, Val accuracy: 0.379292\n",
      "Average loss: 1.787035, Train accuracy: 0.417858, Val accuracy: 0.458262\n",
      "Average loss: 1.593571, Train accuracy: 0.492253, Val accuracy: 0.523309\n",
      "Average loss: 1.420180, Train accuracy: 0.553390, Val accuracy: 0.595796\n",
      "Average loss: 1.273121, Train accuracy: 0.606303, Val accuracy: 0.639820\n",
      "Average loss: 1.158015, Train accuracy: 0.646043, Val accuracy: 0.670603\n",
      "End\n",
      "Start lr=0.01839189885914317, l2=1.2738113231864784e-07\n",
      "Average loss: 2.246689, Train accuracy: 0.182336, Val accuracy: 0.190840\n",
      "Average loss: 2.190392, Train accuracy: 0.201856, Val accuracy: 0.250973\n",
      "Average loss: 1.913167, Train accuracy: 0.358445, Val accuracy: 0.437240\n",
      "Average loss: 1.534751, Train accuracy: 0.511193, Val accuracy: 0.577845\n",
      "Average loss: 1.246133, Train accuracy: 0.613794, Val accuracy: 0.665620\n",
      "Average loss: 1.060228, Train accuracy: 0.677320, Val accuracy: 0.705276\n",
      "Average loss: 0.950051, Train accuracy: 0.716753, Val accuracy: 0.747184\n",
      "Average loss: 0.873643, Train accuracy: 0.742364, Val accuracy: 0.770323\n",
      "Average loss: 0.819748, Train accuracy: 0.757585, Val accuracy: 0.776466\n",
      "Average loss: 0.780875, Train accuracy: 0.771474, Val accuracy: 0.785134\n",
      "End\n",
      "Start lr=0.008737642000038414, l2=3.0024617090855494e-07\n",
      "Average loss: 2.258286, Train accuracy: 0.173975, Val accuracy: 0.190840\n",
      "Average loss: 2.236507, Train accuracy: 0.188871, Val accuracy: 0.190840\n",
      "Average loss: 2.221657, Train accuracy: 0.188991, Val accuracy: 0.191250\n",
      "Average loss: 2.177939, Train accuracy: 0.203563, Val accuracy: 0.231588\n",
      "Average loss: 2.063918, Train accuracy: 0.277531, Val accuracy: 0.333493\n",
      "Average loss: 1.889971, Train accuracy: 0.373153, Val accuracy: 0.417514\n",
      "Average loss: 1.708908, Train accuracy: 0.450346, Val accuracy: 0.483312\n",
      "Average loss: 1.536368, Train accuracy: 0.512866, Val accuracy: 0.553205\n",
      "Average loss: 1.383512, Train accuracy: 0.568116, Val accuracy: 0.603099\n",
      "Average loss: 1.253461, Train accuracy: 0.611951, Val accuracy: 0.639001\n",
      "End\n",
      "Start lr=0.12975121056998687, l2=1.2476595526308685e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.566646, Train accuracy: 0.469150, Val accuracy: 0.754761\n",
      "Average loss: 0.743720, Train accuracy: 0.779084, Val accuracy: 0.821582\n",
      "Average loss: 0.602459, Train accuracy: 0.823858, Val accuracy: 0.825336\n",
      "Average loss: 0.532558, Train accuracy: 0.844623, Val accuracy: 0.857416\n",
      "Average loss: 0.481606, Train accuracy: 0.858120, Val accuracy: 0.868746\n",
      "Average loss: 0.449933, Train accuracy: 0.868205, Val accuracy: 0.873592\n",
      "Average loss: 0.422200, Train accuracy: 0.876190, Val accuracy: 0.876459\n",
      "Average loss: 0.400106, Train accuracy: 0.882094, Val accuracy: 0.882738\n",
      "Average loss: 0.382664, Train accuracy: 0.887213, Val accuracy: 0.886015\n",
      "Average loss: 0.368477, Train accuracy: 0.891120, Val accuracy: 0.887994\n",
      "End\n",
      "Start lr=0.26070041439998437, l2=2.43998629725955e-05\n",
      "Average loss: 1.215733, Train accuracy: 0.600706, Val accuracy: 0.817692\n",
      "Average loss: 0.590443, Train accuracy: 0.825189, Val accuracy: 0.857689\n",
      "Average loss: 0.487860, Train accuracy: 0.856346, Val accuracy: 0.860624\n",
      "Average loss: 0.436274, Train accuracy: 0.871668, Val accuracy: 0.876118\n",
      "Average loss: 0.395023, Train accuracy: 0.882316, Val accuracy: 0.889837\n",
      "Average loss: 0.373442, Train accuracy: 0.889670, Val accuracy: 0.895707\n",
      "Average loss: 0.349692, Train accuracy: 0.896376, Val accuracy: 0.891475\n",
      "Average loss: 0.331804, Train accuracy: 0.901290, Val accuracy: 0.891134\n",
      "Average loss: 0.317569, Train accuracy: 0.906358, Val accuracy: 0.901508\n",
      "Average loss: 0.305493, Train accuracy: 0.908798, Val accuracy: 0.893932\n",
      "End\n",
      "Start lr=0.10282561541743257, l2=1.1092898648952227e-05\n",
      "Average loss: 1.724386, Train accuracy: 0.409992, Val accuracy: 0.713535\n",
      "Average loss: 0.828466, Train accuracy: 0.752773, Val accuracy: 0.804177\n",
      "Average loss: 0.655627, Train accuracy: 0.808211, Val accuracy: 0.811207\n",
      "Average loss: 0.574626, Train accuracy: 0.832355, Val accuracy: 0.849703\n",
      "Average loss: 0.519769, Train accuracy: 0.847507, Val accuracy: 0.859327\n",
      "Average loss: 0.484595, Train accuracy: 0.858598, Val accuracy: 0.867040\n",
      "Average loss: 0.453197, Train accuracy: 0.866891, Val accuracy: 0.870453\n",
      "Average loss: 0.426943, Train accuracy: 0.874108, Val accuracy: 0.873114\n",
      "Average loss: 0.409531, Train accuracy: 0.879535, Val accuracy: 0.881169\n",
      "Average loss: 0.393179, Train accuracy: 0.884159, Val accuracy: 0.879053\n",
      "End\n",
      "Start lr=0.03871318413405635, l2=5.2567911220184196e-06\n",
      "Average loss: 2.213447, Train accuracy: 0.194690, Val accuracy: 0.277114\n",
      "Average loss: 1.645662, Train accuracy: 0.463724, Val accuracy: 0.615385\n",
      "Average loss: 1.101839, Train accuracy: 0.661093, Val accuracy: 0.701317\n",
      "Average loss: 0.891428, Train accuracy: 0.733935, Val accuracy: 0.759743\n",
      "Average loss: 0.787091, Train accuracy: 0.768095, Val accuracy: 0.792233\n",
      "Average loss: 0.727220, Train accuracy: 0.785892, Val accuracy: 0.799877\n",
      "Average loss: 0.683106, Train accuracy: 0.800515, Val accuracy: 0.819876\n",
      "Average loss: 0.647621, Train accuracy: 0.811214, Val accuracy: 0.827452\n",
      "Average loss: 0.616197, Train accuracy: 0.821110, Val accuracy: 0.833595\n",
      "Average loss: 0.590974, Train accuracy: 0.829113, Val accuracy: 0.838919\n",
      "End\n",
      "Start lr=0.06765238872899038, l2=8.648423275731726e-06\n",
      "Average loss: 1.999021, Train accuracy: 0.298092, Val accuracy: 0.587468\n",
      "Average loss: 1.051273, Train accuracy: 0.676774, Val accuracy: 0.760767\n",
      "Average loss: 0.781854, Train accuracy: 0.768351, Val accuracy: 0.776329\n",
      "Average loss: 0.673459, Train accuracy: 0.803331, Val accuracy: 0.824039\n",
      "Average loss: 0.604203, Train accuracy: 0.823875, Val accuracy: 0.837827\n",
      "Average loss: 0.563478, Train accuracy: 0.835921, Val accuracy: 0.846973\n",
      "Average loss: 0.526264, Train accuracy: 0.848121, Val accuracy: 0.857689\n",
      "Average loss: 0.499127, Train accuracy: 0.853855, Val accuracy: 0.862808\n",
      "Average loss: 0.475519, Train accuracy: 0.861004, Val accuracy: 0.868337\n",
      "Average loss: 0.455069, Train accuracy: 0.866362, Val accuracy: 0.870657\n",
      "End\n",
      "Start lr=0.017555958671075653, l2=1.2052609368708414e-07\n",
      "Average loss: 2.247450, Train accuracy: 0.181739, Val accuracy: 0.190840\n",
      "Average loss: 2.200469, Train accuracy: 0.196430, Val accuracy: 0.235615\n",
      "Average loss: 1.966169, Train accuracy: 0.332082, Val accuracy: 0.411849\n",
      "Average loss: 1.599553, Train accuracy: 0.489813, Val accuracy: 0.557982\n",
      "Average loss: 1.300170, Train accuracy: 0.595059, Val accuracy: 0.650468\n",
      "Average loss: 1.098655, Train accuracy: 0.664591, Val accuracy: 0.693127\n",
      "Average loss: 0.978458, Train accuracy: 0.707590, Val accuracy: 0.739540\n",
      "Average loss: 0.895797, Train accuracy: 0.735761, Val accuracy: 0.763429\n",
      "Average loss: 0.838205, Train accuracy: 0.752244, Val accuracy: 0.770391\n",
      "Average loss: 0.796652, Train accuracy: 0.767072, Val accuracy: 0.781380\n",
      "End\n",
      "Start lr=0.03695361016762888, l2=1.042360673976401e-06\n",
      "Average loss: 2.219042, Train accuracy: 0.191977, Val accuracy: 0.248106\n",
      "Average loss: 1.694042, Train accuracy: 0.444016, Val accuracy: 0.597638\n",
      "Average loss: 1.136375, Train accuracy: 0.648807, Val accuracy: 0.689646\n",
      "Average loss: 0.912760, Train accuracy: 0.727263, Val accuracy: 0.755443\n",
      "Average loss: 0.802355, Train accuracy: 0.763403, Val accuracy: 0.788956\n",
      "Average loss: 0.738560, Train accuracy: 0.782377, Val accuracy: 0.796191\n",
      "Average loss: 0.692848, Train accuracy: 0.797683, Val accuracy: 0.815507\n",
      "Average loss: 0.656017, Train accuracy: 0.808808, Val accuracy: 0.826360\n",
      "Average loss: 0.624188, Train accuracy: 0.818449, Val accuracy: 0.831479\n",
      "Average loss: 0.598139, Train accuracy: 0.828243, Val accuracy: 0.837759\n",
      "End\n",
      "Start lr=0.01926764296855264, l2=7.479522515621829e-05\n",
      "Average loss: 2.245970, Train accuracy: 0.182814, Val accuracy: 0.190840\n",
      "Average loss: 2.179299, Train accuracy: 0.206941, Val accuracy: 0.268855\n",
      "Average loss: 1.868340, Train accuracy: 0.379330, Val accuracy: 0.454440\n",
      "Average loss: 1.486532, Train accuracy: 0.527250, Val accuracy: 0.598594\n",
      "Average loss: 1.204217, Train accuracy: 0.628332, Val accuracy: 0.678384\n",
      "Average loss: 1.028906, Train accuracy: 0.688172, Val accuracy: 0.713671\n",
      "Average loss: 0.926706, Train accuracy: 0.724670, Val accuracy: 0.753191\n",
      "Average loss: 0.854842, Train accuracy: 0.747722, Val accuracy: 0.775442\n",
      "Average loss: 0.803796, Train accuracy: 0.763130, Val accuracy: 0.780083\n",
      "Average loss: 0.766868, Train accuracy: 0.776695, Val accuracy: 0.789093\n",
      "End\n",
      "Start lr=0.15628579248441185, l2=8.296958520834915e-06\n",
      "Average loss: 1.445049, Train accuracy: 0.516039, Val accuracy: 0.778104\n",
      "Average loss: 0.695990, Train accuracy: 0.795021, Val accuracy: 0.835574\n",
      "Average loss: 0.564584, Train accuracy: 0.834556, Val accuracy: 0.837759\n",
      "Average loss: 0.500185, Train accuracy: 0.853394, Val accuracy: 0.861238\n",
      "Average loss: 0.452632, Train accuracy: 0.866328, Val accuracy: 0.877415\n",
      "Average loss: 0.424154, Train accuracy: 0.875951, Val accuracy: 0.879667\n",
      "Average loss: 0.396679, Train accuracy: 0.883664, Val accuracy: 0.884718\n",
      "Average loss: 0.375865, Train accuracy: 0.889807, Val accuracy: 0.886424\n",
      "Average loss: 0.359753, Train accuracy: 0.894243, Val accuracy: 0.891270\n",
      "Average loss: 0.346748, Train accuracy: 0.897758, Val accuracy: 0.893727\n",
      "End\n",
      "Start lr=0.34463060521748495, l2=2.614673211801092e-06\n",
      "Average loss: 1.100992, Train accuracy: 0.641624, Val accuracy: 0.832776\n",
      "Average loss: 0.551959, Train accuracy: 0.836843, Val accuracy: 0.861579\n",
      "Average loss: 0.463278, Train accuracy: 0.862488, Val accuracy: 0.869019\n",
      "Average loss: 0.415153, Train accuracy: 0.877589, Val accuracy: 0.878097\n",
      "Average loss: 0.380992, Train accuracy: 0.888390, Val accuracy: 0.894273\n",
      "Average loss: 0.357451, Train accuracy: 0.894533, Val accuracy: 0.893727\n",
      "Average loss: 0.335625, Train accuracy: 0.901887, Val accuracy: 0.891338\n",
      "Average loss: 0.321083, Train accuracy: 0.905470, Val accuracy: 0.893181\n",
      "Average loss: 0.304607, Train accuracy: 0.908832, Val accuracy: 0.902054\n",
      "Average loss: 0.292449, Train accuracy: 0.913234, Val accuracy: 0.895570\n",
      "End\n",
      "Start lr=0.08536763237353458, l2=4.7062248498412817e-07\n",
      "Average loss: 1.851503, Train accuracy: 0.357881, Val accuracy: 0.665142\n",
      "Average loss: 0.909902, Train accuracy: 0.725079, Val accuracy: 0.786567\n",
      "Average loss: 0.702599, Train accuracy: 0.792939, Val accuracy: 0.797693\n",
      "Average loss: 0.613836, Train accuracy: 0.821708, Val accuracy: 0.840693\n",
      "Average loss: 0.554838, Train accuracy: 0.838003, Val accuracy: 0.852229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.519011, Train accuracy: 0.849077, Val accuracy: 0.857006\n",
      "Average loss: 0.484004, Train accuracy: 0.858223, Val accuracy: 0.865879\n",
      "Average loss: 0.459457, Train accuracy: 0.865475, Val accuracy: 0.869224\n",
      "Average loss: 0.438837, Train accuracy: 0.870832, Val accuracy: 0.875094\n",
      "Average loss: 0.421196, Train accuracy: 0.877077, Val accuracy: 0.876664\n",
      "End\n",
      "Start lr=0.005, l2=1.3462605792989111e-06\n",
      "Average loss: 2.270792, Train accuracy: 0.162253, Val accuracy: 0.190840\n",
      "Average loss: 2.241947, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.237290, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.231557, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.221354, Train accuracy: 0.188974, Val accuracy: 0.191181\n",
      "Average loss: 2.201503, Train accuracy: 0.190663, Val accuracy: 0.197188\n",
      "Average loss: 2.164858, Train accuracy: 0.211804, Val accuracy: 0.221623\n",
      "Average loss: 2.104211, Train accuracy: 0.251152, Val accuracy: 0.294860\n",
      "Average loss: 2.018386, Train accuracy: 0.306470, Val accuracy: 0.339567\n",
      "Average loss: 1.918782, Train accuracy: 0.362045, Val accuracy: 0.391850\n",
      "End\n",
      "Start lr=0.016758013254694205, l2=7.479522515621829e-05\n",
      "Average loss: 2.248177, Train accuracy: 0.181432, Val accuracy: 0.190840\n",
      "Average loss: 2.207402, Train accuracy: 0.193103, Val accuracy: 0.223534\n",
      "Average loss: 2.009694, Train accuracy: 0.309064, Val accuracy: 0.389120\n",
      "Average loss: 1.659682, Train accuracy: 0.468160, Val accuracy: 0.535663\n",
      "Average loss: 1.354523, Train accuracy: 0.576153, Val accuracy: 0.633336\n",
      "Average loss: 1.139574, Train accuracy: 0.651384, Val accuracy: 0.679066\n",
      "Average loss: 1.009072, Train accuracy: 0.697830, Val accuracy: 0.728892\n",
      "Average loss: 0.920938, Train accuracy: 0.727724, Val accuracy: 0.756467\n",
      "Average loss: 0.859081, Train accuracy: 0.745214, Val accuracy: 0.764726\n",
      "Average loss: 0.814903, Train accuracy: 0.761321, Val accuracy: 0.776944\n",
      "End\n",
      "Start lr=0.17152346431574594, l2=1.714881969870541e-05\n",
      "Average loss: 1.404865, Train accuracy: 0.531021, Val accuracy: 0.787182\n",
      "Average loss: 0.669953, Train accuracy: 0.802785, Val accuracy: 0.844243\n",
      "Average loss: 0.541791, Train accuracy: 0.841125, Val accuracy: 0.850113\n",
      "Average loss: 0.479630, Train accuracy: 0.859997, Val accuracy: 0.868883\n",
      "Average loss: 0.432925, Train accuracy: 0.872061, Val accuracy: 0.880486\n",
      "Average loss: 0.405327, Train accuracy: 0.881138, Val accuracy: 0.886970\n",
      "Average loss: 0.378989, Train accuracy: 0.888424, Val accuracy: 0.891475\n",
      "Average loss: 0.360338, Train accuracy: 0.893253, Val accuracy: 0.889359\n",
      "Average loss: 0.343884, Train accuracy: 0.899259, Val accuracy: 0.900007\n",
      "Average loss: 0.330078, Train accuracy: 0.902143, Val accuracy: 0.896526\n",
      "End\n",
      "Start lr=0.005487493827465278, l2=1.1887076977119033e-06\n",
      "Average loss: 2.268346, Train accuracy: 0.164915, Val accuracy: 0.190840\n",
      "Average loss: 2.241238, Train accuracy: 0.188820, Val accuracy: 0.190840\n",
      "Average loss: 2.236044, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.228817, Train accuracy: 0.188803, Val accuracy: 0.190840\n",
      "Average loss: 2.214294, Train accuracy: 0.189622, Val accuracy: 0.192274\n",
      "Average loss: 2.184679, Train accuracy: 0.198171, Val accuracy: 0.219507\n",
      "Average loss: 2.129500, Train accuracy: 0.236597, Val accuracy: 0.255204\n",
      "Average loss: 2.043691, Train accuracy: 0.290243, Val accuracy: 0.337315\n",
      "Average loss: 1.935258, Train accuracy: 0.354196, Val accuracy: 0.387277\n",
      "Average loss: 1.821817, Train accuracy: 0.406272, Val accuracy: 0.438059\n",
      "End\n",
      "Start lr=0.12385381779958557, l2=2.3246970599856456e-06\n",
      "Average loss: 1.588919, Train accuracy: 0.461506, Val accuracy: 0.748891\n",
      "Average loss: 0.755159, Train accuracy: 0.776490, Val accuracy: 0.818852\n",
      "Average loss: 0.611561, Train accuracy: 0.820513, Val accuracy: 0.825746\n",
      "Average loss: 0.541202, Train accuracy: 0.841740, Val accuracy: 0.857211\n",
      "Average loss: 0.488854, Train accuracy: 0.855936, Val accuracy: 0.865402\n",
      "Average loss: 0.457532, Train accuracy: 0.865696, Val accuracy: 0.874889\n",
      "Average loss: 0.428402, Train accuracy: 0.873887, Val accuracy: 0.877073\n",
      "Average loss: 0.404960, Train accuracy: 0.879790, Val accuracy: 0.879735\n",
      "Average loss: 0.386931, Train accuracy: 0.885336, Val accuracy: 0.883148\n",
      "Average loss: 0.372110, Train accuracy: 0.889414, Val accuracy: 0.888062\n",
      "End\n",
      "Start lr=0.016758013254694205, l2=8.829699955494083e-06\n",
      "Average loss: 2.248153, Train accuracy: 0.181449, Val accuracy: 0.190840\n",
      "Average loss: 2.206899, Train accuracy: 0.193086, Val accuracy: 0.225172\n",
      "Average loss: 2.006210, Train accuracy: 0.311350, Val accuracy: 0.392055\n",
      "Average loss: 1.654950, Train accuracy: 0.470208, Val accuracy: 0.537028\n",
      "Average loss: 1.349690, Train accuracy: 0.579036, Val accuracy: 0.636202\n",
      "Average loss: 1.135381, Train accuracy: 0.652868, Val accuracy: 0.681319\n",
      "Average loss: 1.005508, Train accuracy: 0.698870, Val accuracy: 0.730257\n",
      "Average loss: 0.917896, Train accuracy: 0.728390, Val accuracy: 0.757764\n",
      "Average loss: 0.856929, Train accuracy: 0.746101, Val accuracy: 0.765477\n",
      "Average loss: 0.812945, Train accuracy: 0.761748, Val accuracy: 0.776739\n",
      "End\n",
      "Start lr=0.08536763237353458, l2=1.0715933998226711e-05\n",
      "Average loss: 1.850838, Train accuracy: 0.358291, Val accuracy: 0.668487\n",
      "Average loss: 0.905477, Train accuracy: 0.727451, Val accuracy: 0.788342\n",
      "Average loss: 0.699656, Train accuracy: 0.794031, Val accuracy: 0.796260\n",
      "Average loss: 0.612121, Train accuracy: 0.821162, Val accuracy: 0.840830\n",
      "Average loss: 0.553998, Train accuracy: 0.838958, Val accuracy: 0.851682\n",
      "Average loss: 0.518633, Train accuracy: 0.848787, Val accuracy: 0.855983\n",
      "Average loss: 0.483420, Train accuracy: 0.858615, Val accuracy: 0.865060\n",
      "Average loss: 0.458409, Train accuracy: 0.865338, Val accuracy: 0.868814\n",
      "Average loss: 0.438444, Train accuracy: 0.871259, Val accuracy: 0.876800\n",
      "Average loss: 0.420925, Train accuracy: 0.876224, Val accuracy: 0.875913\n",
      "End\n",
      "Start lr=0.4348745013088917, l2=2.860595535175739e-05\n",
      "Average loss: 1.018062, Train accuracy: 0.670699, Val accuracy: 0.842195\n",
      "Average loss: 0.516766, Train accuracy: 0.846756, Val accuracy: 0.867654\n",
      "Average loss: 0.439576, Train accuracy: 0.869450, Val accuracy: 0.865333\n",
      "Average loss: 0.396063, Train accuracy: 0.882777, Val accuracy: 0.884786\n",
      "Average loss: 0.366699, Train accuracy: 0.890608, Val accuracy: 0.892431\n",
      "Average loss: 0.346340, Train accuracy: 0.896888, Val accuracy: 0.893591\n",
      "Average loss: 0.326565, Train accuracy: 0.902553, Val accuracy: 0.896048\n",
      "Average loss: 0.313096, Train accuracy: 0.906818, Val accuracy: 0.896185\n",
      "Average loss: 0.298435, Train accuracy: 0.911084, Val accuracy: 0.903283\n",
      "Average loss: 0.287519, Train accuracy: 0.914019, Val accuracy: 0.897891\n",
      "End\n",
      "Start lr=0.03695361016762888, l2=9.794696670695386e-06\n",
      "Average loss: 2.219314, Train accuracy: 0.191840, Val accuracy: 0.245239\n",
      "Average loss: 1.694230, Train accuracy: 0.444323, Val accuracy: 0.598594\n",
      "Average loss: 1.136009, Train accuracy: 0.649268, Val accuracy: 0.690465\n",
      "Average loss: 0.914112, Train accuracy: 0.726700, Val accuracy: 0.754215\n",
      "Average loss: 0.803479, Train accuracy: 0.762772, Val accuracy: 0.788683\n",
      "Average loss: 0.739529, Train accuracy: 0.781985, Val accuracy: 0.797079\n",
      "Average loss: 0.693675, Train accuracy: 0.797205, Val accuracy: 0.814825\n",
      "Average loss: 0.656816, Train accuracy: 0.808125, Val accuracy: 0.826770\n",
      "Average loss: 0.625415, Train accuracy: 0.817578, Val accuracy: 0.830455\n",
      "Average loss: 0.599606, Train accuracy: 0.826605, Val accuracy: 0.835097\n",
      "End\n",
      "Start lr=0.18824679033962347, l2=3.0232946844057763e-05\n",
      "Average loss: 1.355697, Train accuracy: 0.550080, Val accuracy: 0.792779\n",
      "Average loss: 0.650603, Train accuracy: 0.808296, Val accuracy: 0.847109\n",
      "Average loss: 0.527030, Train accuracy: 0.843702, Val accuracy: 0.848748\n",
      "Average loss: 0.466644, Train accuracy: 0.861908, Val accuracy: 0.874343\n",
      "Average loss: 0.422216, Train accuracy: 0.874160, Val accuracy: 0.880896\n",
      "Average loss: 0.394687, Train accuracy: 0.883374, Val accuracy: 0.885469\n",
      "Average loss: 0.369818, Train accuracy: 0.890643, Val accuracy: 0.888404\n",
      "Average loss: 0.351890, Train accuracy: 0.894994, Val accuracy: 0.892977\n",
      "Average loss: 0.334332, Train accuracy: 0.900693, Val accuracy: 0.896526\n",
      "Average loss: 0.322986, Train accuracy: 0.904856, Val accuracy: 0.897618\n",
      "End\n",
      "Start lr=0.021146214371947494, l2=6.650018030431118e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.244376, Train accuracy: 0.183377, Val accuracy: 0.190840\n",
      "Average loss: 2.149443, Train accuracy: 0.223015, Val accuracy: 0.321343\n",
      "Average loss: 1.762608, Train accuracy: 0.425963, Val accuracy: 0.501058\n",
      "Average loss: 1.372166, Train accuracy: 0.568969, Val accuracy: 0.638523\n",
      "Average loss: 1.113502, Train accuracy: 0.659898, Val accuracy: 0.705071\n",
      "Average loss: 0.963634, Train accuracy: 0.710217, Val accuracy: 0.734148\n",
      "Average loss: 0.876452, Train accuracy: 0.741886, Val accuracy: 0.765340\n",
      "Average loss: 0.814460, Train accuracy: 0.761748, Val accuracy: 0.785339\n",
      "Average loss: 0.769466, Train accuracy: 0.773982, Val accuracy: 0.790185\n",
      "Average loss: 0.736596, Train accuracy: 0.785739, Val accuracy: 0.797352\n",
      "End\n",
      "Start lr=0.286118382967511, l2=4.973895958790068e-07\n",
      "Average loss: 1.157802, Train accuracy: 0.621216, Val accuracy: 0.824790\n",
      "Average loss: 0.569383, Train accuracy: 0.832338, Val accuracy: 0.857484\n",
      "Average loss: 0.476061, Train accuracy: 0.858376, Val accuracy: 0.861716\n",
      "Average loss: 0.426174, Train accuracy: 0.873170, Val accuracy: 0.872841\n",
      "Average loss: 0.388475, Train accuracy: 0.884124, Val accuracy: 0.891475\n",
      "Average loss: 0.364648, Train accuracy: 0.892383, Val accuracy: 0.890656\n",
      "Average loss: 0.343136, Train accuracy: 0.898577, Val accuracy: 0.887516\n",
      "Average loss: 0.328138, Train accuracy: 0.903884, Val accuracy: 0.898096\n",
      "Average loss: 0.311452, Train accuracy: 0.908303, Val accuracy: 0.898573\n",
      "Average loss: 0.299157, Train accuracy: 0.911869, Val accuracy: 0.901508\n",
      "End\n",
      "Start lr=0.053613361100516184, l2=2.169383518385182e-07\n",
      "Average loss: 2.122342, Train accuracy: 0.243678, Val accuracy: 0.460583\n",
      "Average loss: 1.259457, Train accuracy: 0.604358, Val accuracy: 0.716333\n",
      "Average loss: 0.893139, Train accuracy: 0.731495, Val accuracy: 0.746570\n",
      "Average loss: 0.761671, Train accuracy: 0.774852, Val accuracy: 0.796328\n",
      "Average loss: 0.683218, Train accuracy: 0.799184, Val accuracy: 0.820149\n",
      "Average loss: 0.633900, Train accuracy: 0.814490, Val accuracy: 0.831001\n",
      "Average loss: 0.593394, Train accuracy: 0.828140, Val accuracy: 0.843833\n",
      "Average loss: 0.561868, Train accuracy: 0.837525, Val accuracy: 0.850727\n",
      "Average loss: 0.534924, Train accuracy: 0.844692, Val accuracy: 0.853662\n",
      "Average loss: 0.512545, Train accuracy: 0.851995, Val accuracy: 0.859805\n",
      "End\n",
      "Start lr=0.08536763237353458, l2=3.0866649433372746e-06\n",
      "Average loss: 1.850164, Train accuracy: 0.358410, Val accuracy: 0.665961\n",
      "Average loss: 0.908249, Train accuracy: 0.726479, Val accuracy: 0.787728\n",
      "Average loss: 0.703196, Train accuracy: 0.794253, Val accuracy: 0.800082\n",
      "Average loss: 0.613437, Train accuracy: 0.821383, Val accuracy: 0.838236\n",
      "Average loss: 0.554597, Train accuracy: 0.838037, Val accuracy: 0.853048\n",
      "Average loss: 0.518770, Train accuracy: 0.848087, Val accuracy: 0.857621\n",
      "Average loss: 0.483902, Train accuracy: 0.858837, Val accuracy: 0.863968\n",
      "Average loss: 0.457997, Train accuracy: 0.865048, Val accuracy: 0.868610\n",
      "Average loss: 0.438080, Train accuracy: 0.871464, Val accuracy: 0.875162\n",
      "Average loss: 0.419852, Train accuracy: 0.876497, Val accuracy: 0.873524\n",
      "End\n",
      "Start lr=0.07087370814634028, l2=4.905583706365046e-06\n",
      "Average loss: 1.972640, Train accuracy: 0.309422, Val accuracy: 0.600915\n",
      "Average loss: 1.022432, Train accuracy: 0.688735, Val accuracy: 0.767524\n",
      "Average loss: 0.765435, Train accuracy: 0.774665, Val accuracy: 0.780015\n",
      "Average loss: 0.661977, Train accuracy: 0.806334, Val accuracy: 0.826770\n",
      "Average loss: 0.595781, Train accuracy: 0.826775, Val accuracy: 0.840898\n",
      "Average loss: 0.555823, Train accuracy: 0.838771, Val accuracy: 0.851341\n",
      "Average loss: 0.519084, Train accuracy: 0.849503, Val accuracy: 0.858576\n",
      "Average loss: 0.491415, Train accuracy: 0.857114, Val accuracy: 0.864037\n",
      "Average loss: 0.467939, Train accuracy: 0.862932, Val accuracy: 0.867791\n",
      "Average loss: 0.448840, Train accuracy: 0.868699, Val accuracy: 0.870180\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "# learning_rates = [1e0, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "# anneal_coeff = 0.2\n",
    "# anneal_epochs = [1, 5, 10, 15, 20, 50]\n",
    "# reg = [1e-3, 1e-4, 1e-5, 1e-7]\n",
    "\n",
    "batch_size = 64\n",
    "epoch_num = 10\n",
    "\n",
    "# Record all the runs here\n",
    "# Key should be Hyperparams and values should be RunResult\n",
    "run_record = {}\n",
    "\n",
    "# Use grid search or random search and record all runs in run_record dictionnary\n",
    "# Important: perform search in logarithmic space!\n",
    "\n",
    "# TODO: Your code here!\n",
    "manualSeed = 42\n",
    "\n",
    "np.random.seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "# if you are suing GPU\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "\n",
    "def _init_fn():\n",
    "    np.random.seed(manualSeed)\n",
    "\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size,\n",
    "                                               sampler=train_sampler, num_workers=4)#worker_init_fn=_init_fn,\n",
    "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler, num_workers=0)\n",
    "\n",
    "# learning_rates = list(np.logspace(\n",
    "#     np.log10(5e-5), np.log10(0.5), base=10, num=10000))\n",
    "learning_rates = list(5*10**np.linspace(-3,-1,100))\n",
    "anneal_epochs = [2, 5, 10]\n",
    "anneal_coeff = 0.2\n",
    "# reg = list(np.logspace(np.log10(1e-7), np.log10(1e-4), base=10, num=1000))\n",
    "reg = list(10**np.linspace(-7,-4,1000))\n",
    "\n",
    "max_evals = 120\n",
    "\n",
    "for _ in range(max_evals):\n",
    "    torch.manual_seed(manualSeed)\n",
    "    # if you are suing GPU\n",
    "    torch.cuda.manual_seed(manualSeed)\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "    \n",
    "    lenet_model = nn.Sequential(\n",
    "        nn.Conv2d(3, 6, 5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "        nn.Conv2d(6, 16, 5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "        nn.Conv2d(16, 120, 5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        Flattener(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(84, 10),\n",
    "        nn.LogSoftmax(dim=-1)\n",
    "    )\n",
    "\n",
    "    lenet_model.type(torch.cuda.FloatTensor)\n",
    "    lenet_model.to(device)\n",
    "    \n",
    "    lr = np.random.choice(learning_rates,1)[0]\n",
    "    l2 = np.random.choice(reg,1)[0]\n",
    "    print(f'Start lr={lr}, l2={l2}')\n",
    "\n",
    "    loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "    optimizer = optim.Adadelta(lenet_model.parameters(), lr=lr, weight_decay=l2)\n",
    "    loss_history, train_history, val_history = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, epoch_num)\n",
    "    h = Hyperparams(lr,None,l2)\n",
    "    run_record[h] = RunResult(lenet_model,train_history,val_history,val_history[-1])\n",
    "    print('End')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T05:45:23.230012Z",
     "start_time": "2019-05-20T05:45:22.809097Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data/hp_none.pkl','rb') as f:\n",
    "        run_record=pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    with open('data/hp_none.pkl','wb') as f:\n",
    "        pickle.dump(run_record,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T07:26:24.010887Z",
     "start_time": "2019-05-19T06:26:51.981888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ae = 2\n",
      "Average loss: 1.224312, Train accuracy: 0.597072, Val accuracy: 0.815166\n",
      "Average loss: 0.598756, Train accuracy: 0.822919, Val accuracy: 0.856733\n",
      "Average loss: 0.479203, Train accuracy: 0.859212, Val accuracy: 0.866494\n",
      "Average loss: 0.459362, Train accuracy: 0.865099, Val accuracy: 0.871203\n",
      "Average loss: 0.436004, Train accuracy: 0.872351, Val accuracy: 0.873592\n",
      "Average loss: 0.436351, Train accuracy: 0.872624, Val accuracy: 0.875299\n",
      "Average loss: 0.429761, Train accuracy: 0.874347, Val accuracy: 0.875845\n",
      "Average loss: 0.428272, Train accuracy: 0.874296, Val accuracy: 0.876049\n",
      "Average loss: 0.427345, Train accuracy: 0.875781, Val accuracy: 0.876118\n",
      "Average loss: 0.427316, Train accuracy: 0.875781, Val accuracy: 0.875913\n",
      "Average loss: 0.425507, Train accuracy: 0.875235, Val accuracy: 0.875981\n",
      "Average loss: 0.426691, Train accuracy: 0.874774, Val accuracy: 0.875981\n",
      "Average loss: 0.426984, Train accuracy: 0.874740, Val accuracy: 0.875981\n",
      "Average loss: 0.427028, Train accuracy: 0.874484, Val accuracy: 0.876118\n",
      "Average loss: 0.426635, Train accuracy: 0.875542, Val accuracy: 0.876118\n",
      "Average loss: 0.427168, Train accuracy: 0.875371, Val accuracy: 0.876118\n",
      "Average loss: 0.424951, Train accuracy: 0.877094, Val accuracy: 0.876118\n",
      "Average loss: 0.425128, Train accuracy: 0.876190, Val accuracy: 0.876118\n",
      "Average loss: 0.426780, Train accuracy: 0.875422, Val accuracy: 0.876118\n",
      "Average loss: 0.425837, Train accuracy: 0.875678, Val accuracy: 0.876118\n",
      "Average loss: 0.425808, Train accuracy: 0.876293, Val accuracy: 0.876118\n",
      "Average loss: 0.425218, Train accuracy: 0.876548, Val accuracy: 0.876118\n",
      "Average loss: 0.427863, Train accuracy: 0.874603, Val accuracy: 0.876118\n",
      "Average loss: 0.425563, Train accuracy: 0.876327, Val accuracy: 0.876118\n",
      "Average loss: 0.425498, Train accuracy: 0.876293, Val accuracy: 0.876118\n",
      "Average loss: 0.423376, Train accuracy: 0.876514, Val accuracy: 0.876118\n",
      "Average loss: 0.424082, Train accuracy: 0.877129, Val accuracy: 0.876118\n",
      "Average loss: 0.424650, Train accuracy: 0.875883, Val accuracy: 0.876118\n",
      "Average loss: 0.428565, Train accuracy: 0.874825, Val accuracy: 0.876118\n",
      "Average loss: 0.426767, Train accuracy: 0.875474, Val accuracy: 0.876118\n",
      "Average loss: 0.427446, Train accuracy: 0.874962, Val accuracy: 0.876118\n",
      "Average loss: 0.426225, Train accuracy: 0.875491, Val accuracy: 0.876118\n",
      "Average loss: 0.425636, Train accuracy: 0.876156, Val accuracy: 0.876118\n",
      "Average loss: 0.424422, Train accuracy: 0.876275, Val accuracy: 0.876118\n",
      "Average loss: 0.426323, Train accuracy: 0.875900, Val accuracy: 0.876118\n",
      "Average loss: 0.424742, Train accuracy: 0.875388, Val accuracy: 0.876118\n",
      "Average loss: 0.425122, Train accuracy: 0.875508, Val accuracy: 0.876118\n",
      "Average loss: 0.425412, Train accuracy: 0.875354, Val accuracy: 0.876118\n",
      "Average loss: 0.424472, Train accuracy: 0.875644, Val accuracy: 0.876118\n",
      "Average loss: 0.423872, Train accuracy: 0.875269, Val accuracy: 0.876118\n",
      "Average loss: 0.426964, Train accuracy: 0.875474, Val accuracy: 0.876118\n",
      "Average loss: 0.425204, Train accuracy: 0.876702, Val accuracy: 0.876118\n",
      "Average loss: 0.426421, Train accuracy: 0.875627, Val accuracy: 0.876118\n",
      "Average loss: 0.424109, Train accuracy: 0.876105, Val accuracy: 0.876118\n",
      "Average loss: 0.424803, Train accuracy: 0.876207, Val accuracy: 0.876118\n",
      "Average loss: 0.427855, Train accuracy: 0.874143, Val accuracy: 0.876118\n",
      "Average loss: 0.426163, Train accuracy: 0.875405, Val accuracy: 0.876118\n",
      "Average loss: 0.425972, Train accuracy: 0.876037, Val accuracy: 0.876118\n",
      "Average loss: 0.426186, Train accuracy: 0.874996, Val accuracy: 0.876118\n",
      "Average loss: 0.425716, Train accuracy: 0.874927, Val accuracy: 0.876118\n",
      "End\n",
      "Start ae = 5\n",
      "Average loss: 1.217472, Train accuracy: 0.600212, Val accuracy: 0.817350\n",
      "Average loss: 0.594060, Train accuracy: 0.825376, Val accuracy: 0.855710\n",
      "Average loss: 0.491985, Train accuracy: 0.854452, Val accuracy: 0.857279\n",
      "Average loss: 0.439685, Train accuracy: 0.870355, Val accuracy: 0.876186\n",
      "Average loss: 0.399770, Train accuracy: 0.881360, Val accuracy: 0.889359\n",
      "Average loss: 0.346895, Train accuracy: 0.897997, Val accuracy: 0.895502\n",
      "Average loss: 0.333100, Train accuracy: 0.902826, Val accuracy: 0.893932\n",
      "Average loss: 0.328223, Train accuracy: 0.903935, Val accuracy: 0.894888\n",
      "Average loss: 0.321365, Train accuracy: 0.907057, Val accuracy: 0.897550\n",
      "Average loss: 0.316011, Train accuracy: 0.907279, Val accuracy: 0.897413\n",
      "Average loss: 0.302039, Train accuracy: 0.912756, Val accuracy: 0.899802\n",
      "Average loss: 0.302360, Train accuracy: 0.911750, Val accuracy: 0.900280\n",
      "Average loss: 0.301473, Train accuracy: 0.912006, Val accuracy: 0.900689\n",
      "Average loss: 0.299912, Train accuracy: 0.912876, Val accuracy: 0.900348\n",
      "Average loss: 0.297723, Train accuracy: 0.913678, Val accuracy: 0.900894\n",
      "Average loss: 0.296057, Train accuracy: 0.914855, Val accuracy: 0.901099\n",
      "Average loss: 0.294394, Train accuracy: 0.915128, Val accuracy: 0.900212\n",
      "Average loss: 0.294512, Train accuracy: 0.914275, Val accuracy: 0.899802\n",
      "Average loss: 0.295430, Train accuracy: 0.914565, Val accuracy: 0.899666\n",
      "Average loss: 0.295422, Train accuracy: 0.914224, Val accuracy: 0.900075\n",
      "Average loss: 0.294638, Train accuracy: 0.914582, Val accuracy: 0.900143\n",
      "Average loss: 0.293895, Train accuracy: 0.914685, Val accuracy: 0.900280\n",
      "Average loss: 0.296019, Train accuracy: 0.914241, Val accuracy: 0.900280\n",
      "Average loss: 0.292995, Train accuracy: 0.913865, Val accuracy: 0.900143\n",
      "Average loss: 0.293142, Train accuracy: 0.915759, Val accuracy: 0.900280\n",
      "Average loss: 0.292160, Train accuracy: 0.915828, Val accuracy: 0.900212\n",
      "Average loss: 0.293295, Train accuracy: 0.915384, Val accuracy: 0.900280\n",
      "Average loss: 0.294083, Train accuracy: 0.914497, Val accuracy: 0.900280\n",
      "Average loss: 0.295574, Train accuracy: 0.914121, Val accuracy: 0.900280\n",
      "Average loss: 0.293624, Train accuracy: 0.915947, Val accuracy: 0.900280\n",
      "Average loss: 0.293893, Train accuracy: 0.915196, Val accuracy: 0.900280\n",
      "Average loss: 0.293484, Train accuracy: 0.914429, Val accuracy: 0.900280\n",
      "Average loss: 0.293387, Train accuracy: 0.915691, Val accuracy: 0.900348\n",
      "Average loss: 0.293877, Train accuracy: 0.915640, Val accuracy: 0.900348\n",
      "Average loss: 0.294189, Train accuracy: 0.915162, Val accuracy: 0.900348\n",
      "Average loss: 0.293036, Train accuracy: 0.914753, Val accuracy: 0.900348\n",
      "Average loss: 0.292265, Train accuracy: 0.915401, Val accuracy: 0.900348\n",
      "Average loss: 0.291996, Train accuracy: 0.915521, Val accuracy: 0.900348\n",
      "Average loss: 0.292903, Train accuracy: 0.915504, Val accuracy: 0.900348\n",
      "Average loss: 0.294255, Train accuracy: 0.914975, Val accuracy: 0.900348\n",
      "Average loss: 0.294317, Train accuracy: 0.915657, Val accuracy: 0.900348\n",
      "Average loss: 0.293547, Train accuracy: 0.915248, Val accuracy: 0.900348\n",
      "Average loss: 0.293296, Train accuracy: 0.915742, Val accuracy: 0.900348\n",
      "Average loss: 0.294487, Train accuracy: 0.915674, Val accuracy: 0.900348\n",
      "Average loss: 0.292147, Train accuracy: 0.915964, Val accuracy: 0.900348\n",
      "Average loss: 0.294213, Train accuracy: 0.915248, Val accuracy: 0.900348\n",
      "Average loss: 0.293310, Train accuracy: 0.915265, Val accuracy: 0.900348\n",
      "Average loss: 0.292759, Train accuracy: 0.915350, Val accuracy: 0.900348\n",
      "Average loss: 0.294538, Train accuracy: 0.914838, Val accuracy: 0.900348\n",
      "Average loss: 0.294418, Train accuracy: 0.914394, Val accuracy: 0.900348\n",
      "End\n",
      "Start ae = 10\n",
      "Average loss: 1.216213, Train accuracy: 0.600655, Val accuracy: 0.816327\n",
      "Average loss: 0.594270, Train accuracy: 0.825530, Val accuracy: 0.855232\n",
      "Average loss: 0.492016, Train accuracy: 0.854230, Val accuracy: 0.857075\n",
      "Average loss: 0.440120, Train accuracy: 0.870235, Val accuracy: 0.873865\n",
      "Average loss: 0.400786, Train accuracy: 0.881275, Val accuracy: 0.888950\n",
      "Average loss: 0.376324, Train accuracy: 0.889329, Val accuracy: 0.891748\n",
      "Average loss: 0.352907, Train accuracy: 0.897127, Val accuracy: 0.891202\n",
      "Average loss: 0.338940, Train accuracy: 0.900334, Val accuracy: 0.891748\n",
      "Average loss: 0.324536, Train accuracy: 0.904071, Val accuracy: 0.899666\n",
      "Average loss: 0.309878, Train accuracy: 0.907672, Val accuracy: 0.895980\n",
      "Average loss: 0.265061, Train accuracy: 0.922602, Val accuracy: 0.905945\n",
      "Average loss: 0.260584, Train accuracy: 0.924410, Val accuracy: 0.905126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.256022, Train accuracy: 0.926014, Val accuracy: 0.907720\n",
      "Average loss: 0.251279, Train accuracy: 0.927448, Val accuracy: 0.906901\n",
      "Average loss: 0.247284, Train accuracy: 0.928540, Val accuracy: 0.908334\n",
      "Average loss: 0.245460, Train accuracy: 0.929888, Val accuracy: 0.908334\n",
      "Average loss: 0.242247, Train accuracy: 0.930570, Val accuracy: 0.908743\n",
      "Average loss: 0.239667, Train accuracy: 0.930826, Val accuracy: 0.907583\n",
      "Average loss: 0.237716, Train accuracy: 0.931440, Val accuracy: 0.907310\n",
      "Average loss: 0.235697, Train accuracy: 0.932993, Val accuracy: 0.907447\n",
      "Average loss: 0.226142, Train accuracy: 0.935331, Val accuracy: 0.909767\n",
      "Average loss: 0.223385, Train accuracy: 0.936884, Val accuracy: 0.909631\n",
      "Average loss: 0.223205, Train accuracy: 0.936065, Val accuracy: 0.910177\n",
      "Average loss: 0.220891, Train accuracy: 0.936372, Val accuracy: 0.909767\n",
      "Average loss: 0.221850, Train accuracy: 0.937703, Val accuracy: 0.910177\n",
      "Average loss: 0.220716, Train accuracy: 0.937310, Val accuracy: 0.909767\n",
      "Average loss: 0.220617, Train accuracy: 0.937634, Val accuracy: 0.910382\n",
      "Average loss: 0.221199, Train accuracy: 0.937191, Val accuracy: 0.909904\n",
      "Average loss: 0.221576, Train accuracy: 0.937037, Val accuracy: 0.910245\n",
      "Average loss: 0.220311, Train accuracy: 0.937600, Val accuracy: 0.909221\n",
      "Average loss: 0.218714, Train accuracy: 0.937686, Val accuracy: 0.909767\n",
      "Average loss: 0.218296, Train accuracy: 0.937720, Val accuracy: 0.910177\n",
      "Average loss: 0.217362, Train accuracy: 0.938948, Val accuracy: 0.910791\n",
      "Average loss: 0.218588, Train accuracy: 0.938709, Val accuracy: 0.909904\n",
      "Average loss: 0.217437, Train accuracy: 0.937737, Val accuracy: 0.910655\n",
      "Average loss: 0.215940, Train accuracy: 0.938641, Val accuracy: 0.910723\n",
      "Average loss: 0.215646, Train accuracy: 0.938965, Val accuracy: 0.910177\n",
      "Average loss: 0.215564, Train accuracy: 0.938215, Val accuracy: 0.910313\n",
      "Average loss: 0.215875, Train accuracy: 0.938539, Val accuracy: 0.910655\n",
      "Average loss: 0.218082, Train accuracy: 0.937532, Val accuracy: 0.910245\n",
      "Average loss: 0.215324, Train accuracy: 0.939204, Val accuracy: 0.910450\n",
      "Average loss: 0.216044, Train accuracy: 0.938795, Val accuracy: 0.910518\n",
      "Average loss: 0.215201, Train accuracy: 0.938675, Val accuracy: 0.910518\n",
      "Average loss: 0.216129, Train accuracy: 0.939255, Val accuracy: 0.910313\n",
      "Average loss: 0.214263, Train accuracy: 0.940143, Val accuracy: 0.910245\n",
      "Average loss: 0.215658, Train accuracy: 0.938982, Val accuracy: 0.910313\n",
      "Average loss: 0.215601, Train accuracy: 0.939699, Val accuracy: 0.910313\n",
      "Average loss: 0.215754, Train accuracy: 0.939341, Val accuracy: 0.910109\n",
      "Average loss: 0.216382, Train accuracy: 0.938624, Val accuracy: 0.910382\n",
      "Average loss: 0.216621, Train accuracy: 0.938488, Val accuracy: 0.910382\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams = None\n",
    "best_val_accuracy = None\n",
    "epoch_num = 50\n",
    "\n",
    "for hyperparams, run_result in run_record.items():\n",
    "    if best_val_accuracy is None or best_val_accuracy < run_result.final_val_accuracy:\n",
    "        best_val_accuracy = run_result.final_val_accuracy\n",
    "        best_hyperparams = hyperparams\n",
    "        \n",
    "for ae in anneal_epochs:\n",
    "    torch.manual_seed(manualSeed)\n",
    "    # if you are suing GPU\n",
    "    torch.cuda.manual_seed(manualSeed)\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "    \n",
    "    lenet_model = nn.Sequential(\n",
    "        nn.Conv2d(3, 6, 5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "        nn.Conv2d(6, 16, 5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "        nn.Conv2d(16, 120, 5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        Flattener(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(84, 10),\n",
    "        nn.LogSoftmax(dim=-1)\n",
    "    )\n",
    "\n",
    "    lenet_model.type(torch.cuda.FloatTensor)\n",
    "    lenet_model.to(device)\n",
    "    \n",
    "    lr = best_hyperparams.learning_rate\n",
    "    l2 = best_hyperparams.reg\n",
    "    \n",
    "    train_history, val_history = [], []\n",
    "    print(f'Start ae = {ae}')\n",
    "\n",
    "    loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "    optimizer = optim.Adadelta(lenet_model.parameters(), lr=lr, weight_decay=l2)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=anneal_coeff)\n",
    "    for i in range(0,epoch_num,ae):\n",
    "        loss_history_, train_history_, val_history_ = train_model(lenet_model, train_aug_loader, val_loader, loss, optimizer, ae)\n",
    "        scheduler.step()\n",
    "        train_history.extend(train_history_)\n",
    "        val_history.extend(val_history_)\n",
    "    h = Hyperparams(lr,ae,l2)\n",
    "    run_record[h] = RunResult(lenet_model,train_history,val_history,val_history[-1])\n",
    "    print('End')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T05:46:02.698147Z",
     "start_time": "2019-05-20T05:46:02.237652Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data/hp.pkl','rb') as f:\n",
    "        run_record=pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    with open('data/hp.pkl','wb') as f:\n",
    "        pickle.dump(run_record,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T05:48:15.443663Z",
     "start_time": "2019-05-20T05:48:15.437663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.91, best hyperparams: Hyperparams(learning_rate=0.24885117821660557, anneal_epochs=10, reg=1.4426439512181588e-05)\n"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = None\n",
    "best_hyperparams = None\n",
    "best_run = None\n",
    "best_model = None\n",
    "\n",
    "for hyperparams, run_result in run_record.items():\n",
    "    if best_val_accuracy is None or best_val_accuracy < run_result.final_val_accuracy:\n",
    "        best_val_accuracy = run_result.final_val_accuracy\n",
    "        best_hyperparams = hyperparams\n",
    "        best_run = run_result\n",
    "        best_model = run_result.model\n",
    "\n",
    "print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" %\n",
    "      (best_val_accuracy, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LOmsR0uVgtgf"
   },
   "source": [
    "# Свободное упражнение - догоним и перегоним LeNet!\n",
    "\n",
    "Попробуйте найти архитектуру и настройки тренировки, чтобы выступить лучше наших бейзлайнов.\n",
    "\n",
    "Что можно и нужно попробовать:\n",
    "- BatchNormalization (для convolution layers он в PyTorch называется [batchnorm2d](https://pytorch.org/docs/stable/nn.html#batchnorm2d))\n",
    "- Изменить количество слоев и их толщину\n",
    "- Изменять количество эпох тренировки\n",
    "- Попробовать и другие агментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T09:59:21.287920Z",
     "start_time": "2019-05-20T09:38:30.946633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50, Average loss: 0.785664, Train accuracy: 0.747227, Val accuracy: 0.851341\n",
      "Epoch 2 of 50, Average loss: 0.459507, Train accuracy: 0.858257, Val accuracy: 0.887789\n",
      "Epoch 3 of 50, Average loss: 0.404207, Train accuracy: 0.875388, Val accuracy: 0.892977\n",
      "Epoch 4 of 50, Average loss: 0.365954, Train accuracy: 0.888902, Val accuracy: 0.895570\n",
      "Epoch 5 of 50, Average loss: 0.340862, Train accuracy: 0.894874, Val accuracy: 0.898573\n",
      "Epoch 6 of 50, Average loss: 0.320441, Train accuracy: 0.901478, Val accuracy: 0.897959\n",
      "Epoch 7 of 50, Average loss: 0.308396, Train accuracy: 0.904600, Val accuracy: 0.902942\n",
      "Epoch 8 of 50, Average loss: 0.293899, Train accuracy: 0.911016, Val accuracy: 0.907242\n",
      "Epoch 9 of 50, Average loss: 0.282150, Train accuracy: 0.913865, Val accuracy: 0.910518\n",
      "Epoch 10 of 50, Average loss: 0.271427, Train accuracy: 0.917261, Val accuracy: 0.911269\n",
      "Epoch 11 of 50, Average loss: 0.265879, Train accuracy: 0.918694, Val accuracy: 0.910450\n",
      "Epoch 12 of 50, Average loss: 0.253823, Train accuracy: 0.921868, Val accuracy: 0.910109\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0000e-01.\n",
      "Epoch 13 of 50, Average loss: 0.249552, Train accuracy: 0.922329, Val accuracy: 0.903010\n",
      "Epoch 14 of 50, Average loss: 0.195894, Train accuracy: 0.939733, Val accuracy: 0.916115\n",
      "Epoch 15 of 50, Average loss: 0.179060, Train accuracy: 0.945535, Val accuracy: 0.917139\n",
      "Epoch 16 of 50, Average loss: 0.174530, Train accuracy: 0.946456, Val accuracy: 0.917821\n",
      "Epoch 17 of 50, Average loss: 0.166944, Train accuracy: 0.949698, Val accuracy: 0.917071\n",
      "Epoch 18 of 50, Average loss: 0.164094, Train accuracy: 0.949647, Val accuracy: 0.917275\n",
      "Epoch    18: reducing learning rate of group 0 to 5.0000e-02.\n",
      "Epoch 19 of 50, Average loss: 0.161604, Train accuracy: 0.950739, Val accuracy: 0.917753\n",
      "Epoch 20 of 50, Average loss: 0.151647, Train accuracy: 0.954203, Val accuracy: 0.917344\n",
      "Epoch 21 of 50, Average loss: 0.153508, Train accuracy: 0.953213, Val accuracy: 0.918640\n",
      "Epoch 22 of 50, Average loss: 0.151400, Train accuracy: 0.953827, Val accuracy: 0.917890\n",
      "Epoch 23 of 50, Average loss: 0.152902, Train accuracy: 0.953759, Val accuracy: 0.917821\n",
      "Epoch 24 of 50, Average loss: 0.152153, Train accuracy: 0.953059, Val accuracy: 0.918982\n",
      "Epoch 25 of 50, Average loss: 0.151284, Train accuracy: 0.954169, Val accuracy: 0.917890\n",
      "Epoch 26 of 50, Average loss: 0.151256, Train accuracy: 0.953759, Val accuracy: 0.917821\n",
      "Epoch    26: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch 27 of 50, Average loss: 0.151827, Train accuracy: 0.954288, Val accuracy: 0.917207\n",
      "Epoch 28 of 50, Average loss: 0.151514, Train accuracy: 0.953367, Val accuracy: 0.918026\n",
      "Epoch 29 of 50, Average loss: 0.148784, Train accuracy: 0.954476, Val accuracy: 0.917480\n",
      "Epoch    29: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 30 of 50, Average loss: 0.150128, Train accuracy: 0.954544, Val accuracy: 0.917617\n",
      "Epoch 31 of 50, Average loss: 0.147290, Train accuracy: 0.955414, Val accuracy: 0.918367\n",
      "Epoch 32 of 50, Average loss: 0.151753, Train accuracy: 0.953913, Val accuracy: 0.918367\n",
      "Epoch    32: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 33 of 50, Average loss: 0.149690, Train accuracy: 0.954356, Val accuracy: 0.918572\n",
      "Epoch 34 of 50, Average loss: 0.149983, Train accuracy: 0.954578, Val accuracy: 0.918504\n",
      "Epoch 35 of 50, Average loss: 0.147789, Train accuracy: 0.954390, Val accuracy: 0.918163\n",
      "Epoch    35: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch 36 of 50, Average loss: 0.150872, Train accuracy: 0.952974, Val accuracy: 0.917548\n",
      "Epoch 37 of 50, Average loss: 0.149859, Train accuracy: 0.954527, Val accuracy: 0.918777\n",
      "Epoch 38 of 50, Average loss: 0.149497, Train accuracy: 0.954237, Val accuracy: 0.918026\n",
      "Epoch    38: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch 39 of 50, Average loss: 0.152071, Train accuracy: 0.954186, Val accuracy: 0.917480\n",
      "Epoch 40 of 50, Average loss: 0.150703, Train accuracy: 0.954424, Val accuracy: 0.917617\n",
      "Epoch 41 of 50, Average loss: 0.152182, Train accuracy: 0.953622, Val accuracy: 0.918436\n",
      "Epoch    41: reducing learning rate of group 0 to 5.0000e-08.\n",
      "Epoch 42 of 50, Average loss: 0.151154, Train accuracy: 0.954117, Val accuracy: 0.918026\n",
      "Epoch 43 of 50, Average loss: 0.150136, Train accuracy: 0.955090, Val accuracy: 0.918094\n",
      "Epoch 44 of 50, Average loss: 0.150581, Train accuracy: 0.954629, Val accuracy: 0.917958\n",
      "Epoch    44: reducing learning rate of group 0 to 5.0000e-09.\n",
      "Epoch 45 of 50, Average loss: 0.150129, Train accuracy: 0.954885, Val accuracy: 0.917753\n",
      "Epoch 46 of 50, Average loss: 0.153018, Train accuracy: 0.953145, Val accuracy: 0.917890\n",
      "Epoch 47 of 50, Average loss: 0.150477, Train accuracy: 0.954476, Val accuracy: 0.917958\n",
      "Epoch 48 of 50, Average loss: 0.148800, Train accuracy: 0.954305, Val accuracy: 0.918777\n",
      "Epoch 49 of 50, Average loss: 0.148355, Train accuracy: 0.955499, Val accuracy: 0.918163\n",
      "Epoch 50 of 50, Average loss: 0.148511, Train accuracy: 0.954407, Val accuracy: 0.917548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7856637239456177,\n",
       "  0.45950669050216675,\n",
       "  0.40420660376548767,\n",
       "  0.3659535348415375,\n",
       "  0.3408624827861786,\n",
       "  0.3204413950443268,\n",
       "  0.30839648842811584,\n",
       "  0.29389891028404236,\n",
       "  0.28214964270591736,\n",
       "  0.27142736315727234,\n",
       "  0.2658792734146118,\n",
       "  0.25382301211357117,\n",
       "  0.24955230951309204,\n",
       "  0.19589394330978394,\n",
       "  0.17906005680561066,\n",
       "  0.174529567360878,\n",
       "  0.16694436967372894,\n",
       "  0.1640939712524414,\n",
       "  0.1616041362285614,\n",
       "  0.15164655447006226,\n",
       "  0.1535082310438156,\n",
       "  0.15140047669410706,\n",
       "  0.1529017686843872,\n",
       "  0.15215347707271576,\n",
       "  0.15128393471240997,\n",
       "  0.1512555032968521,\n",
       "  0.1518273502588272,\n",
       "  0.15151430666446686,\n",
       "  0.1487835943698883,\n",
       "  0.1501276195049286,\n",
       "  0.14729002118110657,\n",
       "  0.15175305306911469,\n",
       "  0.14969047904014587,\n",
       "  0.14998331665992737,\n",
       "  0.14778852462768555,\n",
       "  0.15087245404720306,\n",
       "  0.1498589664697647,\n",
       "  0.1494966447353363,\n",
       "  0.15207061171531677,\n",
       "  0.15070250630378723,\n",
       "  0.1521819531917572,\n",
       "  0.15115436911582947,\n",
       "  0.15013550221920013,\n",
       "  0.1505809873342514,\n",
       "  0.15012896060943604,\n",
       "  0.15301848948001862,\n",
       "  0.15047720074653625,\n",
       "  0.14880000054836273,\n",
       "  0.148355171084404,\n",
       "  0.14851127564907074],\n",
       " [0.7472272463570283,\n",
       "  0.8582568337712863,\n",
       "  0.8753881855100161,\n",
       "  0.8889021601883766,\n",
       "  0.8948742449578542,\n",
       "  0.9014776644029622,\n",
       "  0.9046002115824319,\n",
       "  0.9110159369347849,\n",
       "  0.9138654745247927,\n",
       "  0.9172610312937242,\n",
       "  0.9186943316383988,\n",
       "  0.9218680681158926,\n",
       "  0.9223287717981095,\n",
       "  0.939733133126301,\n",
       "  0.9455345869023649,\n",
       "  0.9464559942667986,\n",
       "  0.9496979831416579,\n",
       "  0.9496467938436337,\n",
       "  0.950738832201481,\n",
       "  0.954202641367778,\n",
       "  0.9532129816059789,\n",
       "  0.953827253182268,\n",
       "  0.9537590007849026,\n",
       "  0.9530594137119066,\n",
       "  0.9541685151690953,\n",
       "  0.9537590007849026,\n",
       "  0.9542879568644849,\n",
       "  0.9533665495000512,\n",
       "  0.9544756509572399,\n",
       "  0.9545439033546054,\n",
       "  0.9554141214210149,\n",
       "  0.9539125686789749,\n",
       "  0.9543562092618503,\n",
       "  0.9545780295532881,\n",
       "  0.9543903354605331,\n",
       "  0.9529740982151998,\n",
       "  0.954526840255264,\n",
       "  0.9542367675664608,\n",
       "  0.9541855782684366,\n",
       "  0.9544244616592158,\n",
       "  0.9536224959901717,\n",
       "  0.9541173258710712,\n",
       "  0.955089922533529,\n",
       "  0.9546292188513121,\n",
       "  0.9548851653414326,\n",
       "  0.9531447292086135,\n",
       "  0.9544756509572399,\n",
       "  0.9543050199638262,\n",
       "  0.9554994369177218,\n",
       "  0.9544073985598744],\n",
       " [0.8513412053784725,\n",
       "  0.8877892294041362,\n",
       "  0.8929765886287625,\n",
       "  0.8955702682410757,\n",
       "  0.8985734762132278,\n",
       "  0.8979591836734694,\n",
       "  0.9029417787181763,\n",
       "  0.9072418264964849,\n",
       "  0.9105180533751962,\n",
       "  0.9112688553682342,\n",
       "  0.9104497986485565,\n",
       "  0.9101085250153573,\n",
       "  0.903010033444816,\n",
       "  0.9161149409596615,\n",
       "  0.9171387618592588,\n",
       "  0.917821309125657,\n",
       "  0.917070507132619,\n",
       "  0.9172752713125384,\n",
       "  0.9177530543990171,\n",
       "  0.9173435260391782,\n",
       "  0.9186403658453348,\n",
       "  0.9178895638522968,\n",
       "  0.917821309125657,\n",
       "  0.9189816394785338,\n",
       "  0.9178895638522968,\n",
       "  0.917821309125657,\n",
       "  0.9172070165858985,\n",
       "  0.9180260733055764,\n",
       "  0.9174800354924578,\n",
       "  0.9176165449457375,\n",
       "  0.9183673469387755,\n",
       "  0.9183673469387755,\n",
       "  0.918572111118695,\n",
       "  0.9185038563920551,\n",
       "  0.9181625827588561,\n",
       "  0.9175482902190977,\n",
       "  0.9187768752986144,\n",
       "  0.9180260733055764,\n",
       "  0.9174800354924578,\n",
       "  0.9176165449457375,\n",
       "  0.9184356016654154,\n",
       "  0.9180260733055764,\n",
       "  0.9180943280322162,\n",
       "  0.9179578185789365,\n",
       "  0.9177530543990171,\n",
       "  0.9178895638522968,\n",
       "  0.9179578185789365,\n",
       "  0.9187768752986144,\n",
       "  0.9181625827588561,\n",
       "  0.9175482902190977])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CV_Model(object):\n",
    "    def __init__(self, nn_model, tfs=None, batch_size=64, learning_rate=1e-1, reg=1e-5, anneal_coeff=0.1, num_epochs=10,\n",
    "                 model_status=None, validation_split=0.2, num_workers=0, random_state=None):\n",
    "        self.model = nn_model\n",
    "        self.transforms = tfs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = learning_rate\n",
    "        self.reg = reg\n",
    "        self.anneal_coeff = anneal_coeff\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        if model_status:\n",
    "            self.model.load_state_dict(torch.load(model_status))\n",
    "        self.vs = validation_split\n",
    "        self.num_workers = num_workers\n",
    "        if random_state:\n",
    "            self.random_state = random_state\n",
    "            np.random.seed(random_state)\n",
    "            random.seed(random_state)\n",
    "            torch.manual_seed(random_state)\n",
    "            # if you are suing GPU\n",
    "            torch.cuda.manual_seed(random_state)\n",
    "            torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "    def _init_fn(self):\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "    def fit(self):\n",
    "        # Load data\n",
    "        data_train = dset.SVHN('./data',\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43, 0.44, 0.47],\n",
    "                                                std=[0.20, 0.20, 0.20])\n",
    "                       ])\n",
    "                       )\n",
    "        data_size = data_train.data.shape[0]\n",
    "        split = int(np.floor(self.vs * data_size))\n",
    "        indices = list(range(data_size))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        data_aug_train = dset.SVHN('./data/',\n",
    "                           transform=self.transforms\n",
    "                           )\n",
    "        train_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=self.batch_size,\n",
    "                                                       # worker_init_fn=self._init_fn,\n",
    "                                                       sampler=train_sampler, num_workers=self.num_workers)\n",
    "        val_loader = torch.utils.data.DataLoader(data_train, batch_size=self.batch_size,\n",
    "                                                 # worker_init_fn=self._init_fn,\n",
    "                                                 sampler=val_sampler, num_workers=0)\n",
    "        # model params\n",
    "        self.model.type(torch.cuda.FloatTensor)\n",
    "        self.model.to(device)\n",
    "        loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "        optimizer = optim.Adadelta(self.model.parameters(), lr=self.lr, weight_decay=self.reg)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                         factor=self.anneal_coeff, patience=2,\n",
    "#                                                          threshold=1e-3, eps=1e-4, \n",
    "                                                         verbose=True)\n",
    "        \n",
    "        #training \n",
    "        loss_history = []\n",
    "        train_history = []\n",
    "        val_history = []\n",
    "        for epoch in range(self.num_epochs):\n",
    "            #train\n",
    "            self.model.train()  # Enter train mode\n",
    "\n",
    "            loss_accum = 0\n",
    "            correct_samples = 0\n",
    "            total_samples = 0\n",
    "            for i_step, (x, y) in enumerate(train_loader):\n",
    "\n",
    "                x_gpu = x.to(device, non_blocking=True)\n",
    "                y_gpu = y.to(device, non_blocking=True)\n",
    "                prediction = self.model(x_gpu)\n",
    "                loss_value = loss(prediction, y_gpu)\n",
    "                optimizer.zero_grad()\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, indices = torch.max(prediction, 1)\n",
    "                correct_samples += torch.sum(indices == y_gpu)\n",
    "                total_samples += y.shape[0]\n",
    "\n",
    "                loss_accum += loss_value\n",
    "\n",
    "            ave_loss = loss_accum / i_step\n",
    "            train_accuracy = float(correct_samples) / total_samples\n",
    "            # validation\n",
    "            val_accuracy = compute_accuracy(self.model, val_loader)\n",
    "\n",
    "            loss_history.append(float(ave_loss))\n",
    "            train_history.append(train_accuracy)\n",
    "            val_history.append(val_accuracy)\n",
    "            \n",
    "            scheduler.step(val_accuracy)\n",
    "\n",
    "            print(\"Epoch %d of %d, Average loss: %f, Train accuracy: %f, Val accuracy: %f\" %\n",
    "                  (epoch+1, self.num_epochs, ave_loss, train_accuracy, val_accuracy))\n",
    "\n",
    "        return loss_history, train_history, val_history\n",
    "\n",
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "    transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43, 0.44, 0.47],\n",
    "                         std=[0.20, 0.20, 0.20])\n",
    "])\n",
    "\n",
    "# tfs = transforms.Compose([\n",
    "#    transforms.ToTensor(),\n",
    "#    transforms.Normalize(mean=[0.43, 0.44, 0.47],\n",
    "#                         std=[0.20, 0.20, 0.20])\n",
    "# ])\n",
    "    \n",
    "my_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 6, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    torch.nn.BatchNorm2d(6),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(6, 16, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(16, 120, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    torch.nn.BatchNorm2d(120),\n",
    "    Flattener(),\n",
    "    nn.Linear(120, 84),\n",
    "    torch.nn.BatchNorm1d(84),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(84, 10),\n",
    "    nn.LogSoftmax(dim=-1)\n",
    ")\n",
    "\n",
    "filename = 'data/start_model.pt'\n",
    "# torch.save(my_model.state_dict(), filename)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 5,\n",
    "    'batch_size':128,\n",
    "    'reg':1e-5,\n",
    "    'anneal_coeff':0.1,\n",
    "    'num_epochs':50\n",
    "}\n",
    "\n",
    "model = CV_Model(my_model, tfs, model_status=filename, random_state=42, num_workers=4,**params)\n",
    "\n",
    "loss_history, train_history, val_history = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T09:59:21.332917Z",
     "start_time": "2019-05-20T09:59:21.329920Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T05:47:29.642471Z",
     "start_time": "2019-05-20T05:47:29.638461Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tSVhD747icoc"
   },
   "outputs": [],
   "source": [
    "# best_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubeKgBcnhx7N"
   },
   "source": [
    "# Финальный аккорд - проверим лучшую модель на test set\n",
    "\n",
    "В качестве разнообразия - напишите код для прогона модели на test set вы.\n",
    "\n",
    "В результате вы должны натренировать модель, которая покажет более **90%** точности на test set.  \n",
    "Как водится, лучший результат в группе получит дополнительные баллы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:02:40.308417Z",
     "start_time": "2019-05-20T10:02:35.163045Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EIqM1kdeh-hd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy -  0.9119161032575291\n"
     ]
    }
   ],
   "source": [
    "# TODO Write the code to compute accuracy on test set\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)\n",
    "test_accuracy = compute_accuracy(best_model, test_loader)\n",
    "print(\"Final test accuracy - \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfH6qip6kVX_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "230.85px",
    "left": "1166px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
