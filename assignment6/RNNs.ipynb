{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
    "\n",
    "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:17:46.143372Z",
     "start_time": "2019-06-21T12:17:46.140370Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "P59NYU98GCb9"
   },
   "outputs": [],
   "source": [
    "# !pip3 -qq install torch==0.4.1\n",
    "# !pip3 -qq install bokeh==0.13.0\n",
    "# !pip3 -qq install gensim==3.6.0\n",
    "# !pip3 -qq install nltk\n",
    "# !pip3 -qq install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:17:46.516514Z",
     "start_time": "2019-06-21T12:17:46.146369Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6CNKM3b4hT1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_XkoGNQUeGm"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFEtWrS_4rUs"
   },
   "source": [
    "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
    "\n",
    "Мы порешаем сейчас POS Tagging для английского.\n",
    "\n",
    "Будем работать с таким набором тегов:\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition (on, of, at, ...)\n",
    "- ADV - adverb (really, already, still, ...)\n",
    "- CONJ - conjunction (and, or, but, ...)\n",
    "- DET - determiner, article (the, a, some, ...)\n",
    "- NOUN - noun (year, home, costs, ...)\n",
    "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
    "- PRT - particle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- . - punctuation marks (. , ;)\n",
    "- X - other (ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPIkKdFlHB-X"
   },
   "source": [
    "Скачаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:17:47.440753Z",
     "start_time": "2019-06-21T12:17:46.518394Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TiA2dGmgF1rW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Aspirant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Aspirant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:17:47.483625Z",
     "start_time": "2019-06-21T12:17:47.442581Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QstS4NO0L97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The            \tDET\n",
      "Fulton         \tNOUN\n",
      "County         \tNOUN\n",
      "Grand          \tADJ\n",
      "Jury           \tNOUN\n",
      "said           \tVERB\n",
      "Friday         \tNOUN\n",
      "an             \tDET\n",
      "investigation  \tNOUN\n",
      "of             \tADP\n",
      "Atlanta's      \tNOUN\n",
      "recent         \tADJ\n",
      "primary        \tNOUN\n",
      "election       \tNOUN\n",
      "produced       \tVERB\n",
      "``             \t.\n",
      "no             \tDET\n",
      "evidence       \tNOUN\n",
      "''             \t.\n",
      "that           \tADP\n",
      "any            \tDET\n",
      "irregularities \tNOUN\n",
      "took           \tVERB\n",
      "place          \tNOUN\n",
      ".              \t.\n"
     ]
    }
   ],
   "source": [
    "for word, tag in data[0]:\n",
    "    print('{:15}\\t{}'.format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epdW8u_YXcAv"
   },
   "source": [
    "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
    "\n",
    "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:15.534685Z",
     "start_time": "2019-06-21T12:17:47.485585Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xTai8Ta0lgwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count in train set: 739769\n",
      "Words count in val set: 130954\n",
      "Words count in test set: 290469\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
    "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
    "print('Words count in test set:', sum(len(sent) for sent in test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eChdLNGtXyP0"
   },
   "source": [
    "Построим маппинги из слов в индекс и из тега в индекс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:15.898660Z",
     "start_time": "2019-06-21T12:18:15.536647Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pCjwwDs6Zq9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in train = 45441. Tags = {'VERB', 'DET', 'ADV', 'PRON', 'NOUN', 'PRT', '.', 'X', 'NUM', 'ADJ', 'CONJ', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "words = {word for sample in train_data for word, tag in sample}\n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tags = {tag for sample in train_data for word, tag in sample}\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
    "tag2ind['<pad>'] = 0\n",
    "\n",
    "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:16.441676Z",
     "start_time": "2019-06-21T12:18:15.901646Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "URC1B2nvPGFt"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
    "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(tags)), tags)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gArQwbzWWkgi"
   },
   "source": [
    "## Бейзлайн\n",
    "\n",
    "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
    "\n",
    "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
    "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
    "\n",
    "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
    "\n",
    "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
    "\n",
    "Простейший вариант - униграммная модель, учитывающая только слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:18.965661Z",
     "start_time": "2019-06-21T12:18:16.443647Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5rWmSToIaeAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unigram tagger = 92.62%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07Ymb_MkbWsF"
   },
   "source": [
    "Добавим вероятности переходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:22.518659Z",
     "start_time": "2019-06-21T12:18:18.966693Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vjz_Rk0bbMyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bigram tagger = 93.42%\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWMw6QHvbaDd"
   },
   "source": [
    "Обратите внимание, что `backoff` важен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:26.640663Z",
     "start_time": "2019-06-21T12:18:22.519661Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8XCuxEBVbOY_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trigram tagger = 23.33%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_data)\n",
    "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4t3xyYd__8d-"
   },
   "source": [
    "## Увеличиваем контекст с рекуррентными сетями\n",
    "\n",
    "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
    "\n",
    "Омонимия - основная причина, почему униграмная модель плоха:  \n",
    "*“he cashed a check at the **bank**”*  \n",
    "vs  \n",
    "*“he sat on the **bank** of the river”*\n",
    "\n",
    "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
    "\n",
    "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
    "\n",
    "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
    "\n",
    "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:27.451823Z",
     "start_time": "2019-06-21T12:18:26.641659Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:27.459661Z",
     "start_time": "2019-06-21T12:18:27.452682Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:27.470693Z",
     "start_time": "2019-06-21T12:18:27.461657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 4), (32, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5I9E9P6eFYv"
   },
   "source": [
    "**Задание** Реализуйте `LSTMTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:27.480845Z",
     "start_time": "2019-06-21T12:18:27.472663Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super(LSTMTagger,self).__init__()\n",
    "\n",
    "        # self.hidden_dim = lstm_hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim,\n",
    "                            num_layers=lstm_layers_count)\n",
    "        self.hidden2tag = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.word_embeddings(inputs)\n",
    "#         print(embeds.shape)\n",
    "        lstm_out, _ = self.lstm(embeds.view(inputs.shape[0], inputs.shape[1], -1))\n",
    "#         print(lstm_out.shape)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(inputs.shape[0], inputs.shape[1], -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_HA8zyheYGH"
   },
   "source": [
    "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:27.538660Z",
     "start_time": "2019-06-21T12:18:27.481661Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jbrxsZ2mehWB",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.0, 92)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "logits = model(X_batch)\n",
    "\n",
    "# <calc accuracy>\n",
    "mask = (y_batch != torch.zeros_like(y_batch))\n",
    "float(torch.sum((torch.argmax(logits, 1) == y_batch)*mask)), int(torch.sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:27.546692Z",
     "start_time": "2019-06-21T12:18:27.540662Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GMUyUm1hgpe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5659, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "# <calc loss>\n",
    "criterion(logits, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSgV3NPUpcjH"
   },
   "source": [
    "**Задание** Вставьте эти вычисление в функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:18:27.563656Z",
     "start_time": "2019-06-21T12:18:27.548658Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "\n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "\n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "\n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                # loss = <calc loss>\n",
    "                loss = criterion(logits, y_batch)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # cur_correct_count, cur_sum_count = <calc accuracy>\n",
    "                mask = (y_batch != torch.zeros_like(y_batch))\n",
    "                cur_correct_count, cur_sum_count = float(\n",
    "                    torch.sum((torch.argmax(logits, 1) == y_batch)*mask)), int(torch.sum(mask))\n",
    "\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "\n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "\n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(\n",
    "            model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "\n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(\n",
    "                model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:22:10.988428Z",
     "start_time": "2019-06-21T12:18:27.564657Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Pqfbeh1ltEYa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 0.82090, Accuracy = 74.70%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 53.72it/s]\n",
      "[1 / 20]   Val: Loss = 0.51450, Accuracy = 82.23%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 49.06it/s]\n",
      "[2 / 20] Train: Loss = 0.41926, Accuracy = 86.03%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 54.24it/s]\n",
      "[2 / 20]   Val: Loss = 0.40463, Accuracy = 85.89%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 47.97it/s]\n",
      "[3 / 20] Train: Loss = 0.31650, Accuracy = 89.55%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 53.51it/s]\n",
      "[3 / 20]   Val: Loss = 0.31975, Accuracy = 89.33%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 48.87it/s]\n",
      "[4 / 20] Train: Loss = 0.23591, Accuracy = 92.37%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 53.41it/s]\n",
      "[4 / 20]   Val: Loss = 0.25900, Accuracy = 91.37%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 48.69it/s]\n",
      "[5 / 20] Train: Loss = 0.17885, Accuracy = 94.20%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 52.78it/s]\n",
      "[5 / 20]   Val: Loss = 0.21334, Accuracy = 92.55%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 49.06it/s]\n",
      "[6 / 20] Train: Loss = 0.14449, Accuracy = 95.28%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 54.06it/s]\n",
      "[6 / 20]   Val: Loss = 0.19585, Accuracy = 93.28%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 48.15it/s]\n",
      "[7 / 20] Train: Loss = 0.12282, Accuracy = 95.96%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 53.85it/s]\n",
      "[7 / 20]   Val: Loss = 0.19513, Accuracy = 93.57%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 47.10it/s]\n",
      "[8 / 20] Train: Loss = 0.11286, Accuracy = 96.26%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 53.63it/s]\n",
      "[8 / 20]   Val: Loss = 0.19072, Accuracy = 93.34%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 47.97it/s]\n",
      "[9 / 20] Train: Loss = 0.10685, Accuracy = 96.45%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 54.01it/s]\n",
      "[9 / 20]   Val: Loss = 0.19279, Accuracy = 93.65%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 50.19it/s]\n",
      "[10 / 20] Train: Loss = 0.10311, Accuracy = 96.58%: 100%|████████████████████████████| 572/572 [00:10<00:00, 53.41it/s]\n",
      "[10 / 20]   Val: Loss = 0.18182, Accuracy = 93.71%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 50.78it/s]\n",
      "[11 / 20] Train: Loss = 0.09950, Accuracy = 96.68%: 100%|████████████████████████████| 572/572 [00:10<00:00, 53.61it/s]\n",
      "[11 / 20]   Val: Loss = 0.18133, Accuracy = 93.67%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 46.59it/s]\n",
      "[12 / 20] Train: Loss = 0.09692, Accuracy = 96.76%: 100%|████████████████████████████| 572/572 [00:10<00:00, 53.64it/s]\n",
      "[12 / 20]   Val: Loss = 0.18765, Accuracy = 93.70%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 48.51it/s]\n",
      "[13 / 20] Train: Loss = 0.09444, Accuracy = 96.85%: 100%|████████████████████████████| 572/572 [00:10<00:00, 52.13it/s]\n",
      "[13 / 20]   Val: Loss = 0.18262, Accuracy = 93.71%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 42.35it/s]\n",
      "[14 / 20] Train: Loss = 0.09322, Accuracy = 96.90%: 100%|████████████████████████████| 572/572 [00:11<00:00, 51.01it/s]\n",
      "[14 / 20]   Val: Loss = 0.17938, Accuracy = 93.69%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 46.26it/s]\n",
      "[15 / 20] Train: Loss = 0.09144, Accuracy = 96.92%: 100%|████████████████████████████| 572/572 [00:10<00:00, 53.25it/s]\n",
      "[15 / 20]   Val: Loss = 0.18515, Accuracy = 93.70%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 45.61it/s]\n",
      "[16 / 20] Train: Loss = 0.09016, Accuracy = 96.99%: 100%|████████████████████████████| 572/572 [00:10<00:00, 55.74it/s]\n",
      "[16 / 20]   Val: Loss = 0.18478, Accuracy = 93.88%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 46.76it/s]\n",
      "[17 / 20] Train: Loss = 0.08856, Accuracy = 97.07%: 100%|████████████████████████████| 572/572 [00:10<00:00, 53.67it/s]\n",
      "[17 / 20]   Val: Loss = 0.19197, Accuracy = 93.78%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 47.97it/s]\n",
      "[18 / 20] Train: Loss = 0.08734, Accuracy = 97.13%: 100%|████████████████████████████| 572/572 [00:10<00:00, 54.12it/s]\n",
      "[18 / 20]   Val: Loss = 0.18850, Accuracy = 93.68%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 48.15it/s]\n",
      "[19 / 20] Train: Loss = 0.08611, Accuracy = 97.14%: 100%|████████████████████████████| 572/572 [00:10<00:00, 53.60it/s]\n",
      "[19 / 20]   Val: Loss = 0.18062, Accuracy = 93.86%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 46.93it/s]\n",
      "[20 / 20] Train: Loss = 0.08456, Accuracy = 97.18%: 100%|████████████████████████████| 572/572 [00:10<00:00, 54.02it/s]\n",
      "[20 / 20]   Val: Loss = 0.18934, Accuracy = 93.42%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 49.43it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0qGetIhfUE5"
   },
   "source": [
    "### Masking\n",
    "\n",
    "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
    "\n",
    "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAfV2dEOfHo5"
   },
   "source": [
    "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:22:11.562441Z",
     "start_time": "2019-06-21T12:22:10.992432Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "98wr38_rw55D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.18492, Accuracy = 93.53%: 100%|█████████████████████████████████████████| 28/28 [00:00<00:00, 50.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.18491816786783083, 0.9353390551143151)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_epoch(model, criterion, (X_test,y_test), 512, None, 'Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXUTSFaEHbDG"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
    "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
    "\n",
    "**Задание** Добавьте Bidirectional LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:22:11.575433Z",
     "start_time": "2019-06-21T12:22:11.567432Z"
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.hidden_dim = lstm_hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim,\n",
    "                            num_layers=lstm_layers_count, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.word_embeddings(inputs)\n",
    "        lstm_out, _ = self.lstm(embeds.view(inputs.shape[0], inputs.shape[1], -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(inputs.shape[0], inputs.shape[1], -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:25:37.126431Z",
     "start_time": "2019-06-21T12:22:11.577431Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 15] Train: Loss = 0.66862, Accuracy = 79.02%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 43.78it/s]\n",
      "[1 / 15]   Val: Loss = 0.41329, Accuracy = 86.04%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 30.09it/s]\n",
      "[2 / 15] Train: Loss = 0.34567, Accuracy = 88.64%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 43.67it/s]\n",
      "[2 / 15]   Val: Loss = 0.33101, Accuracy = 88.86%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 33.25it/s]\n",
      "[3 / 15] Train: Loss = 0.26162, Accuracy = 91.57%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 43.81it/s]\n",
      "[3 / 15]   Val: Loss = 0.26613, Accuracy = 91.04%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 32.42it/s]\n",
      "[4 / 15] Train: Loss = 0.18982, Accuracy = 94.09%: 100%|█████████████████████████████| 572/572 [00:12<00:00, 44.06it/s]\n",
      "[4 / 15]   Val: Loss = 0.20295, Accuracy = 93.26%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 31.94it/s]\n",
      "[5 / 15] Train: Loss = 0.13980, Accuracy = 95.72%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 43.56it/s]\n",
      "[5 / 15]   Val: Loss = 0.17765, Accuracy = 94.15%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 31.25it/s]\n",
      "[6 / 15] Train: Loss = 0.10918, Accuracy = 96.71%: 100%|█████████████████████████████| 572/572 [00:12<00:00, 44.08it/s]\n",
      "[6 / 15]   Val: Loss = 0.16263, Accuracy = 94.73%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 35.39it/s]\n",
      "[7 / 15] Train: Loss = 0.09120, Accuracy = 97.24%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 43.88it/s]\n",
      "[7 / 15]   Val: Loss = 0.16793, Accuracy = 94.83%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 32.34it/s]\n",
      "[8 / 15] Train: Loss = 0.08258, Accuracy = 97.53%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 43.60it/s]\n",
      "[8 / 15]   Val: Loss = 0.17348, Accuracy = 94.88%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 32.34it/s]\n",
      "[9 / 15] Train: Loss = 0.07772, Accuracy = 97.67%: 100%|█████████████████████████████| 572/572 [00:13<00:00, 43.69it/s]\n",
      "[9 / 15]   Val: Loss = 0.15634, Accuracy = 94.92%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 32.66it/s]\n",
      "[10 / 15] Train: Loss = 0.07356, Accuracy = 97.78%: 100%|████████████████████████████| 572/572 [00:13<00:00, 43.61it/s]\n",
      "[10 / 15]   Val: Loss = 0.15320, Accuracy = 95.12%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 31.33it/s]\n",
      "[11 / 15] Train: Loss = 0.07096, Accuracy = 97.86%: 100%|████████████████████████████| 572/572 [00:13<00:00, 43.87it/s]\n",
      "[11 / 15]   Val: Loss = 0.16172, Accuracy = 94.95%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 29.02it/s]\n",
      "[12 / 15] Train: Loss = 0.06810, Accuracy = 97.96%: 100%|████████████████████████████| 572/572 [00:13<00:00, 41.77it/s]\n",
      "[12 / 15]   Val: Loss = 0.16128, Accuracy = 94.93%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 29.95it/s]\n",
      "[13 / 15] Train: Loss = 0.06634, Accuracy = 98.01%: 100%|████████████████████████████| 572/572 [00:13<00:00, 41.18it/s]\n",
      "[13 / 15]   Val: Loss = 0.15901, Accuracy = 95.05%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 30.02it/s]\n",
      "[14 / 15] Train: Loss = 0.06424, Accuracy = 98.05%: 100%|████████████████████████████| 572/572 [00:13<00:00, 41.15it/s]\n",
      "[14 / 15]   Val: Loss = 0.17592, Accuracy = 95.04%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 32.10it/s]\n",
      "[15 / 15] Train: Loss = 0.06319, Accuracy = 98.11%: 100%|████████████████████████████| 572/572 [00:13<00:00, 41.03it/s]\n",
      "[15 / 15]   Val: Loss = 0.15773, Accuracy = 95.06%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 30.16it/s]\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=15,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:25:38.044432Z",
     "start_time": "2019-06-21T12:25:37.128431Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.15582, Accuracy = 95.09%: 100%|█████████████████████████████████████████| 28/28 [00:00<00:00, 31.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1558188535273075, 0.9508725543861823)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_epoch(model, criterion, (X_test,y_test), 512, None, 'Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTXmYGD_ANhm"
   },
   "source": [
    "### Предобученные эмбеддинги\n",
    "\n",
    "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
    "\n",
    "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:26:31.256652Z",
     "start_time": "2019-06-21T12:25:38.047434Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uZpY_Q1xZ18h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Miniconda3\\envs\\dlcourse\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYogOoKlgtcf"
   },
   "source": [
    "Построим подматрицу для слов из нашей тренировочной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:26:31.469692Z",
     "start_time": "2019-06-21T12:26:31.258652Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VsCstxiO03oT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Know 38736 out of 45441 word embeddings\n"
     ]
    }
   ],
   "source": [
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model.vocab:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcG7i-R8hbY3"
   },
   "source": [
    "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:41:07.981389Z",
     "start_time": "2019-06-21T12:41:07.970388Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LxaRBpQd0pat"
   },
   "outputs": [],
   "source": [
    "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(FloatTensor(embeddings))\n",
    "        self.lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim,\n",
    "                            num_layers=lstm_layers_count, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.word_embeddings(inputs)\n",
    "        lstm_out, _ = self.lstm(embeds.view(inputs.shape[0], inputs.shape[1], -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(inputs.shape[0], inputs.shape[1], -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:44:07.191387Z",
     "start_time": "2019-06-21T12:41:11.552387Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EBtI6BDE-Fc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 0.59335, Accuracy = 84.41%: 100%|█████████████████████████████| 572/572 [00:08<00:00, 67.50it/s]\n",
      "[1 / 20]   Val: Loss = 0.25526, Accuracy = 92.52%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 50.98it/s]\n",
      "[2 / 20] Train: Loss = 0.20353, Accuracy = 93.97%: 100%|█████████████████████████████| 572/572 [00:10<00:00, 56.09it/s]\n",
      "[2 / 20]   Val: Loss = 0.18148, Accuracy = 94.51%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 50.00it/s]\n",
      "[3 / 20] Train: Loss = 0.15109, Accuracy = 95.46%: 100%|█████████████████████████████| 572/572 [00:09<00:00, 59.95it/s]\n",
      "[3 / 20]   Val: Loss = 0.14824, Accuracy = 95.46%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 46.26it/s]\n",
      "[4 / 20] Train: Loss = 0.12414, Accuracy = 96.21%: 100%|█████████████████████████████| 572/572 [00:09<00:00, 57.04it/s]\n",
      "[4 / 20]   Val: Loss = 0.13244, Accuracy = 95.92%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 48.87it/s]\n",
      "[5 / 20] Train: Loss = 0.10843, Accuracy = 96.66%: 100%|█████████████████████████████| 572/572 [00:09<00:00, 60.29it/s]\n",
      "[5 / 20]   Val: Loss = 0.11878, Accuracy = 96.32%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 49.62it/s]\n",
      "[6 / 20] Train: Loss = 0.09752, Accuracy = 96.98%: 100%|█████████████████████████████| 572/572 [00:09<00:00, 60.01it/s]\n",
      "[6 / 20]   Val: Loss = 0.11357, Accuracy = 96.47%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 49.24it/s]\n",
      "[7 / 20] Train: Loss = 0.08945, Accuracy = 97.21%: 100%|█████████████████████████████| 572/572 [00:09<00:00, 59.22it/s]\n",
      "[7 / 20]   Val: Loss = 0.10926, Accuracy = 96.56%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 49.62it/s]\n",
      "[8 / 20] Train: Loss = 0.08290, Accuracy = 97.40%: 100%|█████████████████████████████| 572/572 [00:09<00:00, 59.45it/s]\n",
      "[8 / 20]   Val: Loss = 0.10315, Accuracy = 96.66%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 44.67it/s]\n",
      "[9 / 20] Train: Loss = 0.07921, Accuracy = 97.52%: 100%|█████████████████████████████| 572/572 [00:09<00:00, 58.72it/s]\n",
      "[9 / 20]   Val: Loss = 0.10259, Accuracy = 96.74%: 100%|███████████████████████████████| 13/13 [00:00<00:00, 50.39it/s]\n",
      "[10 / 20] Train: Loss = 0.07484, Accuracy = 97.63%: 100%|████████████████████████████| 572/572 [00:08<00:00, 69.66it/s]\n",
      "[10 / 20]   Val: Loss = 0.09998, Accuracy = 96.85%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 56.52it/s]\n",
      "[11 / 20] Train: Loss = 0.07095, Accuracy = 97.75%: 100%|████████████████████████████| 572/572 [00:07<00:00, 73.01it/s]\n",
      "[11 / 20]   Val: Loss = 0.09835, Accuracy = 96.88%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 55.57it/s]\n",
      "[12 / 20] Train: Loss = 0.06754, Accuracy = 97.86%: 100%|████████████████████████████| 572/572 [00:07<00:00, 76.18it/s]\n",
      "[12 / 20]   Val: Loss = 0.09963, Accuracy = 96.82%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 58.31it/s]\n",
      "[13 / 20] Train: Loss = 0.06511, Accuracy = 97.92%: 100%|████████████████████████████| 572/572 [00:07<00:00, 75.91it/s]\n",
      "[13 / 20]   Val: Loss = 0.09595, Accuracy = 96.93%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 53.28it/s]\n",
      "[14 / 20] Train: Loss = 0.06209, Accuracy = 98.02%: 100%|████████████████████████████| 572/572 [00:07<00:00, 75.86it/s]\n",
      "[14 / 20]   Val: Loss = 0.09756, Accuracy = 96.95%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 53.72it/s]\n",
      "[15 / 20] Train: Loss = 0.06030, Accuracy = 98.07%: 100%|████████████████████████████| 572/572 [00:07<00:00, 75.02it/s]\n",
      "[15 / 20]   Val: Loss = 0.09601, Accuracy = 96.97%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 54.62it/s]\n",
      "[16 / 20] Train: Loss = 0.05833, Accuracy = 98.14%: 100%|████████████████████████████| 572/572 [00:07<00:00, 76.21it/s]\n",
      "[16 / 20]   Val: Loss = 0.09510, Accuracy = 96.97%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 59.35it/s]\n",
      "[17 / 20] Train: Loss = 0.05599, Accuracy = 98.20%: 100%|████████████████████████████| 572/572 [00:07<00:00, 75.94it/s]\n",
      "[17 / 20]   Val: Loss = 0.09670, Accuracy = 96.97%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 52.42it/s]\n",
      "[18 / 20] Train: Loss = 0.05421, Accuracy = 98.24%: 100%|████████████████████████████| 572/572 [00:07<00:00, 74.88it/s]\n",
      "[18 / 20]   Val: Loss = 0.09505, Accuracy = 96.99%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 53.94it/s]\n",
      "[19 / 20] Train: Loss = 0.05241, Accuracy = 98.30%: 100%|████████████████████████████| 572/572 [00:08<00:00, 69.59it/s]\n",
      "[19 / 20]   Val: Loss = 0.09698, Accuracy = 96.97%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 46.43it/s]\n",
      "[20 / 20] Train: Loss = 0.05033, Accuracy = 98.36%: 100%|████████████████████████████| 572/572 [00:07<00:00, 75.50it/s]\n",
      "[20 / 20]   Val: Loss = 0.09513, Accuracy = 97.02%: 100%|██████████████████████████████| 13/13 [00:00<00:00, 53.06it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTaggerWithPretrainedEmbs(\n",
    "    embeddings=embeddings,\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ne_8f24h8kg"
   },
   "source": [
    "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
    "\n",
    "Добейтесь качества лучше прошлых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:44:10.967389Z",
     "start_time": "2019-06-21T12:44:10.459388Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HPUuAPGhEGVR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.09519, Accuracy = 97.06%: 100%|█████████████████████████████████████████| 28/28 [00:00<00:00, 56.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0951898353440421, 0.9706164857523523)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_epoch(model, criterion, (X_test,y_test), 512, None, 'Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 06 - RNNs, part 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
